ML_1,semisupervised learning learning paradigm concerned computer natural system human learn presence labeled unlabeled data traditionally learning studied either unsupervised paradigm eg clustering outlier detection data unlabeled supervised paradigm eg classification regression data labeled goal semisupervised learning understand combining labeled unlabeled data may change learning behavior design algorithm take advantage combination semisupervised learning great interest machine learning data mining readily available unlabeled data improve supervised learning task labeled data scarce expensive semisupervised learning also show potential quantitative tool understand human category learning input selfevidently unlabeled introductory book popular semisupervised learning model including selftraining mixture model cotraining multiview learning graphbased method semisupervised support vector machine model discus basic mathematical formulation success semisupervised learning depends critically underlying assumption emphasize assumption made model give counterexample appropriate demonstrate limitation different model addition discus semisupervised learning cognitive psychology finally give computational learning theoretic perspective semisupervised learning conclude book brief discussion question field table content introduction statistical machine learning overview semisupervised learning mixture model em cotraining graphbased semisupervised learning semisupervised support vector machine human semisupervised learning theory outlook ,1
ML_2,learning rank refers machine learning technique training model ranking learning rank useful many application information retrieval natural language processing data mining intensive study conducted problem recently significant progress made lecture give introduction area including fundamental problem major approach theory application future author begin showing various ranking problem information retrieval natural language processing formalized two basic ranking task namely ranking creation simply ranking ranking aggregation ranking creation given request one want generate ranking list offering based feature derived request offering ranking aggregation given request well number ranking list offering one want generate ranking list offering ranking creation ranking major problem learning rank usually formalized supervised learning author give detailed explanation learning ranking creation ranking aggregation including training testing evaluation feature creation major approach many method proposed ranking creation method categorized pointwise pairwise listwise approach according loss function employ also categorized according technique employ svm based boosting based neural network based approach author also introduces popular learning rank method detail include prank oc svm mcrank ranking svm ir svm gbrank ranknet listnet & amp listmle adarank svm map softrank lambdarank lambdamart borda count markov chain cranking author explains several example application learning rank including web search collaborative filtering definition search keyphrase extraction query dependent summarization reranking machine translation formulation learning ranking creation given statistical learning framework ongoing future research direction learning rank also discussed table content learning rank learning ranking creation learning ranking aggregation method learning rank application learning rank theory learning rank ongoing future ,1
ML_3,automated theorem proving represents significant longstanding area research computer science numerous application large proportion method developed date implementation automated theorem provers atp algorithmic sharing great deal common wider heuristic search algorithm however recent year researcher begun incorporate machine learning ml method atp effort extract better performance propositional satisfiability sat solving machine learning large longstanding area research correspondingly large literature book author present result thorough systematic research intersection two apparently rather unrelated field focus research appeared date incorporating ml method solver propositional satisfiability sat problem also solver immediate variant quantified sat qsat comprehensiveness coverage mean ml researcher gain understanding stateoftheart sat qsat solver sufficient make opportunity applying ml research domain clearly visible atp researcher gain clear appreciation stateoftheart machine learning might help design better solver presenting material author concentrate learning method used way incorporated solver enables researcher student automated theorem proving machine learning know tried b understand often complex interaction atp ml needed success undeniably challenging application ,1
ML_4,nonconvex optimization machine learning take indepth look basic nonconvex optimization application machine learning introduces rich literature area well equips reader tool technique needed apply analyze simple powerful procedure nonconvex problem nonconvex optimization machine learning selfcontained possible losing focus topic nonconvex optimization technique monograph initiate discussion entire chapter devoted presenting tutoriallike treatment basic concept convex analysis optimization well nonconvex counterpart monograph concludes look four interesting application area machine learning signal processing exploring nonconvex optimization technique introduced earlier used solve problem monograph also contains topic discussed exercise figure designed engage reader well extensive bibliographic note pointing towards classical work recent advance nonconvex optimization machine learning used semesterlength course basic nonconvex optimization application machine learning hand also possible cherry pick inidual portion chapter sparse recovery em algorithm inclusion broader course several course machine learning optimization signal processing may benefit inclusion topic ,1
ML_5,neurosymbolic programming emerging area bridge area deep learning program synthesis classical machine learning goal learn function data however function represented program neural module addition symbolic primitive induced combination symbolic search gradientbased optimization neurosymbolic programming offer multiple advantage endtoend deep learning program sometimes naturally represent longhorizon procedural task difficult perform deep network neurosymbolic representation also commonly easier interpret formally verify neural network restriction programming language serve form regularization lead generalizable dataefficient learning compositional programming abstraction also natural way reusing learned module across learning task monograph author illustrate potential benefit concrete example recent neurosymbolic programming also categorize way symbolic neural learning technique come together area conclude discussion technical challenge field comprehensive neurosymbolic programming introduces reader topic provides insightful treatise increasingly important topic intersection programming language machine learning p learning verification ,1
ML_6,similarity object play important role human cognitive process artificial system recognition categorization appropriately measure similarity given crucial performance many machine learning pattern recognition data mining method book devoted metric learning set technique automatically learn similarity distance function data attracted lot interest machine learning related field past ten year book provide thorough metric learning literature cover algorithm theory application numerical structured data first introduce relevant definition classic metric function well example machine learning data mining wide range metric learning algorithm starting simple setting linear distance similarity learning show one may scaleup method large amount training data go beyond linear case discus method learn nonlinear metric multiple linear metric throughout feature space method complex setting multitask semisupervised learning although existing focused numerical data cover literature metric learning structured data like string tree graph time series technical part book recent statistical framework analyzing generalization performance metric learning derive result algorithm presented earlier finally illustrate relevance metric learning realworld problem series successful application computer vision bioinformatics information retrieval ,1
ML_7,learning rank refers machine learning technique training model ranking learning rank useful many application information retrieval natural language processing data mining intensive study conducted problem recently significant progress made lecture give introduction area including fundamental problem existing approach theory application future author begin showing various ranking problem information retrieval natural language processing formalized two basic ranking task namely ranking creation simply ranking ranking aggregation ranking creation given request one want generate ranking list offering based feature derived request offering ranking aggregation given request well number ranking list offering one want generate ranking list offering ranking creation ranking major problem learning rank usually formalized supervised learning author give detailed explanation learning ranking creation ranking aggregation including training testing evaluation feature creation major approach many method proposed ranking creation method categorized pointwise pairwise listwise approach according loss function employ also categorized according technique employ svm based boosting svm neural network based approach author also introduces popular learning rank method detail include prank oc svm ranking svm ir svm gbrank ranknet lambdarank listnet & amp listmle adarank svm map softrank borda count markov chain cranking author explains several example application learning rank including web search collaborative filtering definition search keyphrase extraction query dependent summarization reranking machine translation formulation learning ranking creation given statistical learning framework ongoing future research direction learning rank also discussed table content introduction learning ranking creation learning ranking aggregation method learning rank application learning rank theory learning rank ongoing future ,1
ML_8,hilbert space embedding distribution���in short kernel mean embedding���has recently emerged powerful tool machine learning statistical inference basic idea behind framework map distribution reproducing kernel hilbert space rkhs whole arsenal kernel method extended probability measure viewed generalization original feature map common support vector machine svms kernel method addition classical application kernel method kernel mean embedding found novel application ���elds ranging probabilistic modeling statistical inference causal discovery deep learning kernel mean embedding distribution beyond provides comprehensive existing recent advance research area discus challenging issue problem could potentially lead research direction targeted audience includes graduate student researcher machine learning statistic interested theory application kerne,1
ML_9,among data structure commonly used machine learning graph arguably one general graph allow modelling complex object annotated metadata nonetheless seemingly simple question determining whether two graph identical whether one graph contained another graph remarkably hard solve practice machine learning method operating graph must therefore grapple need balance computational tractability ability leverage much information conveyed graph possible last year numerous graph kernel proposed solve problem thereby making possible perform prediction classification regression setting monograph provides existing graph kernel application software plus data resource empirical comparison stateoftheart graph kernel ided two part first part focus theoretical description common graph kernel second part focus largescale empirical evaluation graph kernel well description desirable property requirement benchmark data set finally author outline future trend challenge graph kernel written every researcher practitioner student machine learning graph kernel provides comprehensive insightful survey various graph kernals available today give reader detailed typology analysis relevant graph kernel exposing relation commenting applicability specific data type also largescale empirical evaluation graph kernel ,1
ML_10,learning rank information retrieval introduction field learning rank hot research topic information retrieval machine learning categorizes stateoftheart learningtorank algorithm three approach unified machine learning perspective describes loss function learning mechanism different approach reveals relationship difference show empirical performance real ir application discus theoretical property generalization ability tutorial learning rank information retrieval help people find answer following critical question respect learningtorank algorithm similar aspect differ ? strength weakness algorithm ? learningtorank algorithm empirically performs best ? ranking machine learning problem ? unique theoretical issue ranking compared classification regression ? learning rank information retrieval guide beginner embarking research area useful reference established researcher practitioner ,1
ML_11,active learning protocol supervised machine learning learning algorithm sequentially request label selected data point large pool unlabeled data contrast passive learning labeled data taken random objective active learning produce highlyaccurate classifier ideally fewer label number random labeled data sufficient passive learning achieve theory disagreementbased active learning describes recent advance understanding theoretical benefit active learning implication design effective active learning algorithm much monograph focus particular technique namely disagreementbased active learning amassed mature coherent literature also briefly survey several alternative approach literature emphasis theorem regarding performance general algorithm including rigorous proof appropriate however presentation intended pedagogical focusing result illustrate fundamental idea rather obtaining strongest generally known theorem theory disagreementbased active learning intended researcher advanced graduate student machine learning statistic interested gaining deeper understanding recent ongoing development theory active learning ,1
ML_12,asynchronous sequential machine design analysis provides lucid indepth treatment asynchronous state machine design analysis presented two part part background fundamental related asynchronous sequential logic circuit generally part ii selftimed system highperformance asynchronous programmable sequencer arbiter part provides detailed background fundamental design analysis asynchronous finite state machine fsms included basic model fully documented state diagram design characteristic basic memory cell muller celements simple fsms celements illustrate design process detection elimination timing defect asynchronous fsms covered detail followed array algebraic approach design singletransitiontime machine cad software onehot asynchronous fsms pulse mode fsms part concludes analysis procedure asynchronous state machine part ii concerned mainly selftimed system programmable sequencer arbiter begin detailed treatment externally asynchronousinternally clocked pausable system delayinsensitive metastabilityhardened followed defectfree cascadable asynchronous sequencer defectfree onehot asynchronous programmable sequencerstheir characteristic design application part ii concludes arbiter module various type without metastability protection together application presented appendix brief review covering mixedlogic gate symbology boolean algebra enteredvariable kmap minimization endofchapter problem glossary term expression abbreviation contribute reader learning experience five productivity tool made available specifically text briefly discussed preface table content background fundamental design analysis asynchronous state machine introduction background simple fsm design initialization detection elimination timing defect asynchronous fsms design single transition time machine design onehot asynchronous fsms design pulse mode fsms analysis asynchronous fsms ii selftimed system programmable sequencer arbiter externally asynchronousinternally clocked system cascadable asynchronous programmable sequencer cap timeshared system design asynchronous onehot programmable sequencer system arbiter module ,1
ML_13,wealth literature book available engineer starting understand machine learning used everyday present problem engineer start answer often general slightly outdated introduction read book detailed survey method based probabilistic model check reference learn statistical learning text useful monograph provides starting point literature every engineer machine learning need offer basic compact reference describes key idea principle simple term unified treatment encompassing recent development pointer literature brief introduction machine learning engineer entry point machine learning student practitioner researcher engineering background probability linear algebra ,1
ML_14,submodular function relevant machine learning least two reason problem may expressed directly optimization submodular function lov��sz extension submodular function provides useful set regularization function supervised unsupervised learning learning submodular function convex optimization perspective theory submodular function presented selfcontained way convex analysis perspective presenting tight link certain polyhedron combinatorial optimization convex optimization problem particular describes submodular function minimization equivalent solving wide variety convex optimization problem allows derivation efficient algorithm approximate exact submodular function minimization theoretical guarantee good practical performance listing many example submodular function review various application machine learning clustering experimental design sensor placement graphical model structure learning subset selection well family structured sparsityinducing norm derived used submodular function learning submodular funn convex optimization perspective ideal reference researcher scientist engineer interest applying submodular function machine learning problem ,1
ML_15,machine learning deliver ai ? theoretical result inspiration brain cognition well machine learning experiment suggest order learn kind complicated function represent highlevel abstraction eg vision language ailevel task one would need deep architecture deep architecture composed multiple level nonlinear operation neural net many hidden layer graphical model many level latent variable complicated propositional formula reusing many subformulae level architecture represents feature different level abstraction defined composition lowerlevel feature searching parameter space deep architecture difficult algorithm discovered subarea emerged machine learning community since following discovery learning algorithm deep belief network related unsupervised learning algorithm recently proposed train deep architecture yielding exciting result beating stateoftheart certain area learning deep architecture ai discus motivation principle learning algorithm deep architecture analyzing comparing recent result different learning algorithm deep architecture explanation success proposed discussed highlighting challenge suggesting avenue future exploration area ,1
ML_16,term federated learning coined recently describe machine learning setting multiple entity collaborate solving machine learning problem coordination central server provider client raw data stored locally exchanged transferred instead focused update intended immediate aggregation used achieve learning objective since topic gathered much interest across many different discipline realization solving many interdisciplinary problem likely requires machine learning technique distributed optimization cryptography security differential privacy fairness compressed sensing system information theory statistic monograph contribution leading expert across discipline describe latest stateofthe art perspective contribution carefully curated comprehensive treatment enables reader understand done get pointer effort required solve many problem federated learning become reality practical system researcher working area distributed system find monograph enlightening read may inspire many challenging issue outlined monograph get reader speed quickly easily likely become increasingly important topic federated learning ,1
ML_17,past decade number hardware software advance conspired thrust deep learning neural network forefront computing deep learning created qualitative shift conception software every day seeing application deep learning healthcare art feel like scratching surface universe possibility book offer first introduction foundational idea automated verification applied deep neural network deep learning ided three part part defines neural network dataflow graph operator realvalued input part discus constraintbased technique verification part discus abstractionbased technique verification book selfcontained treatment topic sits intersection machine learning formal verification serve introduction field firstyear graduate student senior undergraduate even exposed deep learning verification ,1
ML_18,author monograph survey recent progress spectral method including matrix tensor decomposition technique learn many popular latent variable model careful implementation tensorbased method run efficiently practice many case algorithm provable guarantee running time sample complexity focus special type tensor decomposition called cp decomposition author cover wide range algorithm find component tensor decomposition also discus usefulness decomposition reviewing several probabilistic model learned tensor method second half monograph look practical application includes tensorly efficient tensor algebra software package simple python interface expressing tensor operation also flexible backend system supporting numpy pytorch tensorflow mxnet spectral learning matrix tensor provides theoretical practical introduction designing deploying spectral learning matrix tensor interest student researcher practitioner working modern day machine learning problem ,1
ML_19,support vector machine become well established tool machine learning well practice used across wide range application recognizing handwritten digit face identification text categorisation bioinformatics database marketing book give introductory overview subject start simple support vector machine performing binary classification considering multiclass classification learning presence noise show framework extended many scenario prediction realvalued output novelty detection handling complex output structure parse tree finally give overview type kernel used practice learn make prediction multiple type input data table content support vector machine classification kernelbased model learning kernel ,1
ML_20,many problem recent interest statistic machine learning posed framework convex optimization due explosion size complexity modern datasets increasingly important able solve problem large number feature training example result decentralized collection storage datasets well accompanying distributed solution method either necessary least highly desirable distributed optimization statistical learning via alternating direction method multiplier argues alternating direction method multiplier well suited distributed convex optimization particular largescale problem arising statistic machine learning related area method developed root equivalent closely related many algorithm dual decomposition method multiplier douglasrachford splitting spingarns method partial inverse dykstras alternating projection bregman iterative algorithm ? problem proximal method others briefly surveying theory history algorithm discus application wide variety statistical machine learning problem recent interest including lasso sparse logistic regression basis pursuit covariance selection support vector machine many others also discus general distributed optimization extension nonconvex setting efficient implementation including detail distributed mpi hadoop mapreduce implementation ,1
ML_21,monograph provides overview bandit algorithm inspired various aspect information retrieval ir click model online ranker evaluation personalization coldstart problem survey style chapter focus specific ir problem explains addressed various bandit approach section algorithm presented chronological order monograph show specific concept related bandit algorithm comprehensive chronological approach enables author explain impact ir development bandit algorithm well impact bandit algorithm development method ir survey primarily intended two group reader researcher information retrieval machine learning practicing data scientist accessible anyone completed introductory intermediate level course machine learning andor statistic ,1
ML_22,key strategy machine learning break problem smaller manageable part process data unknown variable recursively sequential monte carlo smc technique solving statistical inference problem recursively last year smc developed enabled inference increasingly complex challenging model signal processing statistic monograph show powerful technique applied machine learning problem probabilistic programming variational inference inference evaluation name written tutorial style element sequential monte carlo introduces basic smc discus practical issue review theoretical result guiding reader series advanced topic give complete overview topic application machine learning problem monograph provides accessible treatment researcher topic recently gained significant interest machine learning community ,1
ML_23,scalable efficient distributed learning one driving force behind recent rapid advancement machine learning artificial intelligence one prominent feature development recent progress made researcher two community system community database data management distributed system machine learning mathematical optimization community interaction knowledge sharing two community led rapid development distributed learning system theory monograph provides brief introduction three distributed learning technique recently developed lossy communication compression asynchronous communication decentralized communication significant impact system machine learning mathematical optimization community fully realize potential essential understand whole picture monograph provides bridge two community simplified introduction essential aspect community enables researcher gain insight factor influencing monograph provides student researcher groundwork developing faster better research result dynamic area research ,1
ML_24,adaptation learning optimization network deal topic information processing graph presentation largely selfcontained cover result relate analysis design multiagent network distributed solution optimization adaptation learning problem streaming data localized interaction among agent result derived monograph useful comparing network topology comparing networked solution centralized batch implementation many good reason peaked interest distributed implementation especially day age word network become commonplace whether one referring social network power network transportation network biological network type network reason benefit cooperation term improved performance improved resilience failure reason deal privacy secrecy consideration agent may comfortable sharing data remote fusion center situation data may already available dispersed location happens cloud computing one may also interested learning data mining big data set motivated consideration adaptation learning optimization network examines limit performance distributed solution discus procedure help bring forth potential fully adaptation learning optimization network adopts useful statistical framework derives performance result elucidate meansquare stability convergence steadystate behavior learning network time monograph illustrates distributed processing graph give rise revealing phenomenon due coupling effect among agent phenomenon discussed context adaptive network example variety area including distributed sensing intrusion detection distributed estimation online adaptation network system theory machine learning ,1
ML_25,development influenced field computer vision last decade introduction statistical machine learning technique particularly kernelbased classifier support vector machine become indispensable tool providing unified framework solving wide range imagerelated prediction task including face recognition object detection action classification emphasizing geometric intuition kernel method rely kernel method computer vision provides introduction kernelbased machine learning technique accessible wide audience including student researcher practitioner alike without sacrificing mathematical correctness cover support vector machine also le known technique kernelbased regression outlier detection clustering dimensionality reduction additionally offer outlook recent development kernel method yet made regular textbook structured prediction dependency estimation learning kernel function topic illustrated example successful application computer vision literature making kernel method computer vision useful guide wanting understand working principle kernel method also anyone wanting apply reallife problem ,1
ML_26,determinantal point process dpps elegant probabilistic model repulsion arise quantum physic random matrix theory contrast traditional structured model like markov random field become intractable hard approximate presence negative correlation dpps offer efficient exact algorithm sampling marginalization conditioning inference task studied extensively mathematician giving rise deep beautiful theory dpps relatively machine learning determinantal point process machine learning provides comprehensible introduction dpps focusing intuition algorithm extension relevant machine learning community show dpps applied realworld application like finding erse set highquality search result building informative summary selecting erse sentence document modeling nonoverlapping human pose image video automatically building timeline important news story present general mathematical background dpps range modeling extension efficient algorithm theoretical result aim enable practical modeling learning ,1
ML_27,lie group machine learning recognized theoretical basis brain intelligence brain learning higher machine learning higher artificial intelligence sample set lie group matrix widely available practical application lie group learning vibrant field increasing importance extraordinary potential thus need developed aim provide comprehensive survey recent advance lie group machine learning introduce lie group machine learning technique three major category supervised lie group machine learning semisupervised lie group machine learning unsupervised lie group machine learning addition introduce special application lie group machine learning image processing cover following technique lie group machine learning model lie group subspace orbit generation learning symplectic group learning quantum group learning lie group fiber bundle learning lie group cover learning lie group deep structure learning lie group semisupervised learning lie group kernel learning tensor learning frame bundle connection learning spectral estimation learning finsler geometric learning homology boundary learning category representation learning neuromorphic synergy learning overall survey aim provide insightful overview stateoftheart development field lie group machine learning enable researcher comprehensively understand state field identify appropriate tool particular application identify direction future research ,1
ML_28,key idea behind active learning machine learning algorithm perform better le training allowed choose data learns active learner may pose query usually form unlabeled data instance labeled oracle eg human annotator already understands nature problem sort approach wellmotivated many modern machine learning data mining application unlabeled data may abundant easy come training label difficult timeconsuming expensive obtain book general introduction active learning outline several scenario query might formulated detail many query selection algorithm organized four broad category query selection framework also touch theoretical foundation active learning conclude overview strength weakness approach practice including summary ongoing address challenge opportunity table content automating inquiry uncertainty sampling searching hypothesis space minimizing expected error variance exploiting structure data theory practical consideration ,1
ML_29,recent year decision forest established one promising technique machine learning computer vision medical image analysis book directed engineer phd student wish learn basic decision forest well senior researcher wish push state art automated image understanding author present unified efficient model random decision forest used number application scene recognition photograph object recognition image automatic diagnosis radiological scan document analysis application traditionally addressed different supervised unsupervised machine learning technique contrast cast erse task regression classification semisupervised learning instance general decision forest model flexibility forest framework extends task density estimation manifold learning semisupervised learning unified forest framework give u opportunity implement optimize underlying algorithm easily adapt inidual application relatively small change theoretical basis numerous explanatory example presented book serve solid platform upon build exciting future research ,1
ML_30,robot intelligent agent move simple environment problem complex unstructured setting manually programming behavior become increasingly challenging expensive often easier teacher demonstrate desired behavior rather attempt manually engineer process learning demonstration algorithm called imitation learning algorithmic perspective imitation learning provides reader introduction imitation learning cover underlying assumption approach relate rich set algorithm developed tackle problem advice effective tool implementation algorithmic perspective imitation learning serf two audience first familiarizes machine learning expert challenge imitation learning particularly arising robotics interesting theoretical practical distinction familiar framework like statistical supervised learning theory reinforcement learning second provides roboticists expert applied artificial intelligence broader appreciation framework tool available imitation learning pay particular attention intimate connection imitation learning approach structured prediction ,1
ML_31,matching measure relevance document query interest item key problem search recommendation machine learning exploited address problem effort made develop deep learning technique matching task search recommendation availability large amount data powerful computational resource advanced deep learning technique deep learning matching becomes stateoftheart technology search recommendation key success deep learning approach strong ability learning representation generalization matching pattern data survey give systematic comprehensive introduction deep matching model search recommendation first give unified view matching search recommendation solution two field compared one framework survey categorizes current deep learning solution two type method representation learning method matching function learning fundamental problem well stateoftheart solution querydocument matching search useritem matching recommendation described deep learning matching search recommendation aim help researcher search recommendation community get indepth understanding insight space stimulate idea discussion promote development technology matching limited search recommendation technology introduced generalized general matching object two space ,1
ML_32,aim tutorial lecture show role machine learning airelated technique embodied autonomous agent autonomous robot particular tutorial bring forefront aspect robotics closely related computer science believe progress algorithm data processing method together rapid increase available computing power driving force behind success modern robotics last decade period robot various class migrated university laboratory commercial company everyday life everybody buy autonomous vacuum cleaner lawnmower selfdriving car drone good delivery waiting proper legal regulation enter market robotics artificial intelligence already went long path mutual inspiration common development starting symbolic ai aka good oldfashioned artificial intelligence extensive early autonomous robot shakey robot created sri international nil nilsson considered one father modern ai briefly characterize range important application typical ai method modern robotics including motion planning algorithm interpretation sensory data leading creation world model classical learning method reinforcement learning however made robotics part wave ai application recent revolution machine learning mostly grounded enormous success deep learning paradigm many variant proved outclass classic method broad range problem related processing image type signal quick adoption recent advance machine learning ml robotics seems motivated fact ml give possibility infer solution data opposed classic modelbased paradigm decade used robotics whereas modelbased solution mathematically elegant theoretically provable respect stability convergence etc often fail confronted realworld problem real sensory data underlying mathematical model rough approximation real world therefore wider adoption ml robotics give chance make robot robust adaptive hand try technique without discarding knowledge expertise already machine learning method benefit lot prior knowledge known structure problem solved learning knowledge structure adopted modelbased method already wellestablished robotics lecture robot understood broad sense embodied agent mean physically interact environment either manipulator mobile robot aerial vehicle selfdriving car various smart device sensor second part lecture attention paid specific problem appear application machine learning embodied agent need search solution huge multidimensional space curse dimensionality everpresent problem representation incorporation uncertainty processing realworld data example application autonomous robot given successful due ai particular probabilistic representation knowledge machine learning prominent example darpa competition grand challenge urban challenge robotics challenge drc amazon picking challenge prof interest large corporation development aibased robotics third part lecture research direction offered machine learning increased availability training data discussed overview popular application area ml robotics autonomous system presented typical machine learning paradigm applied area focus deep learning mostly convolutional neural network process various sensory data discus three aspect embodied agent make machine learning robotics quite specific respect application area medical image natural language processing first aspect dealing world autonomous robot usually operate situation break assumption underlying popular ml method creates need face problem unknown class identification incremental learning uncertainty sensory data also stress embodied agent ability actively acquire information second aspect inference scene seen agent case robotics semantics geometry intermingle robot threedimensional world although often perceives twodimensional image third aspect analysis related important feature robot distinguishes learning agent softwarebased robot embodied agent physical body subject physical constraint maximum speed motion maximum range perception therefore ml robot analysis spatiotemporal dependency data important robot support advanced learning method thanks possibility interaction environment simple example active vision moving camera much complex one manipulation active testing behavior object repositioning pushing end lecture context specific need limitation characteristic application ml robotics concept machine learning eg deep reinforcement learning interactive perception presented lecture summarized brief discussion important challenge problem ml applied embodied agent ,1
ML_33,nowadays selection range alpha factor gradually narrowing excess return alpha also declining fortunately problem machine learning especially deep learning show many advantage excellent characteristic make machine learning likely become important tool obtain excess return future article three machine learning algorithm support vector machine adaptive boosting neural network discussed various algorithm derived evolved basis three algorithm three machine learning algorithm summarized analyzed according derivation law machine learning algorithm based original linear simple algorithm support vector machine forecast data adding different dimension learning ability sample complexity complementary accuracy reduced case sample complexity adaptive boost adaptive boosting evolved decision tree inclined improvement learning ability improves accuracy prediction ability solve complex sample limited neural network simulates human neuron construction solve large number complex sample data also high learning ability solves defect support vector machine adaptive boost summarizing representative algorithm different evolution stage machine learning algorithm neural network predict performance stock well find accurate alpha factor greater development prospect application space growing stock market ,1
ML_34,emerging application imaging machine learning must perform immense amount computation holding strict limit energy power meet goal architect building increasingly specialized compute engine tailored specific task resulting computer system heterogeneous containing multiple processing core wildly different execution model unfortunately cost producing specialized hardware���and software control it���is astronomical moreover porting algorithm heterogeneous machine typically requires algorithm partitioned across machine rewritten specific architecture time consuming prone error last several year author approached problem domainspecific language dsl highlevel programming language customized specific domain database manipulation machine learning image processing giving generality language able provide highlevel abstraction developer producing high performance output book spur adoption creation domainspecific language especially creating hardware design first chapter short historical journey explains forceputer architecture today chapter describes various method producing design accelerator outlining push abstraction tool enable designer higher conceptual level chapter provides brief introduction image processing algorithm hardware design pattern implementing chapter describe compare darkroom halide two domainspecific language created image processing produce highperformance design fpgas cpu source code enabling rapid design cycle quick porting algorithm final section describes dsl approach also simplifies problem interfacing application code accelerator generating driver stack addition accelerator configuration book serve useful introduction domainspecialized computing computer architecture student primer domainspecific language image processing hardware experience field ,1
ML_35,semantic matching search systematic detailed introduction newly developed machine learning technology query document matching semantic matching search particularly web search focus fundamental problem well stateoftheart solution query document matching form aspect phrase aspect word sense aspect topic aspect structure aspect matching query document limited search similar problem found question answering online advertising crosslanguage information retrieval machine translation recommender system link prediction image annotation drug design application one faced general matching object two different space technology introduced monograph generalized general machine learning technique referred learning match survey hoped idea solution explained semantic matching search may motivate industrial practitioner turn research result product method introduced discussion around also stimulate academic researcher find research direction approach ,1
ML_36,common feature many approach modeling sensory statistic emphasis capturing average early representation brain highly abstracted class category machine learning classification task centraltendency model based gaussian distribution seemingly natural obvious choice modeling sensory data however insight neuroscience psychology computer vision suggest alternate strategy preferentially focusing representational resource extreme distribution sensory input notion treating extremum near decision boundary feature necessarily comprehensive statistical theory recognition based extremum emerging computer vision literature book begin introducing statistical extreme value theory evt visual recognition contrast centraltendency modeling hypothesized distribution near decision boundary form powerful model recognition task focusing coding resource data arguably diagnostic feature evt several important property strong statistical grounding better modeling accuracy near decision boundary gaussian modeling ability model asymmetric decision boundary accurate prediction probability event beyond experience second part book us theory describe class machine learning algorithm decision making measurable advance beyond stateoftheart includes method postrecognition score analysis information fusion multiattribute space calibration supervised machine learning algorithm ,1
ML_37,book aimed providing overview several aspect semantic role labeling chapter begin linguistic background definition semantic role controversy surrounding chapter describes theory led structured lexicon framenet verbnet propbank frame file turn provide basis large scale semantic annotation corpus data facilitated development automatic semantic role labeling system based supervised machine learning technique chapter present general principle applying supervised unsupervised machine learning description standard stage feature choice well giving detail several specific system recent advance include joint inference take advantage context sensitivity attempt improve performance closer integration syntactic parsing semantic role labeling chapter also discus impact granularity semantic role system performance outlined basic approach respect english chapter go discus applying technique language chinese primary example although substantial training data available chinese case many language technique projecting english role label onto parallel corpus also presented table content preface semantic role available lexical resource machine learning semantic role labeling crosslingual perspective summary ,1
ML_38,regression analysis key area interest field data analysis machine learning devoted exploring dependency variable often vector emergence high dimensional data technology neuroimaging computer vision climatology social network brought challenge traditional data representation method tensor high dimensional extension vector considered natural representation high dimensional data book author provide systematic analysis tensorbased regression model application recent year group illustrates existing tensorbased regression method cover basic core idea theoretical characteristic tensorbased regression method addition reader learn existing tensorbased regression method solve specific regression task multiway data datasets selected software package available start related soon possible tensor regression first thorough overview fundamental motivation popular algorithm strategy efficient implementation related application available datasets software resource tensorbased regression analysis essential reading student researcher practitioner working high dimensional data ,1
ML_39,ensemble method called influential development data mining machine learning past decade combine multiple model one usually accurate best component ensemble provide critical boost industrial challenge investment timing drug discovery fraud detection recommendation system predictive accuracy vital model interpretability ensemble useful modeling algorithm book focus decision tree explain clearly describing tree strength weakness author provide overview regularization today understood key reason superior performance modern ensembling algorithm book continues clear description two recent development importance sampling rule ensemble reveals classic ensemble method bagging random forest boosting special case single algorithm thereby showing improve accuracy speed re linear rule model derived decision tree ensemble interpretable version ensemble essential application credit scoring fault diagnosis lastly author explain paradox ensemble achieve greater accuracy data despite apparently much greater complexity book aimed novice advanced analytic researcher practitioner especially engineering statistic computer science little exposure ensemble learn employ breakthrough method advanced practitioner gain insight building even powerful model throughout snippet code r provided illustrate algorithm described encourage reader try technique author industry expert data mining machine learning also adjunct professor popular speaker although early pioneer discovering ensemble distill clarify recent groundbreaking leading academic jerome friedman bring benefit ensemble practitioner table content ensemble discovered predictive learning decision tree model complexity model selection regularization importance sampling classic ensemble method rule ensemble interpretation statistic ensemble complexity ,1
ML_40,people make sense text identifying semantic relation connect entity concept described text system aspires humanlike performance must also equipped identify learn semantic relation text process understanding even simple sentence opportunity curiosity find similar rock mar requires recognizing relation rock located mar signalled word drawing already known relation opportunity curiosity instance class mar rover languageunderstanding system able find relation document progressively build knowledge base even ontology resource kind assist continuous learning advanced languageprocessing task text summarization question answering machine translation book discus recognition text semantic relation capture interaction base noun phrase brief historical background introduce range relation inventory varying granularity proposed computational linguist also variation scale system operate snippet way whole web technique recognizing relation text full supervision weak distant supervision selfsupervised completely unsupervised method discussion supervised learning cover available datasets feature set describe relation instance successful algorithm overview weakly supervised unsupervised learning zoom acquisition relation large corpus hardly annotated data show bootstrapping seed example pattern scale large text collection web also machine learning technique data redundancy variability lead fast reliable relation extraction ,1
ML_41,introduction online convex optimization portrays optimization process many practical application environment complex infeasible lay comprehensive theoretical model classical algorithmic theory mathematical optimization necessary well beneficial take robust approach applying optimization method learns one go learning experience aspect problem observed view optimization process become prominent varied field led spectacular success modeling system part daily life introduction online convex optimization intended serve reference selfcontained course online convex optimization convex optimization approach machine learning educated graduate student computer scienceelectrical engineering operation researchstatistics related field also ideal reference researcher ing fascinating world intersection optimization machine learning ,1
ML_42,bthis book provides comprehensive introduction conversational aib idea interacting computer voice text go back long way recent year idea become reality emergence digital personal assistant smart speaker chatbots advance ai particularly deep learning availability massive computing power vast amount data led generation dialogue system conversational interface current research conversational ai focus mainly application machine learning statistical datadriven approach development dialogue system however important aware previous achievement dialogue technology consider extent might relevant current research development three approach development dialogue system reviewed rulebased system handcrafted best practice guideline statistical datadriven system based machine learning neural dialogue system based endtoend learning evaluating performance usability dialogue system become important topic right variety evaluation metric framework described finally number challenge future research considered including multimodality dialogue system visual dialogue data efficient dialogue model learning knowledge graph discourse dialogue phenomenon hybrid approach dialogue system development dialogue social robot internet thing social ethical issue ,1
ML_43,kernel method among popular technique machine learning regularization theory perspective provide natural choice hypothesis space regularization functional notion reproducing kernel hilbert space probabilistic theory perspective key context gaussian process kernel function known covariance function theory kernel method singlevalued function well established indeed considerable amount devoted designing learning kernel recently increasing interest method deal multiple output motivated partly framework like multitask learning application kernel vectorvalued function include sensor network geostatistics computer graphic several kernel vectorvalued function look different method design learn valid kernel function multiple output paying particular attention connection probabilistic regularization method kernel vectorvalued function aimed researcher interest theory application kernel vectorvalued function area statistic computer science engineering one goal provide unified framework common terminology researcher working machine learning statistic ,1
ML_44,online learning well established learning paradigm theoretical practical appeal goal online learning make sequence accurate prediction given knowledge correct answer previous prediction task possibly additional available information online learning studied several research field including game theory information theory machine learning also became great interest practitioner due recent emergence large scale application online advertisement placement online web ranking online learning online convex optimization modern overview online learning aim provide reader sense interesting idea particular underscore centrality convexity deriving efficient online learning algorithm connects relates result online convex optimization classic result online classification thus providing fresh modern perspective classic algorithm intended comprehensive rather give highlevel rigorous yet easy follow survey topic ,1
ML_45,property testing learning theory perspective take learningtheory point view property testing focus result testing property function interest learning theory community particular cover result testing algebraic property function linearity testing property defined concise representation small dnf representation property testing learning theory perspective start preliminary including precise statement proof simple important observation testing harder learning go consider first type property studied context property testing algebraic property include testing whether function multilinear generally whether polynomial bounded degree turn function class concise propositional logic representation singleton monomials small dnf formula proceeds discus distribution free testing testing random example alone finally contains brief survey result property testing include testing monotonicity testing clustering testing property distribution property testing learning theory perspective ideal text anybody interest property testing connects topic machine learning ,1
ML_46,many modern technique solve supervised learning problem suffer lack interpretability analyzability give rise rigorous mathematical result monograph develops comprehensive statistical learning framework us distributionally robust optimization dro wasserstein metric ensure robustness perturbation data author introduce reader fundamental property wasserstein metric dro formulation explaining theory detail application cover series learning problem including distributionally robust linear regression ii distributionally robust regression group structure predictor iii distributionally robust multioutput regression multiclass classification iv optimal decision making combine distributionally robust regression nearestneighbor estimation v distributionally robust semisupervised learning vi distributionally robust reinforcement learning throughout monograph author application medicine health care illustrate theoretical idea practice include numerical experiment case study synthetic real data distributionally robust learning provides detailed insight technique gained lot recent interest developing robust supervised learning solution founded sound mathematical principle enlightening researcher practitioner student working optimization machine learning system ,1
ML_47,human language acquisition studied century computational modeling study relatively recent trend however computational approach language learning become increasingly popular mainly due advance developing machine learning technique availability vast collection experimental data child language learning childadult interaction many existing computational model attempt complex learning language cognitive plausibility criterion memory processing limitation human face explain developmental stage observed child simulating process child language learning computational model show u linguistic representation learnable input child access mechanism yield pattern behaviour child exhibit process computational modeling provides insight plausible mechanism involved human language acquisition inspires development better language model technique book provides overview research question field human language acquisition review commonly used computational framework methodology resource modeling child language learning evaluation technique used assessing computational model book aimed cognitive scientist want become familiar available computational method investigating problem related human language acquisition well computational linguist interested applying skill child language acquisition different aspect language learning discussed separate chapter including acquisition inidual word general regularity govern word sentence form association form meaning aspect challenge discussed relevant empirical finding child summarized furthermore existing computational model attempt simulate reviewed number case study presented table content overview computational model language learning learning word putting word together formmeaning association final thought ,1
ML_48,industry demand smart analytics keep ahead two field namely machine learning deep learning play vital role machine learning evolved artificial intelligence deep learning evolved machine learning although deep learning show high end application computer vision natural language processing yet machine learning dominates business analytics algorithm survey show learning transition machine learning deep learning outlining different type machine learning model currently available also provides variety automatic machine learning tool used healthcare nowadays also enlightens deep learning method model challenge faced provide insight future deep learning machine learning deep learning healthcare application currently used investigated find technique process finally machine learning deep learning compared term learning ,1
ML_49,cybersecurity application machine learning algorithm increasingly used detect vulnerability somewhat unique challenge arises exploit targeting machine learning model constantly devised attacker traditional machine learning model longer robust reliable attack action reaction machine learning system adversary modeled game two player well���defined attack model game theory provide robustness guarantee machine learning model otherwise vulnerable application���time data corruption two case game theory���based machine learning technique one case player play zero sum game following minimax strategy case player play sequential game one player leader rest follower experimental result e���mail spam web spam datasets presented zero sum game demonstrate adversarial svm model built upon minimax strategy much resilient adversarial attack standard svm one���class svm model also show optimal learning strategy derived counter overly pessimistic attack model produce unsatisfactory result real atta demonstrate mixed strategy allowing player randomize available strategy best solution general without knowing type adversary machine learning application facing wild also discus scenario player behavior may derail rational decision making model consider decision risk ,1
ML_50,cloud platform provides multitenant software leased service therefore various participant software agent effectively conduct service automated machine learning pipeline show construct numerous softwareasaservice saas module platformasaservice paas delivered wellknown cloud provider achieve secured big data causal impact analytics given secured cloud provider still considered honestbutcurious adversary similar assumption also applied participant including data broker data user causal impact model builder user participant leverage software agent saas perspective provide machine learning pipeline service greatest research challenge integrate three type saas ie securityasaservice secasaservice machine learningasaservice mlasaservice data brokerasaservice dbasaservice achieve secured causal impact analytics cloud establish three type saas top aws gcp assume machine learning causal impact model data protected confidential proceed machine learning model training online testing causal impact analytics select machine learning algorithm integrate privacy secured data protection algorithm enable twophase machine learning process causalimpact model training online testing furthermore investigate effectively embed three type saas automated machine learning pipeline achieve secured machine learning causal impact analytics cloud ,1
ML_51,machine learning method achieved good performance widely applied various realworld application learn model adaptively better fit special requirement different task generally good machine learning system composed plentiful training data good model training process accurate inference many factor affect performance machine learning process among ersity machine learning process important one ersity help procedure guarantee totally good machine learning ersity training data ensures training data provide discriminative information model ersity learned model ersity parameter model ersity among different base model make parametermodel capture unique complement information ersity inference provide multiple choice corresponds specific plausible local optimal result even though ersity play important role machine learning process systematical analysis ersification machine learning system systematically summarize method make data ersification model ersification inference ersification machine learning process addition typical application ersity technology improved machine learning performance surveyed including remote sensing imaging task machine translation camera relocalization image segmentation object detection topic modeling others finally discus challenge ersity technology machine learning point direction future analysis provides deeper understanding ersity technology machine learning task hence help design learn effective model realworld application ,1
ML_52,recently many researcher intensely engaged investigation artificial intelligence technology recognizes learns inference act external information wide range field combining technology computing big data machine learning algorithm artificial intelligence technology currently used almost industry many machine learning expert working integrating standardizing various machine learning tool nonexperts easily apply domain researcher also studying autonomous machine learning well ontology construction standardizing machine learning concept classify typical problem solving step autonomous machine learning task problem solving process propose modeling method autonomous machine learning process execution machine learning workflow proposed ontologybased machine learning model defines taskbased process grouping scheme uml activity automatically generate extend machine learning model transformation rule based common element structure relationship process element ,1
ML_53,research full present pedagogy machine learning k learning pedagogy technology introduced aim enhancing student engagement experience learning outcome examined machine learning taught recent past explores way suitable approach k context literature pedagogy associated machine learning reviewed understand dynamic suitability pedagogy support machine learning teaching though study explored pedagogy machine learning higher education context study explored pedagogical strategy teaching machine learning k pedagogy employed teaching learning machine learning witnessed much research literature pedagogical strategy revealed literature mostly adopted higher education institution enable teaching machine learning concept literature survey revealed several pedagogical strategy problembased learning projectbased learning collaborative learning used higher education institution revealed pedagogy suggest learnerscentered approach active learning inquirybased participatory learning designoriented learning among others suitable teaching machine learning k setting ,1
ML_54,industrial application realtime manufacturing fault classification inference autonomous car etc datadriven application require machine learning wealth data generated industrial internet thing iot device however conventional approach transmitting rich data remote data center learn may undesired due nonnegligible network transmission delay sensitiveness data privacy deploying number computingcapable device network edge edge computing support implementation machine learning close industrial environment considering heterogeneous computing capability well network location edge device two type feasible edge computing based machine learning model including centralized learning federated learning model centralized learning resourcerich edge server aggregate data different iot device performs machine learning federated learning distributed edge device federated server collaborate perform machine learning feature data offloaded centralized learning locally trained federated learning make centralized learning federated learning quite different computation offloading problem edge computing based machine learning industrial environment considering abovementioned machine learning model formulate machine learningbased offloading problem goal minimizing training delay energyconstrained delaygreedy ecdg algorithm designed solve problem finally simulation study based mnist dataset conducted illustrate efficiency proposal ,1
ML_55,convenient access copious multifaceted data encouraged machine learning researcher reconsider correlationbased learning embrace opportunity causalitybased learning ie causal machine learning causal learning recent year therefore witnessed great effort developing causal learning algorithm aiming help ai achieve humanlevel intelligence due lackof groundtruth data one biggest challenge current causal learning research algorithm evaluation largely impedes crosspollination ai causal inference hinders two field benefit advance bridge conventional causal inference ie based statistical method causal learning big data ie intersection causal inference machine learning survey commonlyused datasets evaluation method measure causal learning evaluation pipeline similar conventional machine learning focus two fundamental causalinference task causalityaware machine learning task limitation current evaluation procedure also discussed examine popular causal inference toolspackages conclude primary challenge opportunity benchmarking causal learning algorithm era big data survey seek bring forefront urgency developing publicly available benchmark consensusbuilding standard causal learning evaluation observational data hope broaden discussion facilitate collaboration advance innovation application causal learning ,1
ML_56,machine learning method based optimization model constructing machine learning model minimizing loss function basic example express relation machine learning optimization growing number data increase dimension require sparse model order reduce computation cost sparse model computationally efective practice obtained zero norm one norm approximation nonconvex optimization model challenge appears nonconvexity structure problem recently learning algorithm based sparse model nonconvexity approximation gained interest literature talk give recent approximation sparse learning model exist literature specifically feature selection ensemble learning deep learning since ensemble learning aim aggregate accurate erse learner produce best final decision selecting best learning model ensemble becomes sparse learning similar feature selection algorithm connection deep learning sparse learning fashion explained throughout talk example methodology ongoing biomedical project bahcesehir university computer vision laboratory machine learning presented end talk ,1
ML_57,many application natural language processing involve performing texttotext transformation ie given text natural language input system required produce version text eg translation also natural language output automatically evaluating output system important component developing texttotext application two approach proposed problem compare system output one reference output string matchingbased evaluation metric ii build model based human feedback predict quality system output without reference text despite popularity referencebased evaluation metric faced challenge multiple good bad quality output produced texttotext approach input variation hard capture even multiple reference text addition referencebased metric used production eg online machine translation system system expected produce output unseen input book focus second set metric socalled quality estimation qe metric goal provide estimate good reliable text produced application without access goldstandard output qe enables different type evaluation target different type user application machine learning technique used build qe model various type quality label explicit feature learnt representation predict quality unseen system output book describes topic qe texttotext application covering quality label feature algorithm evaluation us stateoftheart approach focus machine translation application since represents qe done date also briefly describes qe several application including text simplification text summarization grammatical error correction natural language generation ,1
ML_58,casebased reasoning methodology long tradition artificial intelligence brings together reasoning machine learning technique solve problem based past experience case given problem solved reasoning involves method retrieve similar past case order reuse solution problem hand problem solved learning method applied improve knowledge based past experience spite broad methodology applied industry service casebased reasoning often forgotten artificial intelligence machine learning book aim book concise introduction casebased reasoning providing essential building block design casebased reasoning system well bring together research line field encourage student solve current cbr challenge ,1
ML_59,monte carlo method particular based markov chain interacting particle system tool routinely used machine learning method profound impact statistical inference wide range application area probabilistic model used moreover many algorithm machine learning based idea processing data sequentially first forward direction backward direction backward simulation method monte carlo statistical inference review branch monte carlo method based forwardbackward idea referred backward simulator recent year theory practice backward simulation algorithm undergone significant development algorithm keep finding application foundation method sequential monte carlo smc smcbased backward simulator capable addressing smoothing problem sequential latent variable model general nonlinearnongaussian statespace model ssms however book also clearly show underlying backward simulation idea mean restricted ssms furthermore backward simulation play important role recent development markov chain monte carlo mcmc method particle mcmc systematic way smc mcmc framework backward simulation give u way significantly improve performance sampler monograph discus several related backwardsimulationbased method state inference well learning static parameter frequentistic bayesian approach backward simulation method monte carlo statistical inference excellent primer anyone interested active research area ,1
ML_60,monograph provides tutorial family sequential learning decision problem known multiarmed bandit problem problem decision serf exploring exploiting balancing act exploration exploitation characteristic type learningonthego problem instantaneously apply learned far even continue learn author give indepth introduction technical aspect theory decisionmaking technology range comprehensive cover topic application many networking system include recommender system ad placement system smart grid clinical trial online learning method networking essential reading student working networking machine learning designer many networkbased system find valuable resource improving technology ,1
ML_61,recent year large amount multidisciplinary research conducted sparse model application statistic machine learning sparsity principle used perform model selectionthat automatically selecting simple model among large collection signal processing sparse coding consists representing data linear combination dictionary element subsequently corresponding tool widely adopted several scientific community neuroscience bioinformatics computer vision sparse modeling image vision processing provides reader selfcontained view sparse modeling visual recognition image processing specifically focus application dictionary learned adapted data yielding compact representation successful various context review large number application dictionary learning image processing computer vision present basic sparse estimation tool start historical tour sparse estimation signal processing statistic moving recent concept sparse recovery dictionary learning subsequently show dictionary learning related matrix factorization technique particularly effective modeling natural image patch consequence used tackling several image processing problem key component many stateoftheart method visual recognition sparse modeling image vision processing concludes presentation optimization technique make dictionary learning easy researcher expert field ,1
ML_62,image understanding playing increasingly crucial role several inverse problem computer vision sparse model form important component image understanding since emulate activity neural receptor primary visual cortex human brain sparse method utilized several learning problem ability provide parsimonious interpretable efficient model exploiting sparsity natural signal led advance several application area including image compression denoising inpainting compressed sensing blind source separation superresolution classification primary goal book theory algorithmic consideration sparse model image understanding computer vision application end algorithm obtaining sparse representation performance guarantee discussed initial chapter furthermore approach designing overcomplete dataadapted dictionary model natural image described development theory behind dictionary learning involves exploring connection unsupervised clustering analyzing generalization characteristic principle statistical learning theory exciting application area benefited extensively theory sparse representation compressed sensing image video data theory algorithm pertinent measurement design recovery modelbased compressed sensing presented paradigm sparse model suitably integrated powerful machine learning framework lead advance computer vision application object recognition clustering segmentation activity recognition framework enhance performance sparse model application imposing constraint based prior discriminatory information underlying geometrical structure kernelizing sparse coding dictionary learning method presented addition presenting theoretical fundamental sparse learning book provides platform interested reader explore vastly growing application domain sparse representation ,1
ML_63,aim combine technology virtual reality human machine interface application practical training mechatronics machine help user practical learning mechatronics without restriction time space mechatronics machine school limited learner take turn operation learning practical training result extremely long practice time selfdesigned human machine interface integrated virtual reality applied online offline monitoring mechatronics machine order solve teaching problem machinesa model mechatronics machine first established attached material assembled virtual reality software used establishing virtual scene machine motion human machine interface finally programmed monitor control virtual reality machine physical machine leaner offline model human machine interface could learn various device name machine operation procedure edition design control program online model human machine interface leaner could also learn remote online offline synchronous monitoring virtual real machine experimental result reveal leaner offline learning could rapidly familiarize operation real machine writing design control program would reduce training time cost personnel injury machine damage caused leaner careless operation control program error ,1
ML_64,machine learning applied every aspect people life especially field game machine gradually show set mechanism occupy certain position field alpha go lee sedol world champion go professional ninedan player manmachine battle go total score however generally game go chess classified game complete information game poker game incomplete information game incomplete information traditional algorithm longer applicable due lack information increase uncertainty independent algorithm system need studied first introduces application machine learning knowncomplete information game explains problem machine learning multiplayers known incomplete information game summarizes development machine learning field incomplete information game stage finally prospect future machine learning field game general machine learning still problem game incomplete information future generation need continue ,1
ML_65,traditional machine learning algorithm data database mutable therefore data fully trusted also machine learning process difficult automate proposes building trustable machine learning system blockchain technology store data permanent immutable way addition smart contract used automate machine learning process make three contribution first establishes link machine learning technology blockchain technology previously machine learning blockchain considered two independent technology without obvious link second proposes unified analytical framework trustable machine learning blockchain technology unified framework solves trustability automation issue machine learning third enables computer translate core machine learning implementation single thread single machine multiple thread multiple machine running blockchain unified approach us association rule mining example demonstrate trustable machine learning implemented blockchain show approach used analyze opioid prescription help combat opioid crisis ,1
ML_66,innovative practice workinprogress compare two different method teach machine learning concept undergraduate student electrical engineering machine learning offered seniorlevel elective several curriculum mean student exposed exposure concept practical application machine learning assist creation workforce ready tackle problem related machine learning currently hot topic industry end author working introducing electrical engineering student machine learning required juniorlevel signal system course challenge teaching machine learning juniorlevel course involves requiring student appreciate linkage complex concept linear algebra statistic optimization argued juniorlevel student seen concept topic requiring apply topic together challenge therefore order assist student better grasp concept provide handson activity since immersive experience help student appreciate practical us machine learning previous approach author held standalone workshop student class given android apps data collection followed different set handson activity approach showed promise several student indicated standalone workshop lacked context alleviate concern fall semester author tried different approach student provided handson activity sidebyside regular course content enabling link made machine learning throughout course providing better context content presented preliminary assessment indicate approach promotes student learning student prefer proposed sidebyside teaching approach numerical comparison show workshop approach may effective student learning indicating area required ,1
ML_67,given today context data saturation whereby data exist anyone know many employ machine learning technique treat machine learning algorithm oracle truth unreachable human mind decision boundary algorithm produce achieve wonderful performance testing often accepted inadequate causal justification assuming causal explanation attempted challenge noncausal approach machine learning good reason abandoning causal justification relying useful mathematical model make prediction attempted astronomy twothousand year ago model led fourteen century stagnation domain science inexplicable prediction failure approach also attempted domain science last twothousand year result samestagnation inexplicable prediction failure begin challenge noncausal approach machine learning root analyzing machine learning process reveal error inductive method shown machine learning algorithm employ inductive method relied upon learn valid generalization order avoid invalid inductive method necessary modification machine learning process presented assumes valid inductive method available form valid generalization machine learning algorithm employed valid method induction presented shown governed law causality turn defining feature causally valid classification proper approach searching feature leveraging machine learning algorithm finally example comparing contrasting traditional versus modified machine learning process presented illustrate power causal approach result practitioner modified machine learning process conscious control success domain reached valid generalization conscious control progress domain yet reach valid generalization ,1
ML_68,air pollution severe problem area population density high metropolitan city various type emission caused people action transportation power fuel affecting air quality machine learning component become key focus area company early stage startup major platform vendor machine learning field artificial intelligence device collect sensor data learns act one factor proposed research chosen learn forecast air quality index opportunity adapt machine learning algorithm air quality index device used determining air quality cause air pollution air pollution widely regarded concern india highest possible value considered fit medical service relatively higher daily air quality quantified attribute situation particularly bad larger city like delhi aqi reached alltime high air pollution control process carried federal government state government many researcher implement algorithm none compare performance across six algorithm single similar condition data portrays different strategy followed forecasting air quality index supervised machine learning procedure supervised machine learning technique smlt used analyze dataset capture multiple piece information including variable recognition univariate analysis bivariate multivariate analysis missing value treatment data analysis moreover estimation air quality index accomplished based pollutant causing effect viz pm pm co component used supervised machine learning procedureres compare air quality environment goal create machine learning model investigate air quality index predicting best result various machine learning algorithm based precision used logistic regression decision tree support vector machine random forest tree nave bayes theorem knearest neighbor six basic machine learning algorithm ,1
ML_69,machine learning subset artificial intelligenceai provides system ability learn automatically perform independently without programmed concentrating machine learning project choosing algorithm one important step machine learning algorithm math logic adjust training model performance come machine learning project choosing correct algorithm implementing model big developer doesnt choose suitable efficient algorithm program accuracy program decreased look machine learning algorithm solution approach fit several factor affect choosing machine learning algorithm number data type problem etc time developer chooses machine learning algorithm prior experience analyzing several past similar project however come beginner tough experience time beginner try several algorithmic approach implement model without understanding however avoid proper solution therefore research proposed nlp graph analyticsbased approach recommending machine learning algorithm project summary proposed solution analyzes past algorithm used machine learning project stored graph nlp based keyword analysis recommend suitable algorithmic approach input project idea natural language processing generates keywords project description thereafter system analyzes graph store past machine learning project used technology find suitable algorithmic approach user project moreover show proposed algorithm used past similar project therefore system developer get clear idea algorithm approach need choose ,1
ML_70,machine learning pervasively used wide range application due technical breakthrough recent year demonstrated significant success dealing various complex problem show capability close human even beyond human however recent study show machine learning model vulnerable various attack compromise security model application system moreover attack stealthy due unexplained nature deep learning model survey systematically analyze security issue machine learning focusing existing attack machine learning system corresponding defense secure learning technique security evaluation method instead focusing one stage one type attack cover aspect machine learning security training phase test phase first machine learning model presence adversary presented reason machine learning attacked analyzed machine learning securityrelated issue classified five category training set poisoning backdoor training set adversarial example attack model theft recovery sensitive training data threat model attack approach defense technique analyzed systematically demonstrate threat real concern physical world also reviewed attack realworld condition several suggestion security evaluation machine learning system also provided last future direction machine learning security also presented ,1
ML_71,machine learning relatively field deepening people research field application machine learning increasingly extensive hand development science technology image become indispensable medium information transmission image processing technology also booming introduces machine learning image processing study image processing technology based machine learning summarizes current popular image processing technology compare various image technology detail explains limitation image processing method addition basis image processing introduces machine learning algorithm applies convolution neural network feature extraction image processing carry simulation test test select voc dataset image segmentation imagenet dataset target detection cifar dataset image classification roc curve performance evaluation result show algorithm based deep learning achieve high accuracy image segmentation classification target detection accuracy image segmentation accuracy image classification accuracy target detection image processing based machine learning great advantage ,1
ML_72,encouraged growing computing power algorithmic development machine learning technology become powerful tool wide variety application area spanning agriculture chemistry natural language processing quantum system process classical data machine learning algorithm given rise emerging research area ie quantum machine learning despite origin processing classical data quantum machine learning also explores quantum phenomenon learning system quantum computer learning quantum data machine learning algorithm software formulated implemented quantum computer quantum machine learning transformational effect computer science may speed processing information well beyond existing classical speed recent seen development quantum algorithm could serve foundation machine learning application despite great promise still significant hardware software challenge need resolved quantum machine learning becomes practical overview quantum machine learning light classical approach departing foundational concept machine learning quantum computing discus various technical contribution strength similarity research domain also elaborate upon recent progress different quantum machine learning approach complexity application various field physic chemistry natural language processing ,1
ML_73,federated machine learning enables resourceconstrained node device eg internet thing iot device smartphones establish knowledgeshared model keeping raw data local could provide privacy preservation economic benefit designing effective communication protocol however communication protocol adopted attacker launch data poisoning attack different node shown big threat machine learning model therefore intend model vulnerability federated machine learning even iot system specific attempt attacking popular federated multitask learning framework us general multitask learning framework handle statistical challenge federated learning setting problem calculating optimal poisoning attack federated multitask learning formulated bilevel program adaptive arbitrary selection target node source attacking node propose novel systemsaware optimization method called attack federated learning atfl efficiently derive implicit gradient poisoned data attain optimal attack strategy federated machine learning earlier knowledge explores attacking federated machine learning via data poisoning finally experiment several realworld datasets demonstrate attacker directly poison target node indirectly poison related node via communication protocol federated multitask learning model sensitive poisoning attack ,1
ML_74,deep learning machine learning image input good field medical image analysis rapidly evolving machine learning expected become norm field medical image analysis inclusion image next decade idea machine learning ml also known deep learning recently become popular many field including computer vision indepth learning strategy based convulsive neural network cnn launched late quickly prestigious global computer vision competition imagenet ranking since academic many field including medical film analysis begun take active part rapid progression deep learning look indepth learning technique analysis medical image managing customary machine learning strategy pc vision industry changed machine learning prior afterward presentation top bottom learning dealing indepth learning pattern indepth practice application medical image analysis deep learning compare deep learning machine learning profound learning ml feature input featurebased ml normal essential key contrast among preand postprofound learning ml straightforwardly picture information object although model depth important asset ision element extraction wellspring top bottom learning capacity graph deep learning test show long history deep learning method classroom ml input exception term deep learning term deep learning used ml class medical image analysis image entry coined address issue pest nonpest taxonomy taxonomy taxonomy pest organ identification pest deep learning image input powerful versatile highperformance technology potential take clinical picture investigation higher level normal become major indepth technology coming decade ,1
ML_75,supervised machine learning used create prediction model degree worklife balance scale information technology woman professional woman working industry participated data collected based questionnaire parameter input supervised machine learning different machine learning ml model like regression tree support vector machine svm created compared performance ml model evaluated coefficient determination r mean absolute error mae mean square error mse optimized support vector machine model found highest accuracy wlb prediction comparison prediction capability support vector machine model multiple regression model done comparison two prediction model find accuracy svm higher multiple regression article provides svm alternative prediction modelling technique multiple regression organization behavior study machine learning modelling optimization training validation interpretation result done stepwise act practical guideline researcher interested ml modelling ,1
ML_76,common manufacturing method punching casting injection forming power metallurgy etc key technique manufacturing method machining degree technique machining directly affect quality product therefore machining technique primary importance promoting student practice ability training process currently practical training applied shop floor discipline student practice ability much time cost used teach technique particularly computerized machine continuously increasing development educating engineer computerized machine becomes much difficult traditional machine therefore research aim develop elearning webbased system teach computeraided manufacturing processing planning enhance quality quantity technological education technological advance internet learning activity free time location expensive resource technological education circulated network resource sharing diffusion education major result research follows establish online teaching material computeraided manufacturing course including cnc coding method cnc simulation propose teaching strategy student learning machining processing planning webbased learning system develop virtual machining laboratory bring machining practical training webbased learning system integrate multimedia virtual laboratory developed elearning webbased system enhance effectiveness machining education webbased system addition comprehensive fundamental theory elearning virtual reality developed system implemented undergraduate vocational high school machining course furthermore employ group technology facilitate effectiveness standardization course material create sharable course content ,1
ML_77,machine learning become essential component design intelligent system across several discipline widespread machine learning led importance evaluating systemssoftware engineering approach go hand hand machine learning reliably integrate intelligence software system research effort motivation develop systematic approach also termed machine learning engineering selection integration machine learning algorithm system proposed approach discus combining structured approach designing developing systemsoftware experimental analysis data scientist perform machine learning algorithm experimental analysis essential characteristic exhibited intelligent algorithm predicted guaranteed compared system without intelligent algorithm elaborate systemsoftware engineering guided disciplined approach comparing two machine learning algorithm focus recognition handwritten digit algorithm compare logistic regression neural network algorithm analysis identify contract associated intelligent component better predict behavior system result selection one component machine learning algorithm finally indicate result used systemssoftware engineer integrating intelligent algorithm ,1
ML_78,machine learning technique extensively apply solution medicine domain problem applying classification model system support medical personnel diagnosis predication diagnosis disease though hard extract knowledge information medical record data data information mixed unorganized high dimensional data also contains noise collected data outlier exist collected data applicable method used applies checking different machine learning technique performance machine learning technique checked verifying validating machine learning technique performance accuracy research discussing usability applicability different machine learning technique ie decision tree algorithm support vector machine method random forest method evolutionary algorithm based model swarm intelligence based technique diagnosis treatment disease advance medical diagnosis criterion generates confidence diagnosis imagining technique diagnosis disease extensively used doctor view fact analyzing medical image complex difficult machine learning method analysis imaging support give major help disease diagnosis application different machine learning method used applying technique big data interpretation diagnosis machine learning method show capability show easiness solve problem bioinformatics domain ,1
ML_79,machine learning major area artificial intelligence enables computer learn explicitly without programming machine learning widely used making decision automatically attacker strong intention manipulate prediction generated machine learning model different type attack countermeasure machine learning model research found many security threat various algorithm knearestneighbors knn classifier random forest adaboost support vector machine svm decision tree revisit existing security thread check possible countermeasure training prediction phase machine learning model machine learning model type attack causative attack occurs training phase exploratory attack occurs prediction phase also discus countermeasure machine learning model countermeasure data sanitization algorithm robustness enhancement privacy preserving technique ,1
ML_80,machine learning algorithm drawing attention lung disease research however due algorithmic learning complexity variability architecture ongoing need analyze performance review input parameter performance machine learning applied diagnosis chronic obstructive pulmonary disease copd one research focus clearly identifying problem issue related implementation machine learning clinical study following prisma preferred reporting item systematic review metaanalyses protocol title identified pubmed scopus google scholar database respectively study used machine learning detect copd provided performance measure included analysis final analysis study included analysis machine learning method detect copd reveals limited usage method lack standard hinder implementation machine learning clinical application performance machine learning diagnosis copd considered satisfactory several study however given limitation indicated study warranted extend potential machine learning clinical setting ,1
ML_81,dealing huge amount data look forward technique like machine learning predictive analysis pattern recognition etc specially health sector machine learning growing fast also give productive challenge predicting future machine learning algorithm play important role system learn become productive passing time method technique machine learning used various field among health care field take lot help technique prediction technique predictive analysis health care effective treatment risk factor managed effectively among patient improve quality health care per modern scenario need huge improvement healthcare term cost factor today healthcare sector face problem electronic data management disease prediction per symptom patient classification computer based diagnosis risk factor etc challenge solved help machine learning tool technique focus various machine learning method predictive analysis includes various application area machine learning mainly highlighting role machine learning health care sector ,1
ML_82,breakthrough various statistical learning method machine learning playing increasingly important role production life although machine learning model perform well practice security issue machine learning model attracted widespread attention academia industry example machine learning model require lot manpower material financial resource training huge commercial value generally speaking machine learning model trade secret company patent us flush+reload technique extract support vector machine svm kernel function information cache side channel seriously threatens security machine learning model experiment attacked scikitlearn machine learning framework two attack required accurately infer kernel function used victim svm training program ,1
ML_83,machine learning become ubiquitous essential part business operation amazon us algorithm nudge customer purchase product might like given purchase history customer large inventory product identify product customer interested likely purchase model decision process would allow computer make recommendation customer motivate product purchase machine learning solves problem solved numerical mean alone algorithm increase enterprise internal efficiency machine learning algorithm also used deepen consumer loyalty say machine learning provides potential solution domain set pillar future civilization course machine learning also important fab could help u solve problem including defect selection image detection fabrication scheduling rule machine learning build heavily statistic train machine model learn give statistically representative sample training data training set isnt representative run risk machine learning pattern complete training set small wont learn enough may even reach inaccurate conclusion ,1
ML_84,machine learning become value creator many old business however efficient realworld machine learning deployment still challenge traditional machine learning deployment suffer efficient resource utilization achieving predictable latency treated manner application server deployment unikernels method specialize application deployment performance suit need application traditionally building porting application unikernels challenging however recent simplifying development unikernels realworld unikernels specializing application run cpu survey machine learning practitioner find majority machine learning practitioner cpu machine learning deployment thus creating opportunity unikernels optimize performance application compare architecture two unikernels nanos unikraft benchmarked scikitlearn popular machine library inside unikernel found offered % advantage traditional deployment however testing could include innovative system like unikraft due immaturity inability run machine learning library include dependency analysis three popular machine learning library tensorflow lite pytorch onnx help pave way building machine learning application unikraft unikernels ,1
ML_85,general pollution climate refers discharge pollutant atmosphere damage human health environment whole ability one dangerous thing human ever experienced damage livestock crop forest among thing avoid issue mostly urban area popular approach machine learning technique may used predict air quality contaminant consequence quality air assessment forecasting become important field goal develop machine learningbased air quality forecasting technique accurate possible supervised machine learning technique smlt used gather several piece information dataset including variable recognition univariate analysis bivariate multivariate analysis missing value treatment analysis data cleaningpreparation data representation finding provide valuable guide sensitivity analysis model parameter term success air quality pollution prediction accuracy measurement comparing supervise classification machine learning algorithm generating prediction result form best accuracy create machine learningbased method accurately predicting air quality index value furthermore compare discus various machine learning algorithm order determine accurate algorithm performance guibased interface air quality prediction motivation aim create machine learning model realtime air quality forecasting potentially replace updatable supervised machine learning classification model predicting best accuracy comparing supervised algorithm aim project machine learning investigate dataset air pollutant record indian meteorological sector difficult determine air quality research attempt reduce risk factor associated forecasting air quality index aqi india safe human level order save significant amount meteorological time resource well predict whether air quality bad good ,1
ML_86,identifying wide range application machine learning algorithm proved ability learn without explicitly programmed classifying image machine learning algorithm getting wide range acceptability nowadays branch artificial intelligence machine learning implies system capability learn data machine learning involves two part representation generalization representation implies labeling seen data instance generalization determines whether system perform well unlabelled data instance article focused performance machine learning algorithm cbir content based image retrieval frame developed obtained reduced texture feature data set caltech image database highlight top five algorithm logistic bagging lmt multiclass classifier attribute selection classifier used image classification introduction overview selected technique presented extracted feature vector caltech image database data used distinguish performance machine learning algorithm checked machine learning algorithm supported identified top five algorithm better performance compared machine learning algorithm software used testing weka source software developed university waikato zealand ,1
ML_87,missing data universal data quality problem many domain leading misleading analysis inaccurate decision much research done investigate different mechanism missing data proper technique handling various data type last decade machine learning utilized replace conventional method address problem missing value efficiently studying analyzing recently proposed method machine learning approach vital adoption accuracy performance time consumed highlighted aimed help data analyst researcher address limitation machine learning imputation method conducting systematic literature provide comprehensive overview method impute missing value novel proposed machine learning approach used data imputation analyzed summarized assist researcher selecting proper machine learning method based several factor setting performed research study published adopting machine learning impute missing value focusing strength limitation total research article various scientific database analyzed search engine selected primary study finally several recommendation given guide future researcher applying machine learning impute missing value ,1
ML_88,benefit teaching machine learning k pupil include building foundational skill useful mental model inspire next generation ai researcher software developer however introducing machine learning school challenge even though several initiative curriculum design platform project tool exist demystify concept existing resource scattered sometimes overlap thereby selecting appropriate tool adopt teaching becomes arduous teacher practitioner despite increasing number paper published field still gap identifying specific tool resource teaching machine learning k setting present literature machine learning k selecting article published therefore present resource catalog survey tool help teacher find suitable teaching path make decision introduce activity help student understand basic concept machine learning based research objective utilized six database extract relevant information thirtynine peerreviewed article collected based systematic literature search analyzed identified resource tool instructional method category pedagogical item needed ensure impactful teaching machine learning k setting besides mode operation benefit challenge pedagogical tool teaching machine learning k setting unraveled finding also show increased number initiative resulting tool development support machine learning teaching finally provides recommendation future research direction help researcher policymakers practitioner education sector identify apply various resource aid decisionmaking practice democratize machine learning practice school ,1
ML_89,uncertainty maintaining prescribed quality machine component functional surface associated unique generalized dependence available original cutting data controlled object required quality machined surface effective approach resolve uncertainty process system learning selflearning control based accumulated data contains description selflearning process system architecture selflearning process system support prescribed surface quality machine component machining structure selflearning process system includes process system presented numerically controlled cutting machine tool sensor gauging cutting power tangential component sensor capturing temperature cutting zone sensor metering roughness parameter integration controller special attention paid system algorithmic support software development system automated control process equipment based pc numerical control machine therefore operation algorithm software considered integral part entire selflearning process system problem development software selflearning process system consideration software structure developed interaction system basic hardware software described designing basic system software module functionality hardware software described designed software enables creating selflearning cutting machine complying prescribed surface quality machined part ,1
ML_90,modern day technology machine learning one best discovery science one critical invention intellectualize made artificially make type revolution product programming behind complicated even type programming language used daily quite sure difficult execute program behind quite familiar according specific case study every human inidual searching query searching instrument via browser desired result come conveniently ever revolution happen time machine level language learning gone far also important research also happening around whole world improve specific section artificial intelligence better ever modern day internet surfing convenient without machine learning artificial intelligence reflects idea machine learning application artificial intelligence last year one biggest tech giant google microsoft usually implementing machine learning artificial intelligence search engine well softwarebased product also investing type technology improve much upcoming future well google microsoft also generation social medium essential thing daily life naming social medium first thing come mind facebook particular reflects explanation machine learning feature application artificial intelligence explores classification software category machine learning used data significant every day show necessary improve machine learning algorithm able handle extensive data return errorless precise output ,1
ML_91,high content screening hcs microscopic image active field computational cell biology powerful technique reveal chemical genetic environmental perturbation affect cellular state hcs effectively used organelle morphology drug discovery signaling pathway subcellular protein localization functional genomics hence high content screening type phenotypic screen conducted cell increased throughput characteristic hcs experiment due automation sample handling microscopy development robotic controlled stage positioning fluorescence filter camera acquisition autofocusing highcontent screening microscopy experiment generally require step sample preparation image acquisition image analysis image data management image analysis processing stage pose number computational challenge success highcontent screeningimaging experiment relies thoughtful assay design appropriate image analysis approach created number method evaluating cell toxicity determine nuclear area cell number plasma membrane permeability method developed characterization bone marrow fraction obtained density gradient centrifugation comprising determining cell size toxicity assessment hoechst dynamic absorption living bone marrow cell investigate influence various factor cell migration cellcell interaction developed highcontent analysis wound healing assay leading increased assay precision accuracy method intracellular reactive oxygen specie dynamic evaluated drugscreening procedure photosensitizing agent used photodynamic therapy hcs experiment contain ten thousand image including million cell researcher must utilize machinelearning algorithm translate morphological feature meaningful biological information machine learning widely used imagebased screening classify cell morphology principal objective screening determine whether experimental perturbation lead cellular phenotype commonly used machinelearning method classification based definition phenotype representative example thus screen conducted negative control well expected class phenotype representative example phenotype obtained supervised machine learning applicable unsupervised method need used instead also among analysis machinelearning method encompass datadriven model deep learning improving usability software interface machine learning could eventually facilitate assay development increase processing throughput accuracy objectivity ,1
ML_92,address rise machine learning big data analytics first machine learning several term related machine learning defined explained detail term include artificial intelligence data mining data science data analytics knowledge discovery statistic business intelligence definition show term interrelated definition big data outlined based three term volume velocity variety implementing good big data strategy crucial order guarantee success applying machine learning learning big data result trending big data also illustrated defined based landscape big data infrastructure analytics application crossinfrastructuresanalytics source data source api incubator school also address source facility available order ensure large scale machine learning application realized finally conclusion big trend last month big data analytics increasing focus artificial intelligence help analyze massive amount data derive predictive insight aimachine learning precipitating trend towards emergence application layer big data combination big data ai drive incredible innovation across pretty much every industry perspective big data opportunity probably even bigger people thought ,1
ML_93,recent year machine learning become widespread since machine learning algorithm become complex amount data handled become large execution time machine learning program increasing processor called accelerator contribute execution machine learning program short time however processor including accelerator different characteristic therefore unclear whether existing machine learning program executed appropriate processor proposes method selecting processor suitable machine learning program proposed method selection based estimation execution time machine learning program processor proposed method need execute target machine learning program advance experimental result clarified proposed method achieve time faster execution original implementation numpy result prove proposed method used system automatically selects processor machine learning program easily executed best processor ,1
ML_94,machine learning technology becomes popular nowadays many physic researcher discovered usage advantage applied different model obtained achievement thesis introduces paper example machine learning solve physic problem including double pendulum conservation law time series chaotic system demonstrates feasibility machine learning mechanic project analyzing different application method mentioned paper result experiment show machine learning good behavior area model used machine learning successful overall machine learning technology great potential feature contribution solving mechanic physic problem ,1
ML_95,machine learning ml type allows system perform operation providing multiple example done ml used allow build computer program help automatic improvement past experience today time machine learning play vital role many field like medical gaming robotics many industry ml algorithm generate many prediction model help providing better solution many field predict result le time also improve result improving prediction model machine learning used solving many problem data mining became essential technique solving problem area future machine learning could essential part every industry vastly used many industry machine learning method help predicting future categorized data help people making essential decision machine learning us advance modelsbased algorithm prediction model include predictive model neural networkbased model us system take necessary decision machine learning usable many industry like sale marketing medical sector healthcare diagnosis manufacturing finance several field today era machine learning play vital role modern industry make system intelligent ,1
ML_96,recent time increasing amount data enriched decision making machine learning despite growth domain machine learning proximity physical limit chip fabrication classical computing motivating researcher explore property quantum computing research effort demonstrated quantum computer leverage property quantum mechanic carry ability surpass classical computer machine learning task contributes enabling researcher understand quantum computer bring paradigm shift field machine learning focus concept quantum computing would used machine learning technique facilitate quantum machine learning also study different quantum algorithm could used core subroutine machine learning technique highlight famous grovers algorithm subroutine used enhance efficacy machine learning task towards end advocate quantum application software throw light existing challenge faced quantum computer current scenario ,1
ML_97,innovative practice workinprogress discus novel method teach machine learning concept undergraduate student teaching machine learning involves introducing student complex concept statistic linear algebra optimization order student better grasp concept machine learning provide handson exercise type immersive experience expose student different stage practical us machine learning data collection apparatus based application apps developed android platform due accessible nature app exercise based app approach useful student across majorswe provide student three different set activity first introduce basic machine learning specially designed artificial datasets second third activity involve data collection modeling training testing applied machine learning algorithm second activity involve collecting touchswipe data mobile device student touch logger app third activity us reflection app collect crosscorrelation data room different purpose handson activity guide student every step machine learning process student learning assessed activity holding workshop undergraduate student workshop first activity outlining basic machine learning given fall significant student learning demonstrated workshop second third activity planned fall semester result workshop presented conference ,1
ML_98,summary form given follows complete record panel discussion made available publication part conference proceeding machine learning gaining popularity eda area machine learning solve many difficult problem difficult traditional method talk give two example apply machine learning ic testing one chip performance prediction ir drop prediction application machine learning show significant speed traditional method however machine learning guarantee perfect accuracy conclusion machine learning good tool help testing requires domain knowledge apply right way ,1
ML_99,machine learning technology potential enrich life many way expected used various situation however value attack machine learning model also increasing therefore considered dangerous machine learning without proper planning poisoning attack one attack launched machine learning model poisoning attack reduce accuracy machine learning model mixing training data data created malicious intent attack model depending scenario damage caused poisoning attack may lead largescale accident propose method protect machine learning model poisoning attack assume environment data obtained multiple source used training data machine learning model method suitable defending poisoning attack environment proposed method computes influence data obtained source accuracy machine learning model understand good source impact replacing data source poisonous data also calculated based result calculation proposed method determines data removal rate data source represents confidence level determining degree harmfulness data proposed method prevents poisonous data mixed normal data removing according removal rate evaluate performance proposed method compared existing method proposed method based accuracy model applying proposed defensive measure experiment condition training data contains % poisonous data accuracy defended model proposed method % higher % obtained existing method show proposed method improved performance model poisoning attack ,1
ML_100,quality control machine learning system fundamental challenge industry provide intelligent service product machine learning recent advance machine learning algorithm substantially improve performance intelligent task object recognition output essentially stochastic sensitive input data output uncertainty big obstacle ensure quality safety critical application like autonomous vehicle hence architectural design mitigate impact error output becomes great importance propose nversion machine learning architecture aim improve system reliability probabilistic output inidual machine learning module key idea architecture exploiting two kind ersities input ersity model ersity first formally defines ersity metric analytically show improved reliability nversion machine learning architecture since treat machine learning module blackbox proposed architecture reliability property generally applicable machine learning algorithm application ,1
ML_101,power big data machine learning drastically demonstrated many field past twenty year somehow lead vague even false understanding huge amount precious human knowledge accumulated date seems longer matter pioneering propose knowledgedriven machine learning kdml model exhibit knowledge play important role machine learning task compared conventional machine learning kdml contains unique knowledge module based specific domain knowledge able simplify machine learning network structure reduce training overhead improve interpretability channel estimation problem wireless communication taken case verification machine learningbased solution face huge challenge term accuracy complexity reliability integrate classical wireless channel estimation algorithm different machine learning neural network propose kdmlbased channel estimator orthogonal frequency division multiplexing ofdm massive multiple input multiple output mimo system experimental result communication system validate effectiveness proposed kdmlbased channel estimator ,1
ML_102,intelligent technology including machine learning artificial intelligence playing significant role human battle covid pandemic machine learning enables machine learn improve without programmed detail machine learning penetrated many field help fight epidemic however specific representative contribution machine learning currently lacking summarize several machine learning application covid including predicting confirmed case trend ii classifying diagnosing mlbased image iii managing medical resource database related machine learning technology covid created moreover concise finished collected information evaluating different us machine learning covid also assemble research covid literature focused mlbased method order demonstrate profound insight covid related topic discovery emphasize crucial variable available covid resource facilitate clinical translational research ,1
ML_103,federated machine learning defines machine learning framework allows collective model constructed data distributed across repository owned different organization device blueprint data usage model building across organization device meeting applicable privacy security regulatory requirement provided guide defines architectural framework application guideline federated machine learning including description definition federated machine learning category federated machine learning application scenario category applies performance evaluation federated machine learning associated regulatory requirement ,1
ML_104,last year machine learning migrated laboratory forefront operational system amazon google facebook machine learning every day improve customer experience suggested purchase connect people socially application facilitate personal connection machine learning powerful capability also cybersecurity cybersecurity positioned leverage machine learning improve malware detection triage event recognize breach alert organization security issue machine learning used identify advanced targeting threat organization profiling infrastructure vulnerability potential interdependent vulnerability exploit machine learning significantly change cybersecurity landscape malware represent many million sample hour traditional malware detection malware analysis unable pace attack variant attack sophisticated malware able bypass network endpoint detection deliver cyberattacks alarming rate technique like machine learning must leveraged address growing malware problem describes machine learning used detect highlight advanced malware cyber defense analyst result initial research discussion future research extend machine learning presented ,1
ML_105,elearning system enable learner without teacher widely deployed university high school company almost system implemented clientserver model clientserverbased elearning system however problem low fault tolerance moreover since computationstorage concentrated server machine prepare expensive machine server ppbased elearning system therefore proposed ppbased elearning system computational resource storage distributed user machine therefore prepare expensive server machine anymore hand copyright issue learning content arises since user machine manage learning content propose elearning system integrated pp model clientserver model system machine constructing pp network provides computational storage resource machine user machine old personal computer used organization anymore since learning content stored user machine copyright issue learning content arise anymore ,1
ML_106,increased interest incorporate machine learning software system method characterize impact reliability machine learning needed ensure reliability software system algorithm reside towards end build upon architecturebased approach software reliability modeling represents application reliability term component reliability probabilistic transition component traditional architecturebased software reliability model consider component deterministic software therefore extend modeling approach case component represent learning enabled component reliability machine learning component interpreted accuracy decision common measure classification algorithm moreover allow machine learning component faulttolerant sense multiple erse classifier algorithm trained guide decision majority decision taken demonstrate utility approach ass impact machine learning software reliability well illustrate concept reliability growth machine learning finally validate past analytical result fault tolerant system composed correlated component real machine learning algorithm data demonstrating analytical expression ability accurately estimate reliability fault tolerant machine learning component subsequently architecturebased software resides ,1
ML_107,colossal development data field social insurance noteworthy improvement made foreseeing infection machine learning calculation forecast plague episode different illness giving better method putting away verifying human service data usage machine learning field social insurance guarantee exact outcome principle center around utilize machine learning social insurance enhance tolerant consideration better outcome machine learning made le demanding distinguish erse illness determination accurately prescient analysis assistance proficient different machine learning calculation predicts illness effectively help treat patient gathering therapeutic data people utilizing iot assessing examining foresee illness given proficient system coordinated machine learning iot arrangement human service part expects give aggregate component would execute machine learning advancement yield exact outcome anticipated infection manifestation coordinating % exactness motivation behind ponder streamlined machine learning calculation usage different illness forecast ,1
ML_108,recent study machine learning regarded one disruptive technology transform future life business global economy mckinsey identified technology area potential high impact people industry economy area machine learning key enabling technology machine learning learning data rather programming hard coded decision rule taking alone short definition highlight central role machine learning nowadays worldwide process digitization produce data area eg production process internet thing health care even daily life presentation machine learning defined bit precise going development rapidly emerging field different type machine learning explained example different application area given shown computer able able solve problem supposed dependent human expertise past among many benefit economically advantageous many area lead broad dissemination machine learning application downside development fact future life particular life change dramatically job particular requiring low level education high level automation likely disappear hand opportunity implication university education discussed apply computer science program alone also field ,1
ML_109,deburring process aerospace industry involves significant amount manual surface roughness measurement quality verification manual work hinder implementation industry discus implementation machine learning cloud computing improve conventional deburring process aerospace manufacturing industry ready industry upgrade start introduction deburring machine learning cloud computing relevant aerospace industry discus analytical approach determining chamfer length deburring machine learning analysis sensor data collected deburring process machine learning one example analysis tool replace manual often involves subjective judgement databased judgement also show offline machine learning result advantage brought online machine learning implementation detail advantage implementing machine learning deburring process aerospace industry moreover effort scale deburring process cloud service long sustainability discussed end reader understand implementation machine learning cloud computing deburring process aerospace industry ,1
ML_110,federated machine learning defines machine learning framework allows collective model constructed data distributed across repository owned different organization device blueprint data usage model building across organization device meeting applicable privacy security regulatory requirement provided guide defines architectural framework application guideline federated machine learning including description definition federated machine learning category federated machine learning application scenario category applies performance evaluation federated machine learning associated regulatory requirement ,1
ML_111,basically two way improving accuracy machine learning building relevant machine learning model providing high quality datasets training model significant effort made designing powerful machine learning model furthermore many opensource datasets created machine learning research however research assessing impact quality dataset accuracy machine learning system received attention experimental show quality datasets impact accuracy machine learning model discovered common problem datasets could greatly impact accuracy machine learning problem could also exist many machine learning system especially developed crowdsourced datasets problem difficult detect traditional validation approach propose novel technique based metamorphic testing validating machine learning system together training testing data key metamorphic testing create test adequately test system propose approach creating test effectiveness proposed approach demonstrated case automated classification biological cell image ,1
ML_112,machine learning essential technology providing ubiquitous intelligence internet thing iot however model training machine learning demand tremendous computing resource bringing heavy burden iot device meanwhile proofofwork pow based blockchains miner devote large amount computing resource compete generating valid block frequently disputed tremendous computing resource waste address dilemma propose evolvedproofofwork epow consensus integrate matrix computation machine learning process blockchain mining integrated architecture elaborated scheme transferring matrix computation machine learning blockchain mining reward adjustment scheme affect activity miner respectively designed epow detail epow keep advantage pow blockchain simultaneously salvage computing power miner model training machine learning conduct experiment verify availability effect epow experimental result show epow salvage % computing power pure blockchain mining parallel model training machine learning ,1
ML_113,machine learning part artificial intelligence branch artificial intelligenceai offer capability system learning better experience without human intervention machine learning ml software application become precise outcome prediction requirement explicit programmed machine learning fundamental concept ie building algorithm accepting input data help statistical analysis predict output nowadays machine learning gained vast popularity algorithm used every field like object detection pattern recognition text interpretation different research area one basic goal machine learning teach computer data solve particular problem fair range machinelearning application include email classification training distinguish spam nonspam message fraud detection etc aim varied machine learning method algorithm tool required run machine learning project also focus advancement administered order current researcher benefited ,1
ML_114,extreme learning machine type single hidden layer feedforward neural network overcome weakness traditional error hack propagation method increase training speed algorithm well decrease adjust time parameter kernel idea used extreme learning machine kernel extreme learning machine instead random map kernel extreme learning machine looser restriction fewer parameter well simple computational complexity better generalization response insufficient fitting ability kernel extreme learning machine kernel extreme learning machine based multiscale wavelet kernel polynomial combination presented presented algorithm optimize combined kernel parameter weight penalty factor test ucl dataset experiment show combined nuclear learning machine owns higher prediction accuracy advantage compared svm single core learning machine ,1
ML_115,machine learning algorithm often data database mutable therefore data result machine learning fully trusted also learning process often difficult automate unified analytical framework trusted machine learning presented literature address issue proposed building trusted machine learning system blockchain technology store data permanent immutable way addition smart contract blockchain used automate machine learning process however blockchain framework data efficiency big concern expensive store large amount data blockchain hand machine learningbased computer vision system often rely lot data therefore fully leverage blockchainbased machine learning framework computer vision system data efficiency issue must addressed investigates enhance data efficiency framework bring computer vision system edge present threestep approach first lightweight machine learning model trained server layer second trained model saved special binary data format data efficiency finally streaming layer take binary data input score incoming data online fashion realtime semantic segmentation autonomous driving used example demonstrate approach work make following contribution first improves analytical framework trusted computer vision system based blockchain second realtime semantic segmentation example show dataefficient learning computer vision performed edge ,1
ML_116,demand data increased witnessed surge machine learning help aid industry government making sense massive amount data subsequently making prediction decision military surge manifested internet battlefield thing pervasive nature data today & amp # x battlefield allow machine learning model increase soldier lethality survivability however machine learning model predicated upon assumption data upon machine learning model trained truthful machine learning model compromised assumption surrounding quality data model statusquo going forward attacker establish novel method exploit machine learning model benefit novel attack method described adversarial machine learning aml attack allow attacker unsuspectingly alter machine learning model model training order degrade model & amp # x ability detect malicious activity show aml poisoning data set evading well trained model affect machine learning model & amp # x ability function network intrusion detection system nids finally highlight evasion attack especially effective setting discus cause degradation model effectiveness ,1
ML_117,machine learning branch artificial intelligence aim enabling machine perform job skillfully intelligent software statistical learning method constitute backbone intelligent software used develop machine intelligence day huge increase demand machine learning seen great number available datasets knowledge acquisition mechanizing experience improvement computational method come machine learning need knowledge specific domain expert performance number ai expert system produced knowledge engineering regular seen industry different domain due increase applicability machine learning systematic various aspect related presented started giving brief description machine learning different model machine learning various type machine learning algorithm used various purpose like data mining predictive analytics image processing etc also presented comprehensive also given different done various researcher different application area covered machine learning medical social medium travelling robotics primary behind popularity different application ability learn work automatically type data input given ,1
ML_118,field prognostic health management aerospace asset fleet accurate prediction future state asset based current historical data challenge several different method computing future state commonly utilized including physicsbased simulation machine learning algorithm physicsbased simulation advantage true predictability able evolve model system first principle based causality predict future state yet observed real asset however also disadvantage difficult timeconsuming expensive construct machine learning algorithm reverse simple fast cheap construct without true predictability since fit input data data set trained aerospace fleet significant amount historical degradation failure data train model machine learning algorithm provide good prediction fleet little historical degradation failure data machine learning may provide good prediction future state asset explores accuracy prediction made machine learning algorithm trained sparse data varying quality empirical performed machine learning model trained data representing various historical data set type typically encountered aerospace health management eg low quality dense data high quality sparse data etc result running algorithm compared idealized physicsbased model predictive performance machine learning algorithm quantified suggestion appropriate utilize machine learning algorithm aerospace health management system presented ,1
ML_119,nonsmall cell lung cancer common type lung cancer common genetic marker mutation epidermal growth factor receptor gene egfr kirsten rat sarcoma kras gene objective predict egfr kras mutation status given ct feature machine learning model feature extracted ct scan tumor area included statistical shape pathological deep learning feature resnet neural network used extract deep learning feature feature fed machine learning model random forest logistic regression support vector machine evaluated fold cross validation confusion matrix area roc curve pvalues calculated ttesting mannwhitley ranksum testing proving significant statistical difference mutated non mutated gene predicting egfr kras mutation machine learning model performed better predicting egfr mutation predicting egfr mutation logistic regression auc support vector machine auc machine learning model performed best predicting kras mutation machine learning model performed suboptimally best performance support vector machine auc calculating permutation feature importance seen inclusion deep learning feature aided machine learning model performanceoverall machine learning algorithm optimized provided data could prove useful predicting egfr kras mutation status nsclc patient saving time money ,1
ML_120,summary form given follows complete presentation made available publication part conference proceeding learning representation critical machine learning computationintensive process many opportunity introduce efficiency parallel distributed computing success machine learning algorithm depends data representation different representation expose hide different feature data think future learning representation impact machine learning important consider state art machine learning today challenge opportunity addressing computation issue around representation learning get deeper understanding capability machine learned model talk describe idea related computational issue representation learning reducing uncertainty developing compact representation debasing training data developing privacypreserving representation ,1
ML_121,machine learning inherently multiobjective traditionally however either one objective adopted cost function multiple objective aggregated scalar cost function mainly attributed fact conventional learning algorithm deal scalar cost function last decade effort solving machine learning problem paretobased multiobjective optimization methodology gained increasing impetus particularly thanks great success multiobjective optimization evolutionary algorithm populationbased stochastic search method shown paretobased multiobjective learning approach powerful compared learning algorithm scalar cost function addressing various topic machine learning clustering feature selection improvement generalization ability knowledge extraction ensemble generation talk provides first brief overview paretobased multiobjective machine learning technique addition number case study provided illustrate major benefit paretobased approach machine learning eg identify interpretable model model generalize unseen data obtained paretooptimal solution three approach paretobased multiobjective ensemble generation compared discussed detail recent result multiobjective optimization spiking neural network presented ,1
ML_122,last decade saw enormous boost field computational technology method concept algebraic differential topology formerly confined realm pure mathematics demonstrated utility numerous area currently computation technology extends newly emerging domain referring topological data analysis tda next application area mentioned tda proven effective supporting enhancing augmenting classical machine learning deep learning model hand cnn deep feature recognition potentially help machine learning assist tda thus article attempt explore possibility collaborative interaction tda machine learning currently machine learning relies online training dataset arent enough sample dataset machine learning correctly avoid problem propose idea offline training via collaborative architecture made tda machine learning collaborative architecture apply weight & ampbiases make lack training sample solve problem mentioned current application future challenge simultaneously also try frame rapid method converting tda visual model provides friendly environment researcher evaluating comprehending complex relationship tda moreover collaborative architecture tda machine learning provides flexible erse learning feature also frame mechanism learningtolearn potential scenario extending varied research field future ,1
ML_123,white blood cell major role human health classification white blood cell help psychiatrist diagnose disease caused abnormality white blood cell diagnosis human subjective prone error deep learning method proposed classify two common type white blood cell result deep learning also compared three conventional machine learning method conventional machine learning refer method learn directly raw data conventional machine learning multi layer perceptron knearest neighbour support vector machine texture feature utilized conventional machine learning deep learning outperformed three conventional machine learning best achieved accuracy deep learning ,1
ML_124,machine learning branch artificial intelligence employ variety statistical probabilistic optimization technique allows computer learn past example detect hardtodiscern pattern large noisy complex data set machine learning offer principle approach developing sophisticated automatic objective algorithm analysis highdimensional multimodal biomedical data machine learning play important role medical system earlier identification disease helped detect earlier accurately save many people well reduce pressure system lung disease one leading cause death early identification prediction lung disease become necessity research facilitate subsequent clinical management patient machine learning based decision support system provide contribution doctor diagnosis decision project considered breathing problem patient well asthma chronic obstructive pulmonary disease copd tuberculosis pneumothorax lung cancer machine learning deep learning used process data well create model diagnosing patient combining processing patient information data chest xrays cnn wellknown pretrained model cap net network data form method used project identify lung disease initially studied analyzed data set apply machine learning deep learning predict patient lung disease project binary classification input patient data age gender chest xray image & amp view position output found disease aim detect diagnose lung disease early possible help doctor save patient life describes lung disease predicted controlled machine learning ,1
ML_125,machine learning effective method whose aim recognize unknown sample learning known sample artificial neural network ann support vector machine svm genetic algorithm ga popular machine learning method defect well merit machine doublelayer learning strategy put forward integrates merit annsvm ga ann svm used carry inner layer learning order obtain model inner parameter ga used implement outer layer learning acquire model outer parameter therefore learning method need carry double layer learning comparison common machine learning method posse stronger selfadaptive ability make shortcoming single learning method fully assure model generalization ability end machine doublelayer learning method applied nonlinear time series forecasting example show correctness validity method ,1
ML_126,machine learning provides automated mean capture complex dynamic wireless spectrum support better understanding spectrum resource efficient utilization communication system become smarter cognitive radio capability empowered machine learning perform critical task spectrum awareness spectrum sharing also become susceptible vulnerability due attack target machine learning application chapter identifies emerging attack surface adversarial machine learning corresponding attack launched wireless communication context g system focus attack spectrum sharing g communication incumbent user citizen broadband radio cbr band ii physical layer authentication g equipment ue support network slicing first attack adversary transmits data transmission spectrum sensing period manipulate signal���level input deep learning classifier deployed environmental sensing capability esc support g system second attack adversary spoof wireless signal generative adversarial network gan infiltrate physical layer authentication mechanisd deep learning classifier deployed g base station result indicate major vulnerability g system adversarial machine learning sustain g system operation presence adversary defense mechanism presented increase uncertainty adversary training surrogate model used launching subsequent attack ,1
ML_127,heart disease detection done number sample data taken various source different machine learning technique detect whether given data cancer infected ingenious technique allows many technology learn instance artificial learning enables computer function like human machine learning aim computer learn without human interruption united iot high capability grasp thing ability change mortgage market accurate data analysis sharp business intelligence machine learning four fundamental step create model first training dataset selected prepared algorithm selectedto apply training dataset algorithm trained create model lastly improving model machine learning consists various technique like supervised learning algorithm unsupervised learning algorithm reinforcementmachine learning semisupervised machine learning create machine learning model python library needed panda numpy skleam matplotlib need evaluate performance machine learning algorithm train test split technique used create graphplot pyplot matplotlib module come handy help creating bar graph pie chart histogram scatter plotsand plotting model function like standardscaler function classification confusion matrix end getting required plot show u accuracy model result shown last conclusion derived ,1
ML_128,machine learning algorithm finalized used application product many development step performed time consuming step preparation data set training testing optimization algorithm afterthese step trained model need integrated application code case selflearning system development process end point reason execution context environment selflearning system deployed often dynamic certain degree unpredictable smart home road traffic good example environment ensure proper functioning machine learning model context support system necessary lt must able perform task like distribution computation verifying prediction trained machine learning model furthermore support infrastructure system must deal incremental onsite training model case system network edge mean training adapting model limited resource organizing maintaining adapting kind support quite difficult microservice architecture potential reduce challenge system network edge discus potential example openlicht system selflearning lighting system network edge furthermore solution based micro service machine learning support presented evaluate microservice pattern architectural pattern ,1
ML_129,poor quality dataset may produce low quality machine learning system therefore transfer learning demonstrated effective approach data quality improvement widely used improving quality machine learning however quality improvement brought transfer learning study rigorously validated even misleading first investigate quality problem datasets used building machine learning system system claimed achieved best performance comparing existing machine learning however best performance due poor quality datasets well incorrect validation process described experimental demonstrate effectiveness transfer learning improving quality datasets however experiment result also show quality improvement transfer learning guaranteed set requirement meet applying approach based investigation experiment result propose group data quality criterion evaluation approach quality improvement machine learning investigated research problem explained result studying machine learning system normalizing medical concept social medium text datasets ,1
ML_130,applied advanced machine learning technique combined ensemble learning widely considered successful method produce objective inferential problem recurrent ovarian cancer five machine learning approach including svmsupport vector machine c elmextreme learning machine marsmultivariate adaptive regression spline rfrandom forest considered find important risk factor predict recurrenceproneness ovarian cancer ensemble learning improve defect classification accuracy used normal machine learning first selecting important risk factor ensemble learning five machine learning approach analyze medical record pathology accessible chung medical university hospital tumor registry existing literature recurrent ovarian cancer reveals factor include age histology grade pathologic pathologic n pathologic pathologic stage international federation gynecology obstetrics figo surgical margin performance status ca operation optimal debulking chemotherapy guideline totally patient data set c superior approach predicting recurrence ovarian cancer moreover classification accuracy c mar rf svm indeed increase ensemble learning particularly classification accuracy c obviously improves ensemble learning hybrid scheme ,1
ML_131,machine learning adaptive process make computer improve experience example analogy discipline methodology provides one form another intelligent information processing capability handling real life bioinformatics one application machine learning bioinformatics interdisciplinary science interpreting biological data information technology computer science machine learning ml focus automatic learning data set machine learning includes learning speed guarantee convergence data learned incrementally usually refer method like artificial neural network anns genetic algorithm gas fuzzy system hybrid method including combination method one major problem classify normal gene invalid gene infected kind disease genomic research classifying dna sequence existing category used learn function protein important identify gene classify order identify infected gene normal gene classification method machine learning technique give mechanism gene sequence classification machine learning technique includes brief detail bioinformatics literature survey key issue dna sequencing machine learning ,1
ML_132,general process building highquality machine learning model iterative complex timeconsuming process involves exploring performance various machine learning algorithm addition good understanding experience effectively tuning hyperparameters practice conducting process efficiently requires solid knowledge experience various technique employed continuous vast increase amount data digital world acknowledged number knowledgeable data scientist scale address challenge thus crucial need automating process combined algorithm selection hyperparameter tuning cash machine learning domain recently several system eg autoweka autosklearn smartml introduced tackle challenge aim reducing role human loop filling gap nonexpert machine learning user playing role data scientist metalearning described process learning previous experience gained applying various learning algorithm different type data hence reducing needed time learn task context automated machine learning automl process one advantage metalearning technique allow handengineered algorithm replaced novel automated method designed datadriven way methodology framework metalearning technique develop method serve effective decision support automl process particular metalearning technique answer several crucial question automl process including classifier expected best performing given dataset ? predict training time classifier ? classifier worth investing larger portion time budget improve performance tuning ? metalearning process used datasets different characteristic wide set metafeatures addition used classifier two popular machine learning library namely weka scikitlearn result metamodels obtained fully automated way methodology result framework easily embededutilized automl system ,1
ML_133,field supervised machine learning transfer learning environment defined training data different distribution characteristic testing data due lack available labeled data domain interest prompt alternate domain used training data insufficient labeled data domain interest validation technique reliably used algorithm selection process transfer learning environment transfer learning algorithm typically comprised domain adaptation step followed learning step learning step usually implemented traditional machine learning algorithm examine analyze impact traditional machine learning algorithm learning step overall performance transfer learning algorithm transfer learning test framework test five stateoftheart transfer learning algorithm coupled seven different traditional learning algorithm total unique transfer learning algorithm experiment labeled data domain interest available training process since validation technique reliably used algorithm selection process transfer learning environment important machine learning researcher practitioner understand impact traditional machine learner overall performance transfer learning algorithm ,1
ML_134,last one decade machine learning changed global technology landscape application almost discipline vertical mobile web security important research area researcher trying apply machine learning data privacy concern high data communication cost central machine learning server limited federated learning emerging promising solution address privacy concern drastically reduces communication cost federated learning data inidual device communicated central server model learning happens distributed manner propose federated learning solution security android based device mobile web security solution evolved signaturebased detection building machine learning model trained large centralized malware repository used federated learning learn security pattern user browsing data resides inidual device never leave device federated learning preserve user privacy share central server model learns user browsing data data way mobile platform train web security model data share centralized server centralized server aggregate trained model received numerous mobile device compiles aggregated global model turn sent mobile device inference mobile security solution based concept create sustained selfevolving security ecosystem million mobile platform share learned model form robust distributed security paradigm result obtained federated learning found comparable result centralized machine learning ,1
ML_135,late progression ai manmade brainpower developing spotlight versatile elearning way deal elearning lose allure level online course build move towards customized versatile learning collaborate student achieve better learning result school focus examination mindfulness arranging technique infuse innovation vision educational program elearning issue standard examination issue u motivation behind research analysis separate potential outcome assessing elearning model utilizing ai strategy supervised semi supervised reinforced learning advance investigating upside downside various method organization literature methodology cross sectional impact elearning machine learning algorithm existing literature ass essentialness elearning feature optimize elearning model available machine learning technique peerinspected journal capable destination book second legitimizes chance elearning structure introduction change demonstrated ai machine learning algorithm examination assist providing helpful highlight analyst researcher academician give exhaustive structure existing elearning framework recent innovation identified learning framework capacity learning task envision ml research opening appropriate space survey identifies demonstrates important role different type elearning feature inidual pertinent feature course pertinent feature context pertinent feature technology pertinent feature framework performance tuning performance machine learning algorithm optimize feature elearning model reviewed previous literature support vector machine technique found one best predict input output parameter elearning model found fuzzy c mean deep learning algorithm producing better result big data set ,1
ML_136,equipping machine comprehensive knowledge world entity relationship longstanding goal ai last decade largescale knowledge base also known knowledge graph automatically constructed web content text source become key asset search engine machine knowledge harnessed semantically interpret textual phrase news social medium web table contributes question answering natural language processing data analytics monograph survey fundamental concept practical method creating curating large knowledge base cover model method discovering curating large knowledge base online content emphasis semistructured web page list table etc unstructured text source case study academic project industrial knowledge graph complement survey concept method intended audience student researcher interested wide spectrum topic machine knowledge data quality machine learning data science well application web content mining natural language understanding also interest industrial practitioner working semantic technology web social medium enterprise content ,1
ML_137,artificial intelligence federates numerous scientific field aim developing machine able assist human operator performing complex treatmentsmost demand high cognitive skill eg learning decision process central quest give machine ability estimate likeness similarity thing way human being estimate similarity stimulus context book focus semantic measure approach designed comparing semantic entity unit language eg word sentence concept instance defined knowledge base aim measure ass similarity relatedness semantic entity taking account semantics ie meaningintuitively word tea coffee refer stimulating beverage estimated semantically similar word toffee confection coffee despite last pair higher syntactic similarity two stateoftheart approach estimating quantifying semantic similaritiesrelatedness semantic entity presented detail first one relies corpus analysis based natural language processing technique semantic model second based le formal computerreadable workable form knowledge semantic network thesaurus ontology semantic measure widely used today compare unit language concept instance even resource indexed eg document gene central element large variety natural language processing application knowledgebased treatment therefore naturally subject intensive interdisciplinary research effort last decade beyond simple inventory categorization existing measure aim monograph convey novice well researcher domain toward better understanding semantic similarity estimation generally semantic measure end propose indepth characterization existing proposal discussing feature assumption based empirical result regarding performance particular application answering question providing detailed discussion foundation semantic measure aim give reader key knowledge required select relevant method according particular usage context ii understand challenge offered field iii distinguish room improvement stateoftheart approach iv stimulate creativity toward development approach aim several definition theoretical practical detail well concrete application presented ,1
ML_138,recent year witnessed rapid growth largescale machine learning big data analytics facilitating development data intensive application like voiceimage recognition realtime mapping service autonomous driving social network augmentedvirtual reality application supported cloud infrastructure composed large datacenters large scale distributed machine learningdata analytics system provide necessary processing power handle application suffer three major performance bottleneck namely communication straggler security groundbreaking monograph author introduce novel concept coded computing coded computing exploit coding theory optimally inject leverage datatask redundancy distributed computing system creating coding opportunity overcome bottleneck introducing reader core problem author describe detail bottleneck overcome coded computing monograph provides accessible introduction technique used developing largescale computing system ,1
ML_139,embeddings provide concrete numerical representation otherwise abstract item downstream task example biologist might look subfamily related cell clustering embedding vector associated inidual cell machine learning practitioner might vector representation word feature classification monograph author general framework faithful embedding called minimumdistortion embedding mde generalizes common case similarity item described weight distance mde framework simple general includes wide variety specific embedding method including spectral embedding principal component analysis multidimensional scaling euclidean distance problem etc author provide detailed description minimumdistortion embedding problem describe theory behind creating solution aspect also give describe detail algorithm computing minimumdistortion embeddings finally provide example approximately solve many mde problem involving real datasets including image coauthorship network united state county demographic population genetics singlecell mrna transcriptomes accompanying opensource software package pymde make easy practitioner experiment different embeddings via different choice distortion function constraint set theory technique described illustrated book interest researcher practitioner working modernday system look adopt cuttingedge artificial intelligence ,1
ML_140,lecture present research general framework perceptual organization conducted mainly institute robotics intelligent system university southern california written historical recount since sequence presentation chronological order aim presenting approach wide range problem computer vision machine learning datadriven local requires minimal number assumption tensor voting framework combine property provides unified perceptual organization methodology applicable situation may seem heterogeneous initially show several problem posed organization input salient perceptual structure inferred via tensor voting presented extends original tensor voting framework addition boundary inference capability novel reformulation framework applicable highdimensional space development algorithm computer vision machine learning problem show complete analysis problem briefly outline approach application provide pointer relevant source ,1
ML_141,representation heart artificial intelligence ai book devoted problem representation discovery intelligent system construct representation experience ? representation discovery reparameterizes state space prior application information retrieval machine learning optimization technique facilitating later inference process constructing taskspecific base adapted state space geometry book present general approach representation discovery framework harmonic analysis particular fourier wavelet analysis biometric compression method compact disc computerized axial tomography cat scanner medicine jpeg compression spectral analysis timeseries data among many application classical fourier wavelet analysis central goal book show analytical tool generalized usual setting infinitedimensional euclidean space discrete finitedimensional space typically studied many subfields ai generalizing harmonic analysis discrete space pose many challenge discrete representation space must adaptively acquired basis function predefined rather must constructed algorithm efficiently computing representing base require dealing curse dimensionality however benefit outweigh cost since extracted basis function outperform parametric base often reflect irregular shape particular state space case study computer graphic information retrieval machine learning state space planning used illustrate benefit proposed framework challenge remain addressed representation discovery actively developing field author hope book encourage researcher explore exciting area research table content overview vector space fourier base graph multiscale base graph scaling large space case statespace planning case computer graphic case natural language future direction ,1
ML_142,contemporary science engineering application volume available data growing enormous rate spectral method emerged simple yet surprisingly effective approach extracting information massive noisy incomplete data erse array application found machine learning imaging science financial econometric modeling signal processing monograph present systematic yet accessible introduction spectral method modern statistical perspective highlighting algorithmic implication erse largescale application author provide unified comprehensive treatment establishes theoretical underpinnings spectral method particularly statistical lens building year research experience field author powerful framework called leaveoneout analysis prof effective versatile delivering finegrained performance guarantee variety problem book essential reading student researcher practitioner working data science ,1
ML_143,one grand challenge artificial intelligence enable computer interpret scene object imagery book organizes introduces major concept scene object representation inference still image focus recent effort fuse model geometry perspective statistical machine learning book organized three section interpretation physical space recognition object integrated scene interpretation first discus representation spatial layout technique interpret physical scene image second section introduces representation object category account intrinsically nature object provide robustness change viewpoint third section discus strategy unite inference scene geometry object pose identity coherent scene interpretation section broadly survey important idea cognitive science artificial intelligence research organizes discus key concept technique recent computer vision describes sample approach detail newcomer computer vision benefit introduction basic concept singleview geometry image classification expert novice alike may find inspiration book organization discussion recent idea scene understanding object recognition specific topic include mathematics perspective geometry visual element physical scene structural scene representation technique feature image region categorization historical perspective computational model datasets machine learning technique object recognition inference geometrical attribute object size pose probabilistic featurepassing approach contextual reasoning object scene table content background scene model singleview geometry modeling physical scene categorizing image region example scene interpretation background recognition modeling object recognizing understanding object example layout model reasoning object scene cascade classifier conclusion future direction ,1
ML_144,digital library dl introduced technology well leveraging enhancing integrating related technology since early effort enriched formal approach eg society scenario space structure stream framework discussed two earlier volume series volume help advance dl also www information system drawing upon four kozievitch murthy park yang completed three elsherbiny farag srinivasan inprocess dissertation well effort collaborating researcher score related publication presentation tutorial report book advance dl field regard least six key technology integrating survey stateoftheart research connection formalization case study exercisesprojects book serve computing information science textbook support study cybersecurity document management hypertexthypermedia ir knowledge management li multimedia machine learning chapter case fingerprint collection focus complex composite compound object connecting dl related bucket dcc oaiore chapter discussing annotation hypertexthypermedia emphasizes part document including image well text managing superimposed information superidr system prototype effort flickr motivate development standardization related annotation would benefit dl www user chapter ontology explains help browsing query expansion focused crawling classification chapter connects dl semantic web us ctrnet example chapter hierarchical classification leverage li theory well machine learning important dl well www chapter extraction text cover document segmentation well construct database heterogeneous collection reference etd ie converting string canonical form chapter survey security approach used information system explains approach apply digital library fully given rich content interested dl able find solution key problem right technology method hope book help show formal approach enhance development suitable technology better integrated dl information system ,1
ML_145,exascale computing need reexamine existing hardware platform support intensive dataoriented computing since bottleneck memory aim develop energyefficient inmemory computing platform book first model spintransfer torque magnetic tunnel junction racetrack memory presented next show spintronics could candidate future dataoriented computing storage logic interconnect result utilizing spintronics inmemorybased computing applied data encryption machine learning implementation inmemory aes simon cipher well interconnect explained detail addition inmemorybased machine learning face recognition also illustrated book ,1
ML_146,multiagent system ma networked multiple autonomous agent accomplish complex task area spacebased application smart grid machine learning overall system goal achieved local interaction among agent last two decade witnessed rapid development mass automatic control tracing root system back year monograph provides reader indepth comprehensive survey research multiagent system focus research conducted two decade introduces basic concept definition reader going describe ma used form system monograph offer concise reference understanding mass contemporary research issue investigation addition covering basic theory author also cover application multirobot system sensor network smart grid machine learning social network manycore microprocessor control multiagent system provides researcher student system control modern comprehensive survey one important current day topic ,1
ML_147,bartificial intelligence already enabled pivotal advance erse field yet impact computer architecture begunb particular recent explored broader application design optimization simulation computer architecture notably machinelearningbased strategy often surpass prior stateoftheart analytical heuristic humanexpert approach book review application machine learning systemwide simulation runtime optimization many inidual component cachesmemories branch predictor networksonchip gpus book analyzes current practice highlight useful design strategy identify area future based optimized implementation strategy opportune extension existing ambitious long term possibility taken together strategy technique promising future increasingly automated computer architecture design ,1
ML_148,may attractive view sensor simple transducer convert physical quantity electrical signal truth matter complex engineer proper understanding physic involved conversion process including interaction measurable quantity deep understanding interaction leveraged apply sensor fusion technique minimize noise andor extract additional information sensor signal advance microcontroller mem manufacturing improved internet connectivity enabled costeffective wearable internet thing sensor application time machine learning technique gone mainstream application intelligent ever book explores topic context small set sensor type provide basic understanding sensor operation accelerometer magnetometer gyroscope pressure sensor show information fused provide estimate orientation explore topic machine learning sensor data analytics ,1
ML_149,internetofthings machine learning promise era healthcare emergence transformative technology implantable wearable medical device iwmds enabled collection analysis physiological signal anyone anywhere anytime machine learning allows u unearth pattern signal make healthcare prediction daily clinical situation broadens reach healthcare conventional clinical context pervasive everyday scenario passive data collection active decisionmaking despite existence rich literature iwmdbased clinical healthcare system fundamental challenge associated design implementation smart healthcare system welladdressed smart healthcare defines standard framework smart healthcare aimed daily clinical setting investigates stateoftheart smart healthcare system constituent component discus various consideration challenge taken account designing smart healthcare system explains existing study tackled design challenge finally suggests avenue future research based set issue challenge ,1
ML_150,bthe efficiency solar energy farm requires detailed analytics information panel regarding voltage current temperature irradianceb monitoring utilityscale solar array shown minimize cost maintenance help optimize performance photovoltaic array various condition describe project includes development machine learning signal processing algorithm solar array testbed pv monitoring control kw pv array testbed consists panel fitted smart monitoring device device embeds sensor wireless transceivers relay enable continuous monitoring fault detection realtime connection topology change facility enables networked data exchange via wireless data sharing server fusion control center mobile device develop machine learning neural network algorithm fault classification addition weather camera data cloud movement prediction kernel regression technique serf input guide topology reconfiguration camera satellite sensing skyline feature well parameter sensing panel provides information fault detection power output optimization topology reconfiguration achieved programmable actuator relay smds specifically custom neural network algorithm guide selection among four standardized topology accuracy fault detection demonstrate level + % topology optimization provides increase power much % shading ,1
ML_151,recent year witnessed enormous progress airelated field computer vision machine learning autonomous vehicle rapidly growing field becomes increasingly difficult stay uptodate enter field beginner several survey paper particular subproblems appeared comprehensive survey problem datasets method computer vision autonomous vehicle published monograph attempt narrow gap providing survey stateoftheart datasets technique survey includes historically relevant literature well current state art several specific topic including recognition reconstruction motion estimation tracking scene understanding endtoend learning autonomous driving towards goal analyze performance state art several challenging benchmarking datasets including kitti mot cityscape besides discus problem current research challenge ease accessibility accommodate missing reference also provide website allows navigating topic well method provides additional information ,1
ML_152,variational autoencoders vaes powerful deep generative model widely used represent highdimensional complex data lowdimensional latent space learned unsupervised manner monograph author introduce discus general class model called dynamical variational autoencoders dvaes extend vaes model temporal vector sequence author provide ��� formal definition general class dvaes ��� detailed complete technical description seven dvae model ��� rapid overview dvae model presented recent literature ��� discussion recent development dvaes relation history technical background classical model dvaes built ��� quantitative benchmark selected dvae model ��� discussion put dvae class model perspective monograph comprehensive current stateoftheart dvaes give reader accessible summary technical aspect different dvae model connection classical model crossconnections unification dvae class concise easytoread book author put considerable effort unifying terminology notation used across various modelking machine learning find invaluable resource ,1
ML_153,arched type swing loom information retrieval system observed record progression information fetch knowledge data processing intelligent information progression subsequent processing machine like document retrieval text summarization search engine rule based machine expert system developed machine dedicated performance retrieval measure particular dimension machine learning method facilitated reasoning machine ability like human still corner research argues highly intelligent time constraint fact seeking real world information processing machine hybrid technology integration optimized approach various level information processing proposed hybrid search answer machine four technique optimization question reformulation userintent profile search method semantic concept context machine learning answer presentation ranking algorithm decision support comparative analysis choose best technique retrieve result data corpus heart ir system large dataset facilitates good search argue distributed data computing intelligence reformation proceeds excel time dataset machine designed facilitated updatable training dataset fact seeking knowledge acquirement train data mutiagent model distributed search methodology proposed precise hybrid extraction hybrid model performed semantic context concept based profiled best machine learning decision supportive multiagent distributed search system proposed give underlying technology overview examination paper done recent technology advancement outcome orderly placed research query answering output query structure trail search engine answering machine facilitate research done scholar technology perspective integrate draw sketch hybrid search answering domain point reference concept research studied comparative view advance ir identify benchmark research method blueprint explore space research area intelligent machine implementation ,1
ML_154,development behavior robot motion control fundamental robot operation physical environment yet challenged many factor sensor noise approximate actuation model technique like demonstration learning seed training dataset example behaviour execution expert powerful practical development motion control behavior endow robot ability continue learning experience demonstration assist robustness poor demonstrator demonstration interface also enable behavior adaptation change environment requirement tactile guidance policy adaptation introduces approach continuing motion control learning demonstration capitalizes availability multiple sensor modality human teacher may transfer domain knowledge particular note motion control correction provided tactile sensor located body robot approach validated high degreeoffreedom robot system demonstration correction challenging tactile guidance policy adaptation interest considering demonstration machine learning development robot behavior particular high degreeoffreedom humanoid well interested transfer knowledge multiple sensor modality ,1
ML_155,deep reinforcement learning combination reinforcement learning rl deep learning field research recently able solve wide range complex decisionmaking task previously reach machine deep rl open many application domain healthcare robotics smart grid finance many book provides reader starting point understanding topic although written research level provides comprehensive accessible introduction deep reinforcement learning model algorithm technique particular focus aspect related generalization deep rl used practical application written recognized expert book important introduction deep reinforcement learning practitioner researcher student alike ,1
ML_156,major breakthrough artificial intelligence deep learning achieved impressive success solving grand challenge many field including speech recognition natural language processing computer vision image video processing multimedia monograph provides historical overview deep learning focus application object recognition detection segmentation key challenge computer vision numerous application image video specifically topic covered object recognition include image classification imagenet face recognition video classification detection monograph cover general object detection imagenet pedestrian detection face landmark detection face alignment human landmark detection pose estimation finally segmentation cover recent progress scene labeling semantic segmentation face parsing human parsing saliency detection concrete example application explain key point make deep learning outperform conventional computer vision system deep learning object recognition detection segmentation provides comprehensive introductory overview topic major impact many area research signal processing computer vision machine learning mustread student researcher field ,1
ML_157,bayesian method machine learning widely investigated yielding principled method incorporating prior information inference algorithm monograph provides reader indepth role bayesian method reinforcement learning rl paradigm major incentive incorporating bayesian reasoning rl provides elegant approach actionselection explorationexploitation function uncertainty learning provides machinery incorporate prior knowledge algorithm bayesian reinforcement learning survey first discus model method bayesian inference simple singlestep bandit model review extensive recent literature bayesian method modelbased rl prior information expressed parameter markov model also present bayesian method modelfree rl prior expressed value function policy class bayesian reinforcement learning survey comprehensive reference student researcher interest bayesian rl algorithm theoretical empirical property ,1
ML_158,learning representation control markov decision process describes method automatically compressing markov decision process mdps learning lowdimensional linear approximation defined orthogonal set basis function unique feature text laplacian operator whose matrix representation nonpositive offdiagonal element zero row sum generalized inverse laplacian operator particular drazin inverse shown useful exact approximate solution mdps author go describe broad framework solving mdps generically referred representation policy iteration rpi basis function representation approximation value function well optimal policy linear span simultaneously learned basis function constructed diagonalizing laplacian operator dilating reward function initial set base power operator idea decomposing operator finding invariant subspace shown important principle constructing lowdimensional representation mdps theoretical property approach discussed also compared experimentally variety discrete continuous mdps finally challenge research briefly outlined learning representation control markov decision process timely exposition topic broad interest machine learning beyond ,1
ML_159,major part natural language processing depends text data build linguistic analyzer consider statistical computational approach modeling linguistic structure seek unify across many approach many kind linguistic structure assuming basic understanding natural language processing andor machine learning seek bridge gap two field approach decoding ie carrying linguistic structure prediction supervised unsupervised learning model predict discrete structure output focus also survey natural language processing problem method applied address related topic probabilistic inference optimization experimental methodology table content representation linguistic data decoding making prediction learning structure annotated data learning structure incomplete data beyond decoding inference ,1
ML_160,propose machine tutoring framework modified adversarial autoencoderaae interactive machine learningiml iml master teach machine valuable knowledge skill machine transfer knowledge skill novice generally iml discus transferring knowledge something known skill something need know practice learn well master machine machine novice focus one part iml technique transferring knowledge skill machine novice called machine tutoring realize taikodrum playing game platform taikodrum playing skill learning considered important knowledge learning particular adopt internal measurement unit imu attached novice forearm collect necessary data understand novice motion assume imu data help u understand well novice learn particular motion machine master eventually side capture game score novice play evaluation four song different level easy hard used experiment novice play game extract explainable value latent feature deep learner representation novice play machine tutoring operated show visualization built given latent representation novice suggest may perform better better play demonstrate effectiveness proposed machine tutoring framework three different deep neural network structure stacked autoencoder included framework including mlp cnn lstm result show aaeregression cnn aaercnn performs best latent information representation song level easy normal aaerlstm also performs best song level difficult two task namely score prediction subject classification afterwards illustrate representation help machine tutoring ,1
ML_161,machine���to���machine mm system internet thing lot broad term sometimes used interchangeably little point debating one end begin cloud computing refers class on���demand compute service available internet service include foundational offering like computation data storage well specialized service like machine learning parallel data set processing remote monitoring represents basic feature common iot solution asset management build remote monitoring adding capability command control system predictive maintenance scenario additional cloud service added like machine learning distributed analysis tool like apache hadoop vending machine provide excellent example benefit predictive maintenance remote monitoring machine learning failure pattern recognized addressed actual failure happens predi,1
ML_162,difficult avoid problem tool wear breakage machining cnc machine tool failure detect stop machine time likely cause damage machine workpiece requires online monitoring tool state machining loadbased tool wear monitoring method proposed selflearning method adopted obtain load range specific machining process online monitoring subsequent machining process carried selflearning mainly used process load signal statistical algorithm �� algorithm obtain upper lower boundary monitoring range load signal subsequent machining process compared upper lower boundary determined selflearning algorithm determine whether tool worn finally feasibility method verified experim,1
ML_163,discrete choice model widely used explain transportation behavior including household decision car show distinct choice human behavior preference influence decision also used project future demand estimate support policy exploration latter prediction indirectly aligned conditional model estimation aim fit observed data contrast machine learning model derived maximize prediction accuracy mechanism outofsample validation nonlinear structure automated covariate selection albeit expense interpretability sound behavioral theory investigate machine learning model outperform discrete choice model prediction car ownership transportation household survey data singapore compare household car ownership model multinomial logit model various machine learning model eg random forest support vector machine data derive ie estimate model predict ownership machine learning model inferior discrete choice model discrete choice feature however engineering feature appropriate machine learning superior result highlight cost applying machine learning model econometric context opportunity improved prediction better urban policy making machine learning model appropriate feature ,1
ML_164,area corporate bankruptcy prediction attains high economic importance affect many stakeholder prediction corporate bankruptcy extensively studied economics accounting decision science past two decade corporate bankruptcy prediction matter talk among academic literature professional researcher throughout world different traditional approach suggested based hypothesis testing statistical modeling therefore primary research come model estimate probability corporate bankruptcy evaluating occurrence failure different machine learning model dataset well prepared contains missing value various data mining data preprocessing technique utilized data preparation research resolving issue induced imbalance two class approached applying different data balancing technique address problem imbalanced data random undersampling synthetic minority sampling technique smote used five machine learning model support vector machine j decision tree logistic model tree random forest decision forest predict corporate bankruptcy earlier occurrence data poland manufacturing corporates selected financial indicator broken finding significant improvement predictive accuracy machine learning technique also include economic indicator ratio altmans zscore variable related profitability liquidity leverage solvency shortlong term propose efficient model machine learning model give better result balancing data smote compared random undersampling machine learning technique related decision forest led % accuracy whereas support vector machine svm j decision tree logistic model tree lmt random forest rf led % % % % accuracy respectively predictive financial indicator find decision forest outperforms technique previous technique discussed literature proposed method also deployed web assist regulator investor creditor scholar predict corporate bankruptcy ,1
ML_165,big influence robotics natural language processing field automation current scenario natural language processing nlp focus machine analysis machine interpretation term machine analysis accuracy becomes important phenomenon named augean refers higher accuracy natural language processing difficult attain involving neural network thus far named augean artificial neural network one key branch machine learning peculiar branch speculating towards artificial intelligence nlp one key aspect making machine learn letting speak current framework discus deep learning one biggest challenge make machine learn speak known thus far processing becomes crucial part therefore come processing better idea brain involved current scenario making machine learn best accuracy something great accuracy involves real complex algorithm machine work possibly best accuracy stay high stepping precision better learning ability machine remarkable frame artificial neural network neuroscience used make model robust increasing accuracy least five percent previous model involved ,1
ML_166,deal deployment evaluation machine learning classifier prediction tuberculosis research deploys five key machine learning classifier naive bayes support vector machine decision tree k nearest neighbor random forest clearly understood support vector machine provides best accuracy & amp # x prediction pulmonary tuberculosis ptb extrapulmonary tuberculosis eptb compared machine learning classifier tuberculosis data set important challenge machine learning build accurate competent machine learning classifier hence support vector machine best suited machine learning classifier prediction ptb eptb ,1
ML_167,outline approach build intrusion detection system network interface device research developed hybrid intrusion detection system involves various machine learning technique inference detection comparative analysis explained phase training model training inference network building detection phase working phase aim solve current reallife problem exists machine learning algorithm machine learning technique stiff respective classification region outside cease properly aim provide best working machine learning technique many used machine learning technique used comparative analysis decision tree na��ve bayes knearest neighbor knn support vector machine svm nslkdd dataset testing training network intrusion detection model accuracy recorded decision tree na��ve bayes knearest neighbor knn support vector machinessvm respectively tested independently % % % % tested inference detection model % % % % therefore concluded inference detection model help improving certain factor detected conventional machine learningue ,1
ML_168,artificial intelligence spectacular part computer engineering earned compelling ersion field medical data classification due stateofart algorithmic strength learning capability machine learning major subdomain artificial intelligence become one promising field computer science recent year large spectrum healthcare biomedical data growing intensely due huge labeled unlabeled data important compact robust machine learning solution classification several optimizers deployed improve inclusive performance machine learning model classification machine learning model depends several factor comprehensive aim insight current stage optimized machine learning success medical data classification increasing number unstructured medical data utilizing machine learning algorithm predict intuition difficult inherent immense intuition data machine learning researcher utilized stateofart optimizers novel feature selection technique overcome emend performance accuracy highlighted recent literature exhibit robust impact optimizers feature selection machine learning technique medical data characterization hand cleancut introduction machine learning theoretical outlook widely utilized optimization technique like genetic algorithm gray wolf optimization particle swarm optimization discussed initial understanding optimization technique ,1
ML_169,entering exciting era human intelligence enhanced machine intelligence big data fueled artificial intelligence ai machine learning ml however recent show dnn model trained privately vulnerable adversarial input adversarial input inject small amount perturbation input data fool machine learning model misbehave turning deep neural network defense method proposed sophisticated attack algorithm surfaced arm race ongoing since rise adversarial machine learning keynote provides comprehensive analysis characterization representative attack defense mission critical system incorporating machine learning ai essential component realworld big data application big data provisioning platform product understanding ensuring verifiable robustness deep learning becomes pressing challenge presence adversarial attack includes development formal metric quantitatively evaluate measure robustness dnn prediction respect intentional unintentional artifact deception comprehensive understanding blind spot invariant dnn trained model dnn training process statistical measurement trust distrust place deep learning algorithm perform reliably truthfully keynote talk empirical analysis evaluation crosslayer strategic teaming defense framework technique illustrate feasibility ensuring robust deep learning ,1
ML_170,model produced machine learning particularly deep neural network stateoftheart many machine learning task demonstrate high prediction accuracy unfortunately model also brittle vulnerable specially crafted adversarial example recent result shown accuracy model reduced close hundred percent % adversarial example brittleness deep neural network make challenging deploy learning model securitycritical area adversarial activity expected ignored number method recently proposed craft effective generalizable attack neural network competing effort improve robustness learning model current approach make machine learning technique resilient fall short goal succession adversarial attack proposed method increase neural network robustness raise doubt foolproof approach robustify machine learning model possible adversarial attack consider problem detecting adversarial example would help identify learning model trusted without attempting repair model make robust adversarial attack goal finding limitation learning model present tractable approach protecting adversarial attack approach based identifying low dimensional manifold training sample lie distance observation manifold identify whether data point adversarial empirical demonstrates adversarial example lie farther away data manifold distance manifold adversarial example increase attack confidence thus adversarial example likely result incorrect prediction machine learning model also easier detect approach first step towards formulating novel approach based computational geometry identify limiting boundary machine learning model detect adversarial attack ,1
ML_171,machine learning one field modern computing world plenty research undertaken make machine intelligent learning natural human behavior made essential aspect machine well various technique devised traditional machine learning algorithm applied many application area researcher put many effort improve accuracy machinelearning algorithm another dimension given thought lead deep learning concept deep learning subset machine learning far application deep learning explored definitely going cater solving issue several application domain subdomains deep learning past future application domain subdomains application machine learning deep learning illustrated ,1
ML_172,highquality corpus essential building effective legal intelligence system quality corpus includes quality original data quality corresponding labeling major quality dimension legal corpus include comprehensiveness freshness correctness however building comprehensive correct fresh legal corpus grand challenge article propose semiautomated machine learning framework address challenge first created initial corpus instance manually labeled several strategy implemented assure quality initial result showed class imbalance insufficiency training data two major quality issue negatively impacted quality system built data experimented compared three classimbalancehandling technique found mixedsampling method combine upsampling downsampling effective way address issue order address insufficiency training data experimented several machine learning method automated data augmentation including pseudolabeling cotraining expectationmaximization generative adversarial network gan result showed gan deep learning model achieved best performance finally ensemble learning different classifier proposed experimented construction legal corpus achieves higher quality comprehensiveness freshness correctness compared existing semiautomated machine learning framework data quality evaluation method developed research used data augmentation quality evaluation large dataset well reference selection machine learning method data augmentation generation machine learning model training data legal corpus published publicly accessible online available httpsgithubcomhaihualegalargumentmining ,1
ML_173,machine learning computational intelligence applied wide range medical problem assist medical professional decisionmaking especially artificial neural network fuzzy system powerful hybrid neurofuzzy approach already proven strong potential medicine especially important interesting emerging field personalized medicine often described providing right patient right drug right dose right time represents tailoring medical treatment inidual patient characteristic need preference machine learning focus development computer program access data learn regarding medical application concerning prediction patient clinical outcome machine learning considered datadriven analytic approach specializes integration multiple risk factor predictive tool talk hypothesis considered machine learning based model may help improve prediction clinical outcome various medical field comparison traditional statistical scoring approach hypothesis tested result several study experience considered regarding artificial neural network based prediction cerebral palsy infant central coordination disturbance adaptive neurofuzzy estimation autonomic nervous system parameter effect heart rate variability machine learning leukemia clinical outcome prediction neural prediction mortality spontaneous intracerebral hemorrhage based initial clinical parameter others finally demonstrated potential machine learning medical diagnosis result concerning cervical cancer detection improving standard screening test considered ,1
ML_174,good machine learning model evidently available literature research towards even improved version machine learning model still going however machine unlearning side coin ignored little done focused erasing data previously used machine learning model mean making machine learning model forget learnt trend however erasing prior learning experience order relearn scratch time consuming expensive addition high risk datasets pollution process investigated detection save point multiple linear regression model result show successful detection save point major trend change data visually noted plausible model potentially improve quality machine learning well speed ,1
ML_175,driven recent technological advancement field artificial intelligence machine learning emerged promising representation learning decisionmaking method many technological domain inspired impressive result machine learning technique also applied address decisionmaking control problem area cyberphysical system instance system fall category safetycritical system chemical plant autonomous vehicle surgical robot modern medical equipment one major performance issue related applicability machine learning safetycritical system related probabilitybased prediction nature machine learning component used system particular characteristic machine learning make extremely difficult guarantee safety directed standard iso importantly nontransparent complex nature machine learning algorithm make reasoning well formally establishing safety aspect underlying system extremely difficult objective research investigate key issue propose efficient machine learning methodology based mixedcriticality approach feasible safetycritical system ,1
ML_176,since birth artificial intelligence theory technology increasingly mature application field also expanding artificial intelligence technology deep learning help develop resilient machine learning mitigate adversarial learning attack us money lending case explain application artificial intelligence building resilient machine learning generative adversarial network example moreover discus definition resilient machine learning give adversarial machine learning attack threat actor ,1
ML_177,rapid development information technology widespread internet volume ersity data also increased meaningful information important result obtained processing data expressed concept big data machine learning platform automatically learn data set different data type dimension developed dataset field given input developed automatic machine learning platform appropriate machine learning model determined platform web interface easily used people expert field sufficient knowledge field machine learning data science suitable machine learning model data set suggested user training test result different model obtained compared experimental study shown developed platform successful knitting machine learning model suitable dataset ,1
ML_178,background machine learning model sometimes embedded software implement required function result nonexperts machine learning becoming familiar model however interpretability built model often low machine learning deep learning recognition process model different human therefore easy novice user endusers beginner anticipate behavior model build aim assist novice user realize aspect behavior machine learning model relating robustness intuitively method formalized evaluated quizbased analysis often applied practitioner test robustness machine learning model arbitrarily generate test case model analysis convert image towards boundary classification machine learning human regarded type boundary value analysis software development result experiment evaluated whether analysis quantitatively clarified aspect model analysis clarified robustness model image conversion misclassification quantitatively conclusion analysis expected enlighten novice user behavior machine learning model may promote behavioral change evaluation model novice user ,1
ML_179,huge data set would like perform predictive analysis pattern recognition machine learning way go machine learning ml fastest rising arena computer science health informatics extreme challenge aim machine learning develop algorithm learn progress time used prediction machine learning practice widely used various field primarily health care industry benefitted lot machine learning prediction technique offer variety alerting risk management decision support tool targeted improving patient safety healthcare quality need reduce healthcare cost movement towards personalized healthcare healthcare industry face challenge essential area like electronic record management data integration computer aided diagnosis disease prediction machine learning offer wide range tool technique framework address challenge depicts various prediction technique tool machine learning practice glimpse application machine learning various domain also discussed highlighting prominence role health care industry ,1
ML_180,give broad view machine learning author describe basic method learning give example learning system illustrate technique early research performance machine learning system discussed taking simplistic approach machine learning technique ided following category rote inductive example observation discovery deduction analogy even simplistic approach technique overlap highperformance learning machine exhibit intelligence lowperformance learning machine therefore performance learning algorithm presented analyzed respect suitability parallel machine environment & ltetx & gtetx ,1
ML_181,breast cancer ductal carcinoma prevalent woman leading cause woman death worldwide delaying breast cancer tumor growth longterm effect also become lifethreatening tumor identified early possible control growth preventing spread tissue several type research done detect breast cancer early treatment started increase chance survival mammography procedure early detection diagnosis breast cancer commonly advised many technique used malignancy prediction artificial intelligencepowered machine learning widely recommended research conducted machine learning detect cancerous tumor human body mainly used algorithm give high accuracy svm na��ve bay decision tree knn deep learning machine learning subbranch also used classify breast cancer deep learning method mostly used clear rectify detect machine learning error disadvantage convolutional neural network perfect deep learning method overcoming drawback machine learning malignancy detection however strategy recurrent neural network deep belief network used overcome tcoming machine learning consequence deep learning rather machine learning yield better result paper primary motivation make budding researcher aware breast cancer serious issue among woman need swift different technology detect improve accuracy efficiently possible important save mother sister loved one society dangerous predator discussed technique used different author ,1
ML_182,fog edge pervasive computing technology developed overcome limitation cloud computing chapter cover role various machine learning deep learning framework technique algorithm fog edge pervasive computing latency privacy bandwidth limitation problem cloud computing chapter discus machine learning combined computing technology help overcome limitation cloud computing inferencing challenge machine learning deep learning model chapter cover various framework help provide inference quantize model even machine learning advantage disadvantage chapter cover advantage disadvantage machine learning edgefogpervasive computing also cover various study done researcher every field numerous application chapter discus possible application fog era machine learning technique end chapter know ml framework various machine learning algorithm used fogedge computing ,1
ML_183,artificial intelligence becoming important part life machine learning deep learning two derivative artificial intelligence machine learning emerging field current era concern machine learning develop computer learn machine learning playing important role various field education entertainment medical diagnosis etc role machine learning important medical diagnosis term accuracy efficiency used various disease diagnosis lung cancer heart disease diabetes many presented machine learning application medical diagnosis survey various disease diagnosis application various machine learning approach model described aim research provide brief role ai ml help collected pre trained datasets medical diagnosis ,1
ML_184,machine learning algorithm cognitive computing decision making help achieve significant solution generalizing learned model environmental pattern instance technique frequently practicable economical manual rigid rule based abstract programming suitable training input pattern obtainable betterdetermined task attempted result machine learning extensively used cognitive computing artificial intelligence handling structured unstructured multimedia big data however evolving fruitful machine learning cognitive application involves considerable extent concept available general theory analyze primary module machine learning approach attempt friendly real world example cognitive teacher appraisal first section sightsee meaning machine learning deliberate cognitive ability generate second third section discus practical procedure issue solving cognitive problem next five section define concept machine learning method application problem domain last section show comparison machine learning algorithm capability limitation ,1
ML_185,poor data quality direct impact performance machine learning system built data demonstrated effective approach data quality improvement transfer learning widely used improve machine learning quality however quality improvement brought transfer learning rarely rigorously validated quality improvement result misleading article first exposed hidden quality problem datasets used build machine learning system normalizing medical concept social medium text system claimed achieved best performance compared existing machine learning however result experiment showed best performance due poor quality datasets defective validation process address data quality issue build highperformance medical concept normalization system developed transferlearningbased strategy data quality enhancement system performance improvement result experiment showed strong correlation quality datasets performance machine learning system result also demonstrated rigorous evaluation data quality necessary guiding quality improvement machine learning therefore propose data quality evaluation framework includes quality criterion corresponding evaluation approach data validation process performance improvement strategy data quality evaluation framework discussed article used machine learning researcher practitioner build highperformance machine learning system ,1
ML_186,would like discus making curriculum practical machine learning application university student increasingly motivated learn machine learning industrial request career plan application machine learning released quickly curriculum university insufficient correspondence focus importance including practical machine learning application university curriculum discus issue specifically provide perspective necessary front end back end technology machine learning technology blended back end system front end system like mobile interface important point quality today student necessary learn lot learning content quality amount time issue university fusion topic existing curriculum economic cost balance also discussion necessary social cooperation industry method stem education important practical machine learning application curriculum discus example effect japan ,1
ML_187,learned bloom filter lbf combine machine learning model learner traditional bloom filter improve false positive rate fpr achieved given memory budget lbf recently generalized making full spectrum learner prediction score however design machine learning model fixed first time design learned bloom filter proposed evaluated considering machine learning model one variable process detail given memory budget several lbfs constructed different machine learning model one lowest false positive rate selected demonstrate approach achieve much better performance existing lbf design providing reduction fpr % setting ,1
ML_188,recent development machine learning computational linguistics enabled cognitive machine understand semantics human expression system sentence syntactic analysis semantic synthesis developed based denotational mathematics machine sentence learning comprehension reduced building composed concept map semantics subject onto counterpart object represented formal concept phrase set semantic operation concept composition modification generalization specification extension reduction formally specified based concept algebra semantic algebra machine learning algorithm unsupervised sentence learning ausl designed implemented express learnt sentence knowledge graph related semantic hierarchy machine knowledge base experimental result demonstrate autonomous learning algorithm case study machine learning towards application cognitive robot knowledge learning system ,1
ML_189,machine learning based anomaly detection system gained prominence field internet thing iot due effectiveness dealing security privacy issue internet thing manifold application possible aid effective integration sensor database machine service due increasing iotbased architecture attack anomaly detection become crucial part functioning iot basic goal anomaly detection system verify whether behavior system normal unfaithful action taken system anomaly detection system used detection attack anomaly right denialofservice malicious operation may cause disruption iotbased system variety machine learning algorithm used anomaly attack detection analyzed different machine learning algorithm compared proposed stacked ensemble learning model evaluation metric used comparison various machine learning algorithm proposed stacked ensemble learning model include f score precision accuracy recall area roc curve proposed system found accuracy % superior comparison traditional machine learning algorithm proposed stacked ensemble learning model could effectively used improving existing anomaly detection system ,1
ML_190,covid affected people life though covid rising existence misinformation virus also grows parallel additionally spread misinformation created confusion among people caused disturbance society even led death social medium central daily life internet become significant source knowledge owing widespread damage caused fake news important build computerized system detect fake news proposes updated deep neural network identification false news deep learning technique modifiedlstm one three layer modified gru one three layer particular carry investigation large dataset tweet passing data respect covid separate dubious claim two category true false compare performance various algorithm term prediction accuracy six machine learning technique decision tree logistic regression k nearest neighbor random forest support vector machine na��ve bayes nb parameter deep learning technique optimized kerastuner four benchmark datasets used two feature extraction method used tfid ngram extract essential feature four benchmark dets baseline machine learning model word embedding feature extraction method proposed deep neural network method result obtained proposed framework reveal high accuracy detecting fake nonfake tweet containing covid information result demonstrate significant improvement compared existing state art result baseline machine learning model approach classify data two category fake nonfake compare execution proposed approach six machine learning procedure six machine learning procedure decision tree dt logistic regression lr k nearest neighbor knn random forest rf support vector machine svm naive bayes nb parameter deep learning technique optimized kerastuner four benchmark datasets used two feature extraction method used tfid ngram extract essential feature four benchmark datasets baseline machine learning model word embedding feature extraction method proposed deep neural network method result obtained proposed framework reveal high accuracy detecting fake nonfake tweet containing covid information result demonstrate significant improvement compared existing state art result baseline machine learning model ,1
ML_191,cloud computing system expanding number terminal thing connected cloud system increase limit capability also becoming apparent lead significant processing time delay edge fog computing system known method improving conventional cloud system basic idea consider system place edge server cloud terminal thing capacity edge may high many edge cooperate execute task achieve high processing power machine learning realized edge system ? fast secure learning method desired machine learning cryptographic system seem necessarily suitable machine learning therefore safe system distributed processing attracted attention smc secure multiparty computation one typical model horizontally vertically partitioned data known smc proposed method realizing machine learning cloud smc also method machine learning horizontally partitioned data smc edge system proposed hand little study done machine learning vertically partitioned data fast secure bp backpropagation neural network learning vertically partitioned data edge system proposed effectiveness shown numerical simulation ,1
ML_192,carnegie mellon university pioneered contextaware mobile computing built first prototype including contextaware mobile phone contextaware personal communicator prototype machine learning cognitive modeling technique derive state intent device sensor contextaware computing describes situation mobile computer aware user state surroundings modifies behavior based information demonstrated power method automatically derive meaningful context model performed experimental measurement evaluation employed unsupervised machine learning technique combine real time data multiple sensor model behavior inidualized observe context require descriptive label used adaptivity contextually sensitive response make approach towards completely unsupervised machine learning feasible unsupervised learning mean identification user context without requiring manually annotating current state unsupervised machine learning technique independently cluster sensor quantity associate interaction cluster discretization enables learning observation time interaction observed interpreted labeled example used construct statistical model contextdependent preference example contextaware parameter following location nearby people device calendar cyber sensor information movement pattern characteristic preference interest behavior pattern mapping observable parameter cognitive state computing system estimate form interaction minimizes distraction risk cognitive overload capability herein proposed extend significantly stateoftheart sometimes radical fashion time incrementally approach produce enriched observation combining machine learning instrumentation software application sensor describing state context information erse sensor fusion symbolic signal sensor inferring context state go much beyond situationsensing currently practiced even experimental setting ,1
ML_193,machine learning application become common recent year important place many technological field cyber security language processing biometry automation possible see machine learning application many place personal assistant autonomous vehicle however like system machine learning number security risk addition general security vulnerability also vulnerability specific machine learning system attack targeting vulnerability encountered training production cause serious problem system split feature model sfm split feature model approach developed evasion attack evasion attack tried evade machine learning system performance system reduced adversarial input sfm feature splitted distributed different model thus feature prevented directly affecting output entire model result aimed prevent manipulation feature directly affecting output machine learning system effect security attack spam filter applied traditional learning model sfm examined performance sfm compared traditional machine learning model security attack experimental result demonstrate effectiveness sfm term maintaining accuracy adversarial input ,1
ML_194,evolutionary multitasking novel concept algorithm utilize implicit parallelism populationbased search solve several task efficiently last decade multitask learning harness underlying similarity learning task proved efficient many application extreme learning machine distinctive learning algorithm feedforward neural network similarity low computational complexity comparing convenient neural network training algorithm used many case data analysis modular training technique employing evolutionary multitask paradigm used evolve modular topology extreme learning machine though extreme learning machine much faster convenient gradientbased method need hidden neuron due random determination input weight proposed method combine evolutionary extreme learning machine multitask modular training defined evolutionary extreme learning machine different number hidden neuron method produce modular extreme learning machine need le number hidden unit could effective even hidden neuron connection removed experiment result show effectiveness generalization proposed method benchmark classification problem ,1
ML_195,hottest frontier technology field artificial intelligence machine learning subverting various industry step step future penetrate aspect life become indispensable technology around u among network security area machine learning show strength among many network security problem privacy protection difficult problem need introduction technology method idea machine learning help solve problem research content include four part overview machine learning significance machine learning network security application process machine learning network security research application machine learning privacy protection focus issue related privacy protection proposes combine advanced matching algorithm deep learning method information theory data protection technology introduce biometric authentication ensuring loss matching accuracy minimal highstandard privacy protection algorithm concluded enables business government entity end user widely accept privacy protection technology ,1
ML_196,machine learning artificial intelligence adopted varying application automation flexibility cyber security different researcher engineer investigating data���driven technology harden security cyberinfrastructure possibility attacker exploiting vulnerability technology eg adversarial machine learning however much investigated attacker might try take advantage machine learning ai technology u chapter discus potential advance targeted attack utilization machine learning technique chapter introduce concept ai���driven malware advance already sophisticated cyber threat ie advanced targeted attack rise furthermore demonstrate prototype ai���driven malware built top set statistical learning technology two distinct cyber���physical system ie raven���ii surgical robot building automation system experimental result demonstrate support ai technology malware mimic human attacker deriving attack payload custom target system determining opportune time trigger attack payload maximize chance suct record real threat driven machine learning model however advanced malware might already exist simply remain undetected hope chapter motivates research advanced offensive technology favor adversary know prepared ,1
ML_197,data set grow leveraging machine learn valuable pattern structured data extremely powerful volume data large comprehensive analysis range potential correlation relationship disparate data source great analyst test hypothesis derive value buried data machine learning ml ideal exploiting opportunity hidden big data machine learning type artificial intelligence ai allows software application become accurate predicting outcome without explicitly programmed basic machine learning build algorithm take input data statistical analysis predict output value acceptable range explores basic machine learning discussing concept topic like supervised unsupervised reinforcement learning regression classification model evaluation metric overfitting variance versus bias linear regression ensemble method model selection decision tree random forest several several case machine learning applied including limited aerospace internet thing iot computer network analytics case applicability ai ml reviewed case finally latest trend machine learning discussed ,1
ML_198,recent year significant advance technology & amp tactic area cyber security ml machine learning forefront transformation ability obtain security event characteristic finding cyber security information develop matching information model allow security system become autonomous smart widespread proliferation usage web smartphone application increased size cyber world consequence computerized assault take long complete internet becomes vulnerable security measure may improved recognizing reacting cyberattacks thanks cyber security technique security measure previously used arent longer appropriate scammer learned evade getting difficult detect formerly unknown unpredictable security breach growing widespread cyber security becoming dependent machine learning ml technique machine learning algorithm dependability remains major challenge given continual advancement possible find malicious hacker internet ready exploit ml defect made thorough machine learning technique safeguarding cyberspace attack provided present literature cyber security machine learning method vulnerability scanning spam filtering threat detection desktop network well smart phone network among thing provides brief description machinelearning technique security info essential machinelearning technology evaluation parameter classification method ,1
ML_199,machine trained human being feeding massive amount data like example instruction learn without human intervention internet thing iot still outset developing front iot consisting devicesmachines erse sensor associated together wireless network need great amount security avoiding unauthorized access network collect transmit data packet industrial field showing much interest forefront intrusion threat make vulnerable addressing several positive measure regarding machine learning ml modality like supervised learning sl unsupervised learning ul semi supervised learning ssl reinforcement learning rl support vector machine svm used training iot device also address brief survey scenario machine learning algorithm applied various iot device network signal authentication security network flow information retrieval traffic management spectrum sensing also indicates necessity surveying scattered work machine deep learning application various aspect like security congestion control wireless computer network embedded sensor system iot application several limitation existing research number research issue fellow researcher may find useful future also discussed ,1
ML_200,many engineering program university across country dropped machine shop manufacturing course curriculum due budget constraint accreditation requirement concern student safety university portland resurrected enhanced handson advanced cad automated manufacturing course introduces student advanced solid modeling technique cad sweep loft surfacing method addition student learn manual machining vacuum forming machine shop learning create tool path cnc machining designed cad part wax various three axis end mill printer laser scanner end mill refurbished andor repaired period four year get course running commercial software package mastercam used conjunction solidworks platform learn automated manufacturing addition makerbot printer built kit give student experience future manufacturing technique laser scanner student designed built creates cad surface model part useful learning reverse engineering machinable wax used machining recycled melted formed block reuse save considerable money goal enhance design quality curriculum experiential learning prior taking course mechanical engineering student required take solid modeling cad course learn basic however experience student conceptually understand importance designing manufacture although emphasized course without handson experience difficult student remember apply fillet radius bottom pocket example faced fit block sharp corner machined pocket default small corner radius however learning instantaneous early outcome course show student learned great deal design manufacturing manufacturing technique taking course ,1
ML_201,extreme learning machine elm gained increasing interest various research field recently researcher proposed various extension improve stability sparsity generalization performance propose robust sparse elm exploit inlineformula texmath notationlatex $ l_ { } $ texmathinlineformulanorm minimization loss function regularization lrelm inlineformula texmath notationlatex $ l_ { } $ texmathinlineformulanormbased loss function diminish undue influence noise outlier data point compared inlineformula texmath notationlatex $ l_ { } $ texmathinlineformulanorm based loss function make learned elm model robust stable powerful structural sparseinducing inlineformula texmath notationlatex $ l_ { } $ texmathinlineformulanorm regularization integrated elm objective function eliminate potential redundant neuron elm adaptively reduce complexity learning model introduce effective iterative optimization algorithm solve inlineformula texmath notationlatex $ l_ { } $ texmathinlineformulanorm minimization problem empirical test number benchmark datasets indicate proposed algorithm generate compact robust discriminative model compared original elm algorithm ,1
ML_202,highdimensional crowdsourced data collected numerous user produce rich knowledge society however also brings unprecedented privacy threat participant local differential privacy ldp variant differential privacy recently proposed stateoftheart privacy notion unfortunately achieving ldp highdimensional crowdsourced data publication raise great challenge term computational efficiency data utility end based expectation maximization em algorithm lasso regression first propose efficient multidimensional joint distribution estimation algorithm ldp develop local differentially private highdimensional data publication algorithm lopub taking advantage distribution estimation technique particular correlation among multiple attribute identified reduce dimensionality crowdsourced data thus speeding distribution learning process achieving high data utility extensive experiment realworld datasets demonstrate multivariate distribution estimation scheme significantly outperforms existing estimation scheme term communication overhead estimation speed moreover lopub keep average % % accuracy released datasets term support vector machine random forest classification respectively ,1
ML_203,explosive growth multimedia data internet make essential develop innovative machine learning algorithm practical application especially small number labeled sample available manifold regularized semisupervised learning mrssl thus received intensive attention recently successfully exploit local structure data distribution including labeled unlabeled sample leverage generalization ability learning model although many representative work mrssl including laplacian regularization lapr hessian regularization explore exploit local geometry data manifold still challenging problem introduce fully efficient approximation algorithm graph plaplacian significantly saving computing cost propose plapr plapr preserve local geometry specifically plaplacian natural generalization standard graph laplacian provides convincing theoretical evidence better preserve local structure apply plapr support vector machine kernel least square conduct implementation scene recognition extensive experiment scene dataset scene dataset ucmerced dataset validate effectiveness plapr comparison conventional manifold regularization method ,1
ML_204,social medium data country challenge free speech reliable form journalism analysis conducted examine social medium response venezuelan food shortage filtered spanish tweet city caracas venezuela used observe reaction city five municipality number tweet december october month compared top trending tweet july machine learning technique show certain tweet may linked municipality km radius tweet volume almost two year indicates significance shortage among venezuelan people engaged event ,1
ML_205,proposes smartwatchbased system measuring emotion iniduals classroom setting respect five mood variable activation tiredness pleasance quality presentation understanding internal body external environment data movement heart rate noise temperature humidity collected builtin sensor smartwatch system verified mean longitudinal carried series workshop lecture experiencebased sampling participant polled periodic time interval asking enter selfassessment aforementioned mood state directly smartwatch goal demonstrate whether sensor data used effectively predict five mood resorting machine learning approach system able predict mood accuracy ranging % singleoutput classification % chain classification approximately % multioutput analysis result showed also body signal better predictor compared external environmental variable result demonstrate verify potential smartwatches collecting predicting human emotion enabling dynamic feedback loop enhance experience ,1
ML_206,area planning state space search often conducted find solution usually heuristic derived knowledge domain many case knowledge domain limited domain complex effective heuristic formulated alternative machinelearning technique neural network may used derive heuristic game freecell selected suitable benchmark domain knowledge based heuristic neural heuristic employed find solution randomly generated game amalgamation two neural network developed heuristic several knowledge based heuristic also used neural derived heuristic bestcase architecture employ knowledge based heuristic moreover neural heuristic able improve upon defined priori ,1
ML_207,automatic speech generation algorithm enhanced deep learning technique enable increasingly seamless immediate machinetohuman interaction result latest generation phonecalling bot sound convincingly human previous generation application technology strong social impact term privacy issue eg customercare service fraudulent action eg social hacking erosion trust eg generation fake conversation reason crucial identify nature speaker either human bot propose speech classification algorithm based convolutional neural network cnns enables automatic classification human v nonhuman speaker analysis short audio excerpt evaluate effectiveness proposed solution exploiting real human speech database populated audio recording various source automatically generated speech stateoftheart texttospeech generator based deep learning eg google wavenet ,1
ML_208,twitter data applied address wide range application eg political election prediction disease tracking however study conducted explore interaction potential relationship twitter data social event available government entity introduce novel approach investigate spatiotemporal relationship sentiment aspect tweet civil complaint recorded case database freely available city san francisco also result two supporting task apply sentiment analysis technique model emotional characteristic five metropolitan area around globe allowing one gain insight relative happiness across city neighborhood city quantify performance several opensource machine learning algorithm sentiment analysis applying large volume twitter data thereby providing empirical guideline practitioner major contribution finding include developed system relative ranking happiness geographical area result show sydney australia happiest five city found counterintuitive positive correlation frequency local sentiment performing sentiment analysis tweet inclusion emoticon training dataset lead model fitting whereas nlpbased feature seem great potential improve classification accuracy ,1
ML_209,novel predicament quantitative data science generated abundance large wellcured data set biological social science coupled extraordinary increase computational ability possibility sophisticated study combined remedial understanding analytics intelligent system cover architecture hardware platform application software method technique tool anticipated adapting dynamic memory information processing parametric value large data sheet optimization would faster field bigdata analytics recent trend data science study various mean preprocessing analyzing filtering huge semistructured data set different source complex handled traditional data processing system addition extracting aggregating data various performance measure proposal also forecast potential value kpis key performance indicator alert unfavorable value occur ai ml implemented different platform sector including chatbots robotics social medium healthcare selfdriven automobile space exploration large company investing field demand ml ai expert growing accordingly python becoming popular language ai artificial intelligence machine learning due rich supported tool proposed application icare intelligent care provide recommendation improve quality bigdata analytics proposed examines methodology requirement architecture modeling analytics implementation describes architectural design result obtained pilot application python powerful tool like panda scikitlearn ,1
ML_210,machine learning software unfair making humanrelated decision prejudice certain group people existing primarily focus proposing fairness metric presenting fairness improvement approach remains unclear key aspect machine learning system feature set training data affect fairness present result comprehensive address problem find enlarging feature set play significant role fairness average effect rate % importantly contrary widelyheld belief greater fairness often corresponds lower accuracy finding reveal enlarged feature set higher accuracy fairness perhaps also surprisingly find larger training data help improve fairness result suggest larger training data set unfairness smaller one feature set insufficient important cautionary finding practising software engineer ,1
ML_211,soft demodulation demapping received symbol back conveyed soft bit bit loglikelihood ratio llrs heart modern receiver trainable universal neural networkbased demodulator architecture dubbed llrnet introduced llrnet facilitates improved performance significantly reduced overall computational complexity instance commonly used quadrature amplitude modulation qam llrnet demonstrates llr estimate approaching optimal log maximum aposteriori inference order magnitude le operation straightforward exact implementation linklevel simulation example application llrnet gnr dvbs provided llrnet yet another powerful example usefulness applying machine learning physical layer design ,1
ML_212,machine learning ml increasingly used credit analysis also known credit scoring however vast majority article focus ml technique delve relevant variable define good bad payer objective research identify published work variable define customer default well identify lead consumer take credit even though resource repay achieve objective systematic literature carried combination automatic search resulted article relevant study found credit score similar rating analysis method variable used model changed ,1
ML_213,many realworld data set machine learning data mining contain missing value much previous research regard problem attempt impute missing value training testing issue costsensitive learning considers test cost misclassification cost attribute test expensive obtaining value would costeffective miss value similar skipping expensive risky test missing value patient diagnosis classification missing useful missing value actually reduces total cost test misclassifications therefore meaningful impute value discus compare several strategy utilize known value missing useful cost reduction costsensitive decision tree learning ,1
ML_214,summary form given follows claim notion connectionism evolving one since publication pdp bookwhich enumerated accepted principle connectionism many idea proposed many development occurred according claim connectionism today different connectionism yesterday example development connectionism include hybrid connectionistsymbolic model sun neurofuzzy model keller bezdek reinforcement learning model kaelbling et al sutton barto geneticevolutionary algorithm mitchell support vector machine reference newer connectionist model many violation older connectionist principle one simplest violation reading setting connection weight network external agent system mean mechanism external setting reading weight envisioned early connectionism need local learning law external source set weight network ? feature newer method obviously direct conflict early connectionism context algorithmic development said maybe nobody stage clear definition connectionism everyone make thing term basic principle go case ? pose problem field ? defend situation argue connectionism one principle many ? case ? redefine connectionism given need type learning method basis current knowledge brain work ? panel intends closely examine issue focused intensive way debate expected hope least clarify fundamental notion issue concerning connectionism hopefully also make progress understanding need go near future ,1
ML_215,internet thing iot come towards peak time includes smart city smart building smart home smart kitchen smart appliance security smart home smart health smart factory smart machine smart supply chain smart transportation smart manufacturing autonomous vehicle smart consumer device etc infrastructure management based smart system sensor crowdsourcing information source future iot success depends optimization approach application interface allocation behaviour evolution technology system security iot success realized major development system engineering process tool able overcome challenge iot network talk discus state art bioinspired research communication technology iot network example system engineering discus computational iterative optimization introduced bioinspired algorithm inspired living creature organism discus example learned intelligence living organism nature bioinspired algorithm taxonomy evolution swarm ecology network immune overcome challenge resource constraint scalability heterogeneity mobility security discussed optimization technique used research network protocol conventional mathematical programming bioinspired metaheuristic approach lead heuristic robust low complexity parallel structure exposed presentation also discus bioinspired algorithm application network deployment clustering routing security ,1
ML_216,recent emergence ubiquitous smart communication device accelerate people post current trending topic real time micro blog tweet post multimedia content social medium site geographical location tag geotags specifically recent flood tamilnadu early warning flooded area emerged get posted popular social medium geoparsed hash tag continuously humanitarian view realtime crisis sparked great interest designing innovative methodology big social medium data analysis supervised machine learning technique actuate immediate disaster response rescue effort near future proposed system performs disaster tweet collection based trending disaster hash tag system performs naivebayesian multinomial ssvm classification collected tweet identify severity disaster based locationtointerpolation cluster proximity disaster geographic map generated affected area approach detects tweet fitted correct classifier label generate output detection rate % % time predicted disaster mapping result highly accurate % real time geoparsed tweet matched actual location atrisk flood ,1
ML_217,fluxflow interactive visual analysis system revealing analyzing anomalous information spreading social medium everyday million message created commented shared people social medium website twitter facebook provides valuable data researcher practitioner many application domain marketing inform decisionmaking distilling valuable social signal huge crowd message however challenging due heterogeneous dynamic crowd behavior challenge rooted data analyst capability discerning anomalous information behavior spreading rumor misinformation rest conventional pattern popular topic newsworthy event timely fashion fluxflow incorporates advanced machine learning algorithm detect anomaly offer set novel visualization design presenting detected thread deeper analysis evaluated fluxflow real datasets containing twitter feed captured significant event hurricane sandy quantitative measurement algorithmic performance qualitative interview domain expert result show backend anomaly detection model effective identifying anomalous retweeting thread frontend interactive visualization intuitive useful analyst discover insight data comprehend underlying analytical model ,1
ML_218,propose novel machine learning based equalization algorithm imdd pon extend capacity pon gbps�� gbps�� gb pampam imdd transmission achieved km ssmf gclas,1
ML_219,objective train svm based localized multiple kernel learning arbitrary formula formulatypeinlinetex notationtex $ l_ { p } $ tex formulanorm constraint alternating optimization standard svm solver localized combination base kernel associated samplespecific kernel weight unfortunately latter form difficult formula formulatypeinlinetex notationtex $ l_ { p } $ texformulanorm constraint quadratic optimization letter approximating formula formulatypeinline tex notationtex $ l_ { p } $ texformulanorm taylor expansion problem updating localized kernel weight reformulated nonconvex quadratically constraint quadratic programming solved via associated convex semidefinite programming relaxation experiment ten benchmark machine learning datasets demonstrate advantage approach ,1
ML_220,ergence measure two probability distribution positive array positive measure useful tool solving optimization problem optimization signal processing machine learning statistical inference csiszar ifiergence unique class ergences information monotonicity dual ialphai geometrical structure fisher metric derived bregman ergence another class ergences give dually flat geometrical structure different ialphaistructure general csiszar gave axiomatic characterization ergences related inference problem kullbackleibler ergence proved belong class one space probability distribution prof ialphaiergences constitute unique class belonging class space positive measure positive array considered canonical ergences derived dually flat geometrical structure space positive measure ,1
ML_221,revisits integer programming ip problem play fundamental role many computer vision machine learning application literature abounds many seminal work address problem focusing continuous approach eg linear program relaxation others discrete one eg mincut however since many method designed solve specific ip form adequately satisfy simultaneous requirement accuracy feasibility scalability end propose novel versatile framework called $ \ell _p $ ���pbox admm based two idea discrete constraint equivalently replaced intersection box $ \ell _p $ ���pnorm sphere infuse equivalence alternating direction method multiplier admm framework handle continuous constraint separately harness attractive property importantly admm update step lead manageable subproblems continuous domain demonstrate efficacy apply optimization form occurs often computer vision machine learning namely binary quadratic programming bqp case admm step simple computationally efficient moreover theoretic analysis global convergence $ \ell _pdmm adding perturbation sufficiently small factor $ \epsilon $ �� original ip problem specifically globally converged solution generated $ \ell _p $ ���pbox admm perturbed ip problem close stationary feasible point original ip problem $ o\epsilon $ o�� demonstrate applicability $ \ell _p $ ���pbox admm three important application mrf energy minimization graph matching clustering result clearly show significantly outperforms existing generic ip solver runtime objective also achieves competitive performance stateoftheart method designed speci,1
ML_222,collaborative filtering cf become standard approach solve recommendation system problem collaborative filtering algorithm try make prediction interest collecting personal interest multiple user multiple cf algorithm one bias machine learning practitioner choose best algorithm beforehand recommender system different algorithm different performance different user dataset meta learning used choose best algorithm given problem meta learning usually applied select algorithm whole dataset adapting select algorithm single r involves several challenge important design metafeatures typical meta learning characterize datasets must characterize single present metalearning based framework named tex $ \mu\mathbf { cf } \mathbf { vec } $ tex select best algorithm propose representation learning technique extract metafeatures representation learning try extract representation reused learning task also implement framework different rl technique evaluate one useful solve meta level meta learning model metafeatures extract knowledge used predict best algorithm evaluated implementation framework movielens dataset implementation achieved consistent gain meta level however base level achieved marginal gain ,1
ML_223,documentation comment important software project although documentation executed useful many purpose code comprehension reuse maintenance project evolves code documentation easily grow outofsync inconsistency introduced mislead developer introduce bug subsequent development recent study shown promising natural language processing machine learning detect inconsistency code documentation however challenging apply existing technique detect codedocument inconsistency rust program rustdoc support advanced document feature like document testing make existing solution inapplicable present first software tool prototype r detect understand codedocument inconsistency rust perform analysis r leverage static program analysis rust source code also document testing code detect inconsistency indicating either bug bad documentation evaluate effectiveness r applied source rust project domain total line rust source code line comment result analysis give interesting insight example cryptocurrency domain highest documentation ratio % documentation testing rarely used ratio % average realworld rust project domain etc based finding propose recommendation guide construction better rust documentation better rust documentation quality detection tool boarder adoption language ,1
ML_224,support vector machine svm one widely used learning algorithm classification problem although svm good performance practical application high algorithmic complexity size training sample large introduce svm classification svmc algorithm based ktimes markov sampling numerical study learning performance svmc ktimes markov sampling benchmark data set experimental result show svmc algorithm ktimes markov sampling smaller misclassification rate le time sampling training also obtained classifier sparse compared classical svmc previously known svmc algorithm based markov sampling also give discussion performance svmc ktimes markov sampling case unbalanced training sample largescale training sample ,1
ML_225,human activity analysis video increasingly attracted attention computer vision research massive number video accessible online although many recognition algorithm reported recently activity representation challenging recently manifold regularized sparse coding obtained promising performance action recognition simultaneously learns sparse representation preserve manifold structure propose generalized version laplacian regularized sparse coding human activity recognition called plaplacian regularized sparse coding plsc proposed method exploit plaplacian regularization preserve local geometry plaplacian nonlinear generalization standard graph laplacian tighter isoperimetric inequality result plsc provides superior theoretical evidence standard laplacian regularized sparse coding proper p also provide fast iterative shrinkagethresholding algorithm optimization plsc finally input sparse code learned plsc algorithm support vector machine conduct extensive experiment unstructured social activity attribute dataset human motion database hmdb human activity recognition experimental result demonstrate proposed plsc algorithm outperforms manifold regularized sparse coding algorithm including standard laplacian regularized sparse coding algorithm proper p ,1
ML_226,concept entropy play key role information theory statistic machine learning introduces entropy measure called tentropy exploit concavity inversetan function analytically show proposed tex $ $ texentropy satisfies prominent axiomatic property entropy measure demonstrate application proposed entropy measure multilevel thresholding image also propose entropicloss measure ergence two probability distribution lead robust estimator context parametric statistical inference consistency asymptotic breakdown point proposed estimator mathematically analysed finally also show application tex $ $ texentropy feature weighted data clustering ,1
ML_227,massive information communication technology supervisory control data acquisition scada system open way carrying cyberattacks critical infrastructure relying scada network various vulnerability system heterogeneity cyberattacks make extremely difficult traditional intrusion detection system id modeling cyberattacks become nearly impossible potential consequence may severe primary objective detect malicious intrusion already bypassed traditional id firewall investigates machine learning intrusion detection scada system oneclass classification algorithm two approach oneclass classification investigated support vector data description svdd kernel principle component analysis impact considered metric examined detail lpnorms radial basis function rbf kernel heuristic proposed find optimal choice bandwidth parameter kernel test conducted real data several type cyberattacks ,1
ML_228,extreme learning machine elm attracted attention pattern recognition field due remarkable advantage fast operation straightforward solution strong generalization however performance elm highdimensional data hyperspectral image still problem therefore introduce elm hyperspectral image classification furthermore order overcome drawback elm caused randomness input weight bias two algorithm ensemble extreme learning machine baggingbased adaboostbased elm proposed classification order illustrate performance proposed algorithm support vector machine svms used evaluation comparison experimental result real hyperspectral image collected reflective optic spectrographic image system rosis airborne visibleinfrared imaging spectrometer aviris indicate proposed ensemble algorithm produce excellent classification performance different scenario respect spectral spectral���spatial featur,1
ML_229,research learning shown student learn differently prefer different type resource adaptive educational system support different learning characteristic building model student learning behaviour subsequently adapting learning environment match different need however major challenge exist clear student model learning style accurately built one solution may machine learning technique present first aid novel adaptive educational system dynamically determines learning style machine learning technique describes us feider & amp solomon index learning style design environment different learning style also describes student interacts learning environment us naive bayes algorithm predict student preferred learning style adaptively customize learning environment ,1
ML_230,petroleum analytics learning machine palm machinelearningbased brutally empirical analysis system managing internet thing iot upstream midstream oil gas operation palm developed unconventional shale oil gas play america simultaneous analysis hundred iot attribute hundred horizontal well thousand hydraulic fracture stage must analyzed near realtime palm validated shale oil gas well hydraulic fracture stage permian basin tx marcellus basin pa palm comprises machine analytics application apps bigdatacentric computational machine learning predictive prescriptive analysis technique maximize production natural gas hydrocarbon liquid minimizing cost operation palm predictive prescriptive technology utilize support vector machine learning signature realtime random forest decision tree steer hydraulic fracture become high instead low oil gas producer completion horizontal shale well progress palm also us support vector regression logistic regression bayesian model nearest neighbor neural network deep learning network uniquely combined ensemble learning tool weigh importance hundred thousand geological geophysical engineering attribute measured field iot computed theoretical analysis reservoir simulation model seismic monitoring production change time palm iot system since method written separate apps strung together operator utilizing oil gas well attribute compute importance weight predicted oil gas water production allows forecasting accurate estimated ultimate recovery eur lifetime well ,1
ML_231,spoken language understanding slu component goaloriented dialogue system aim interpret user natural language query system semantic representation format current stateoftheart slu approach achieve high performance english domain true language approach literature extending slu model grammar language rely primarily machine translation pose challenge scaling language machine translation system may reliable several especially low resource language examine different approach train slu component little supervision two language hindi turkish show hundred labeled example surpass approach proposed literature experiment show training model bilingually ie jointly english enables faster learning model requires fewer labeled instance target language generalize qualitative analysis show rare slot type benefit bilingual training ,1
ML_232,tutorial part series elearning course designed help prepare examination become certified software development professional csdp learn specific software engineering topic course series address one fifteen knowledge area comprise software engineering body knowledge swebok upon certification exam based course module list textbook course relevant reference material assist preparing certification exam mathematical fundamental software engineering provide mathematical underpinnings construction software product desired attribute provide mathematical foundation model facilitate reasoning product interrelation well form basis predictable design process course intended ass understanding mathematical foundation inline quiz feedback specific topic addressed course basic propositional predicate logic mathematical set function relation technique making valid argument way counting discrete event evaluate efficiency graphical representation abstract problem solving discrete probability formal grammar finite state machine regular expression numerical precision accuracy number theory algebraic structure boolean algebra ,1
ML_233,article term intelligence artificial intelligence ai computational intelligence ci topic addressed include historical evolution term ai ci seductive semantics term machine learning owe heavy debt intuitive idea intelligence evolution ieee computational intelligence society role buzzword play life researcher ,1
ML_234,melanoma deadliest form skin cancer automated skin lesion analysis play important role early detection nowadays isic archive atlas dermoscopy dataset employed skin lesion source benchmark deeplearning based tool however datasets contain bias often unintentional due acquired annotated bias distort performance machinelearning model creating spurious correlation model unfairly exploit contrarily destroying cogent correlation model could learn propose set experiment reveal type bias positive negative existing skin lesion datasets result show model correctly classify skin lesion image without clinicallymeaningful information disturbingly machinelearning model learned image information lesion remains present accuracy ai benchmark curated dermatologist performance strongly suggests spurious correlation guiding model fed model additional clinically meaningful information failed improve result even slightly suggesting destruction cogent correlation finding raise awareness limitation model trained evaluated small datasets one evaluated may suggest future guideline model intended realworld deployment ,1
ML_235,learning content video easy traditional machine learning approach computer vision difficulty satisfactorily however past year machine learning community seen rise deep learning method significantly improve accuracy several computer vision application eg convolutional neural network convnets explore suitability convnets movie trailer genre classification problem assigning genre movie particularly challenging genre immaterial feature physically movie frame offtheshelf image detection model directly applied context hence propose novel classification method encapsulates multiple distinct convnets perform genre classification namely connect convnet learns feature capture distinct aspect movie frame compare novel approach current stateoftheart technique movie classification make wellknown image descriptor lowlevel handcrafted feature result show connect significantly outperforms stateoftheart approach moving towards effectively solving genre classification problem ,1
ML_236,internet thing iot device usage grown adopted various daily device applied healthcare smart home smart grid connected car list go iot device security vulnerability completely guarantee data privacy case network iot device also prone hack hardware intrinsic hi attack hardware trojan ht firmware modification memory manipulation manifestation hi attack lead various type security issue includes data theft denial traditional ht attack detection technique valid integrated circuit level considered invasive iot device therefore propose noninvasive approach investigates hardware intrinsic attack detection iot hiadiot device approach detects covert channel power depletion attack power profile iot device different mode operation utilizing machine learning algorithm power profile behavior different iot device observed period time preprocessed serve data point data point provided random forest algorithm correctly classifies % data point recognizes potential hi attack ,1
ML_237,automated composition process creating software automated fashion studied many different way last decade however impact automated composition rather small utility realworld application demonstrated far describes case automated machine learning realworld scenario automated composition play important role turn existing composition approach able reasonably solve problem requires evaluate candidate executing search briefly sketch composition algorithm mlsplan illustrate applied problem automated machine learning ,1
ML_238,machine learning ml become prevalent across many critical domain need understand ml system resilience previous focused building ml fault injector application level little enabling fault injection ml application lower level lltfi tool development allows user run fault injection experiment cc++ tensorflow pytorch application llvm ir level lltfi provides user greater fault injection granularity better ability understand fault manifest propagate programmed ml component demonstrate lltfi applied ml application endtoend example ,1
ML_239,many system execute untrusted program virtual machine vms limit access system resource sun introduced java vm primarily intended lightweight platform execution untrusted code inside web page recently microsoft developed net platform similar goal platform share many design implementation property key difference java net impact security examines net design avoids vulnerability limitation discovered java discus lesson learned missed java experience security ,1
ML_240,order address defective surface product traditional manufacturing detection efficiency accuracy defect improved sort product effectively combination indepth learning machine vision technology realize accurate detection product quality first place product data image collected machine vision illuminating system uploaded cloud analyzing data image convolutional neural network model built used train ide test set indepth learning last model applied check sample product defective surface classify type defect high accuracy efficiency machine vision cloud collect analyze quality data indepth learning improves detection accuracy ,1
ML_241,brief present subthreshold voltage ider based strong physical unclonable function puf puf derives uniqueness random mismatch threshold voltage inverter gate drain shorted biased subthreshold region nonlinear currentvoltage relationship subthreshold region also make proposed puf resistant machine learning ml based attack prediction accuracy puf response logistic regression support vector machine svm multilayer perceptron mlp close % prototype puf fabricated nm consumes pjbit achieves best combination energy efficiency resistance ml attack measured inter intra hamming distance hd puf respectively ,1
ML_242,handbook ict developing country next generation ict technology second volume handbook ict developing country first volume potential implementation delivery forthcoming g network focus technology service enabled g network broadband internet network including artificial intelligence ai machine learning augmented reality internet thing iot autonomous driving blockchain solution cloud solution etc already globally experiencing growth existing network expected grow substantially future example currently % global organization fully adopted ai penetration expected increase rapidly iot billion device connected estimated show billion device connected expected growth based delivering value business citizen however obvious growth also occur developing country currently digital ide developing country developed country widening mostly due lack infrastructure low level awareness business citizen value made possible technology developing country book discus potential technology developing country need market intervention facilitate demand supply side market designed broad audience including practitioner researcher academic policy maker industry player influencers language approach handbook combination academic writing style professional review ,1
ML_243,cambridge analytica scandal exemplified social medias perceived threat democratic institution process cambridge analytica���a data firm hired donald trump ted cruz presidential campaign funded republican hedge fund machine learning pioneer robert mercer���allegedly altered result year u election uk brexit referendum immodest statement made cambridge analytica ceo alexander nix partly fueled allegation speech concordia summit nix claimed responsibility cruzs success year primary nix explained cruz generally unliked unrecognized beginning primary campaign cruzs embrace���through cambridge analytica���of behavioral science psychographics addressable ad technology big data powered steady rise end came second trump specifically cambridge analytica created profile every adult united state america targeted swung,1
ML_244,signal processing sp landscape enriched recent advance artificial intelligence ai machine learning ml yielding tool signal estimation classification prediction manipulation layered signal representation nonlinear function approximation nonlinear signal prediction feasible large scale dimensionality data size leading significant performance gain variety longstanding problem domain like speech image analysis well providing ability construct class nonlinear function eg fusion nonlinear filtering book help academic researcher developer graduate undergraduate student comprehend complex sp data across wide range topical application area social multimedia data collected social medium network medical imaging data data covid test etc book focus ai utilization speech image communication yirtual reality domain ,1
ML_245,many small medium scale business afford procure expensive cybersecurity tool many case even procurement lack workforce knowledge standard architecture enterprise security tool often used ineffectively editor developed multiple project help developing cybersecurity solution architecture right tool opensource software domain book chapter describing project detail recipe opensource tooling obtain standard cyber defense ability selfpenetration testing vulnerability assessment book also demonstrates related malware analysis machine learning implementation honeypot network intrusion detection system security operation center environment essential reading cybersecurity professional advanced student ,1
ML_246,educational data mining edm one emerging field pedagogy andragogy paradigm concern technique research data coming educational domain edm promising discipline imperative impact predicting student academic performance includes transformation existing innovation approach derived multidisciplinary sphere influence statistic machine learning psychometrics scientific computing etc archetype covered book learning example intention reader easily able replicate given example adapt suit need teachinglearning content book based research undertaken author theme mining educational data analysis prediction student academic performance basic knowhow presented book treated guide educational data mining implementation r rattle source data mining tool technical topic discussed book include ��� emerging research direction educational data mining ��� design aspect developmental framework system ��� model development building classifier ��� educational data analy,1
ML_247,since launch secondgeneration network g planning future mobile initiated many year commercial launch g network begun deployed commercially almost ten year planning similarly race g wireless network operational already started fulfill potential upcoming decade g undoubtedly require architectural orchestration based amalgamation existing solution innovative technology book begin evaluating state art current mobile generation looking core building block g implementation require fundamental support artificial intelligence ai machine learning network edge core including radio frequency rf spectrum g case require advanced technique enabling future wireless network humancentric ensuring enhanced quality experience qoe application concept human bond communication beyond knowledge home communication navigation sensing service conasense also profit future wireless communication terahertz domain exploit ultramassive multiple input multiple output antenna ummimo technology support terabit data throughput moreover optical wireless communication owc also come play support indoor outdoor highdata rate expansion g core entity support novel concept society quantum computing processing communication also likely added g ecosystem security managed blockchain orchestration robust network ,1
ML_248,robot autonomous vehicle unmanned aerial vehicle smart factory significantly change human living style digital society artificial intelligence wireless robotics introduces wireless communication networking technology enhances facilitation artificial intelligence robotics bridge basic multidisciplinary knowledge among artificial intelligence wireless communication computing control robotics unique aspect book introduce applying communication signal processing technique enhance traditional artificial intelligence robotics multiagent system technical content book include fundamental knowledge robotics cyberphysical system artificial intelligence statistical decision markov decision process reinforcement learning state estimation localization computer vision multimodal data fusion robot planning multiagent system networked multiagent system security robustness networked robot ultrareliable lowlatency machinetomachine networking example exercise provided easy effective comprehension engineer wishing extend knowledge robotics ai wireless communication would benefited book meantime book ready textbook senior undergraduate student firstyear graduate student electrical engineering computer engineering computer science general engineering student reader book shall basic knowledge undergraduate probability linear algebra basic programming capability order enjoy deep reading ,1
ML_249,since creation beginning world ii radar forever transformed practice modern warfare evolution countermeasure conducted electronic warfare system radar radar corresponding counter countermeasure intriguing technical subject book provides accessible introduction broad range radar electronic warfare technology subject covered book range early radar development later technology stealthy technique low probability intercept radar machine learning historical event used illustrate principle electronic warfare help reader apprehend context radar corresponding electronic warfare technique developed ,1
ML_250,ai hype fear mirror mirror wall smartest u ? result announced lee sedols eye swell tear alphago artificial intelligence ai developed google deepmind secured victory game go march two decade earlier chess grandmaster garry kasparov lost machine deep blue computer program eighteentime world champion lee sedol complex game seen one human could play intuition strategic thinking computer following rule given programmer mean machine learning based million past go match playing case programmer prepare data set create algorithm know move program come ai learns number unusual surprising move lee resign borowiec ,1
ML_251,emergence huge amount data require analysis case realtime processing forced exploration fast algorithm handling lage data size analysis xray image medical application cyber security data crime data telecommunication stock market data health record business analytics data area interest application platform including r rapidminer weka provide basis analysis often used practitioner pay little attention underlying mathematics process impacting data often lead inability explain result correct mistake spot error applied data analytics principle application seek bridge missing gap providing sought technique big data analytics establishing strong foundation topic provides practical ease big data analysis undertaken widely available source commercially orientated computation platform language visualisation system book combined platform provides complete set tool required handle big data lead fast implementation application book contains mixture machine learning foundation deep learning artificial intelligence statistic evolutionary learning mathematics written usage point view rich explanation concept mean author thus avoided complexity often associated concept found research paper tutorial nature book application provided reason book suitable undergraduate postgraduate big data analytics enthusiast text ease fear mathematics often associated practical data analytics support rapid application artificial intelligence environmental sensor data modelling analysis health informatics business data analytics data internet thing deep learning application ,1
ML_252,longstanding goal artificial intelligence build intelligent agent function linguistic dexterity people involves erse capability participating fluent conversation dialog support taskoriented collaboration engaging lifelong learning processing speech text much debate whether goal principle achievable since component problem arguably complex involved space exploration mapping human genome fact enabling machine emulate humanlevel language proficiency well understood aicomplete problem���one whose full solution requires solving problem artificial intelligence general however believe interest scientific progress technological innovation assume goal achievable proven otherwise question becomes best pur,1
ML_253,cyber security innovation digital economy considers possible solution relatively scientifictechnical problem developing innovative solution field cyber security digital economy solution proposed based result exploratory study conducted author area big data acquisition cognitive information technology cognotechnologies method analytical verification digital ecosystem basis similarity invariant dimension computational cognitivism involving number existing model method practice successfully allowed creation entity required safe trusted digital ecosystem basis development digital cyber security technology resulting change behavioral preference ecosystem understood certain system organization created around certain technological platform service make best offer customer access meet ultimate need client legal entity iniduals basis ecosystem certain technological platform created advanced innovative development including interface code machine learning cloud technology big data collection processing artificial intelligence technology etc mentioned technological platform allows creating best offer client good service offer external provider real time book contains four chapter devoted following subject ��� relevance given scientifictechnical problem cybersecurity digital economy ��� determination limiting capability ��� possible scientific technical solution ��� organization perspective research study area digital econom,1
ML_254,recent year advance machine learning brought idea artificial intelligence ai back limelight return ai spurred growing debate think ethic world semiintelligent machine one famous example ai ethic selfdriving carsuperscriptsuperscript know people prefer autonomous car selfsacrificing needed would crash avoid harming others even though would buy one themselvessuperscriptsuperscript also discovered people opinion moral action autonomous vehicle vary across globesuperscriptsuperscript yet ethic ai involves much morality autonomous vehicle ,1
ML_255,although researcher around world building machine could understand speech speak back number simple task first ai artificial intelligence assistant introduced number u user wildfire telephone assistant built wildfire communication bostonbased company funded wildfire responding number specific need combining convenience customizable directory functionality intelligent answering machine even though product successful commercial point view wildfire demonstrated welldesigned interface could cope deficiency speech recognition program imperfect technologysuperscriptsuperscript motivated user would learn system pleasantly sleek intelligently conceived interface welldesigned recorded prompt suggested option one could choose speech recognition could conveniently constrained recognize option profession voice interface vui design started wildfire ,1
ML_256,data science encompasses set principle problem definition algorithm process extracting nonobvious useful pattern large data set many element data science developed related field machine learning data mining fact term data science machine learning data mining often used interchangeably commonality across discipline focus improving decision making analysis data however although data science borrows field broader scope machine learning ml focus design evaluation algorithm extracting pattern data data mining generally deal analysis structured data often implies emphasis commercial application data science take consideration account also take challenge capturing cleaning transforming unstructured social medium web data bigdata technology store process big unstructured data set question related data ethic regulation ,1
ML_257,past decade seen remarkable series advance machine learning particular deeplearning approach based artificial neural network improve ability build accurate system across broad range area including computer vision speech recognition language translation natural language understanding task companion keynote talk international solidstate circuit conference isscc discussing advance machine learning implication kind computational device need build especially postmoores lawera also discus way machine learning may able help aspect circuit design process finally provides sketch least one interesting direction towards much largerscale multitask model sparsely activated employ much dynamic exampleand taskbased routing machine learning model today ,1
ML_258,internet everything become ubiquitous indeed around u reside background life predicted three decade ago three technology make ioe possible smart everyday object informationcentric network automated realtime insight highlighted central role electronics three pillar smart everyday object sense data everywhere created printed hybrid logic sensor circuit organic ink ink containing microchip informationcentric network increase internet versatility reduce traffic congestion improve security require novel hardware software creation automated realtime insight edge ioe network require deeplearning chip novel machineintelligence software ,1
ML_259,society increasingly relies machine learning model automated decisionmaking adm yet efficiency gain automation come paired concern algorithmic discrimination systematize inequality consequently research algorithmic fairness surged focusing either postprocessing trained model constraining learning process preprocessing training data recent proposed optimal postprocessing method randomize decision fraction iniduals order achieve fairness measure related calibration error parity contrast proposes alternative active framework deployment decisionmaker adaptively acquires information according need different group iniduals order balance disparity classification performance propose two method information collection adapted group iniduallevel need respectively show realworld data set achieve calibration single error parity eg equal falsenegatives parity falsepositive falsenegative rate ie equal odds moreover show fairness goal achieved substantially lower information cost avoiding limitation randomized classifier pareto suboptimality intragroup unfairness ,1
ML_260,handbook ict developing country next generation ict technology second volume handbook ict developing country first volume potential implementation delivery forthcoming g network focus technology service enabled g network broadband internet network including artificial intelligence ai machine learning augmented reality internet thing iot autonomous driving blockchain solution cloud solution etc already globally experiencing growth existing network expected grow substantially future example currently % global organization fully adopted ai penetration expected increase rapidly iot billion device connected estimated show billion device connected expected growth based delivering value business citizen however obvious growth also occur developing country currently digital ide developing country developed country widening mostly due lack infrastructure low level awareness business citizen value made possible technology developing country book discus potential technology developing country need market intervention facilitate demand supply side market designed broad audience including practitioner researcher academic policy maker industry player influencers language approach handbook combination academic writing style professional review ,1
ML_261,signal processing sp landscape enriched recent advance artificial intelligence ai machine learning ml yielding tool signal estimation classification prediction manipulation layered signal representation nonlinear function approximation nonlinear signal prediction feasible large scale dimensionality data size leading significant performance gain variety longstanding problem domain like speech image analysis well providing ability construct class nonlinear function eg fusion nonlinear filtering book help academic researcher developer graduate undergraduate student comprehend complex sp data across wide range topical application area social multimedia data collected social medium network medical imaging data data covid test etc book focus ai utilization speech image communication yirtual reality domain ,1
ML_262,design novel internet thing iot based agriculture automation machine learning ml implemented major source economy country agriculture get better production improvement technology iot ml improvement demand population growth agriculture parameter analyzed humidity sensor temperature sensor soil moisture sensor collected data sent web server iot machine learning algorithm applied data water motor water sprinkler sprinkle water gsm message send corresponding member last output obtained result observe accuracy system improved effectively ,1
ML_263,invesigate powerlink budget gbps laser communication comparison dml nonlinearity effect ofdm scfde discussed volterra machinelearning nonlinear compensation powerlink budget achieve db ,1
ML_264,mordvintsevs deepdream image went viral ian goodfellow university montreal came invention would redefine frontier machine learning generative adversarial network gans yann lecun geoffrey hinton pioneered modern revolution deep neural network declared gans interesting idea last year machine learningsuperscriptsuperscript ,1
ML_265,recent year increased availability reduced cost sensor system led plethora wearable smart sport watch track exertion activity sensor also embedded sport clothing game console accessory monitor activity stimulate gaming technical advancement like led increased interest exertion experience research community resulting term sportshci often humancomputer interaction around exercise health make underlying assumption human body seen machine monitoring measurable parameter neglecting human factor help user learn something want become get exertion experience monograph us focussed technique lens highlight factor interactive technology could deploy provide powerful opportunity design system designer interactive system exertion experience lens included monograph explore theoretical discussion around stimulating user technology lens unpacked three component provide designer practical handle engage design practice complemented design example suggest thinking lead particular design lens design sportshci stimulating read designer computing system include aspect exertion experience student researcher find wealth area research contained ,1
ML_266,since creation beginning world ii radar forever transformed practice modern warfare evolution countermeasure conducted electronic warfare system radar radar corresponding counter countermeasure intriguing technical subject book provides accessible introduction broad range radar electronic warfare technology subject covered book range early radar development later technology stealthy technique low probability intercept radar machine learning historical event used illustrate principle electronic warfare help reader apprehend context radar corresponding electronic warfare technique developed ,1
ML_267,robot autonomous vehicle unmanned aerial vehicle smart factory significantly change human living style digital society artificial intelligence wireless robotics introduces wireless communication networking technology enhances facilitation artificial intelligence robotics bridge basic multidisciplinary knowledge among artificial intelligence wireless communication computing control robotics unique aspect book introduce applying communication signal processing technique enhance traditional artificial intelligence robotics multiagent system technical content book include fundamental knowledge robotics cyberphysical system artificial intelligence statistical decision markov decision process reinforcement learning state estimation localization computer vision multimodal data fusion robot planning multiagent system networked multiagent system security robustness networked robot ultrareliable lowlatency machinetomachine networking example exercise provided easy effective comprehension engineer wishing extend knowledge robotics ai wireless communication would benefited book meantime book ready textbook senior undergraduate student firstyear graduate student electrical engineering computer engineering computer science general engineering student reader book shall basic knowledge undergraduate probability linear algebra basic programming capability order enjoy deep reading ,1
ML_268,emergence huge amount data require analysis case realtime processing forced exploration fast algorithm handling lage data size analysis xray image medical application cyber security data crime data telecommunication stock market data health record business analytics data area interest application platform including r rapidminer weka provide basis analysis often used practitioner pay little attention underlying mathematics process impacting data often lead inability explain result correct mistake spot error applied data analytics principle application seek bridge missing gap providing sought technique big data analytics establishing strong foundation topic provides practical ease big data analysis undertaken widely available source commercially orientated computation platform language visualisation system book combined platform provides complete set tool required handle big data lead fast implementation application book contains mixture machine learning foundation deep learning artificial intelligence statistic evolutionary learning mathematics written usage point view rich explanation concept mean author thus avoided complexity often associated concept found research paper tutorial nature book application provided reason book suitable undergraduate postgraduate big data analytics enthusiast text ease fear mathematics often associated practical data analytics support rapid application artificial intelligence environmental sensor data modelling analysis health informatics business data analytics data internet thing deep learning application ,1
ML_269,next decade artificial intelligence going redeploy job create source inequality generate trillion dollar profit control ai going become fabulously wealthy wealth alone going translate great political power yet political power ai go well beyond monetary value government transnational corporation tech entrepreneur machine learning intelligent automation also going strengthen foundational apparatus state power military policing security agency surveillance propaganda tool subjugation ,1
ML_270,industry first nm low power high performance mobile soc successfully ramped production thanks thorough designtechnology codevelopment nm soc % faster % smaller % lower power nm predecessor latest soc feature gigabit class modem set advance arvr ai machine learning computing nm finfet technology scaling challenge sharply increased wiring resistance variation strong layout stress effect discussed illustrate design technology codevelopment technology definition product ramp stage imperative realize scaling entitlement ,1
ML_271,internet thing iot machine learning ml commonly used field medical diagnostics health care monitor patient condition iot used create system functionality wearable series sensor warn patient event abnormality ml assisted medical diagnosis model designed detect anomaly patient condition health professional patient benefit iot technology access latest uptodate medical device setting furthermore medical application mostly interested iot minimize cost simplify process improve patient satisfaction increasing amount medical information provided iot used improving result patient ml approach health care method offer exciting application significant challenge development several application iot ml healthcare discussed g technology cloud computing manage smart healthcare system ,1
ML_272,since creation beginning world ii radar forever transformed practice modern warfare evolution countermeasure conducted electronic warfare system radar radar corresponding counter countermeasure intriguing technical subject book provides accessible introduction broad range radar electronic warfare technology subject covered book range early radar development later technology stealthy technique low probability intercept radar machine learning historical event used illustrate principle electronic warfare help reader apprehend context radar corresponding electronic warfare technique developed ,1
ML_273,emergence huge amount data require analysis case realtime processing forced exploration fast algorithm handling lage data size analysis xray image medical application cyber security data crime data telecommunication stock market data health record business analytics data area interest application platform including r rapidminer weka provide basis analysis often used practitioner pay little attention underlying mathematics process impacting data often lead inability explain result correct mistake spot error applied data analytics principle application seek bridge missing gap providing sought technique big data analytics establishing strong foundation topic provides practical ease big data analysis undertaken widely available source commercially orientated computation platform language visualisation system book combined platform provides complete set tool required handle big data lead fast implementation application book contains mixture machine learning foundation deep learning artificial intelligence statistic evolutionary learning mathematics written usage point view rich explanation concept mean author thus avoided complexity often associated concept found research paper tutorial nature book application provided reason book suitable undergraduate postgraduate big data analytics enthusiast text ease fear mathematics often associated practical data analytics support rapid application artificial intelligence environmental sensor data modelling analysis health informatics business data analytics data internet thing deep learning application ,1
ML_274,handbook ict developing country next generation ict technology second volume handbook ict developing country first volume potential implementation delivery forthcoming g network focus technology service enabled g network broadband internet network including artificial intelligence ai machine learning augmented reality internet thing iot autonomous driving blockchain solution cloud solution etc already globally experiencing growth existing network expected grow substantially future example currently % global organization fully adopted ai penetration expected increase rapidly iot billion device connected estimated show billion device connected expected growth based delivering value business citizen however obvious growth also occur developing country currently digital ide developing country developed country widening mostly due lack infrastructure low level awareness business citizen value made possible technology developing country book discus potential technology developing country need market intervention facilitate demand supply side market designed broad audience including practitioner researcher academic policy maker industry player influencers language approach handbook combination academic writing style professional review ,1
ML_275,alzheimers disease ad one leading cause death dementia worldwide early diagnosis confers many benefit including improved care access effective treatment however still medical challenge due lack efficient inexpensive way ass cognitive function although research data neuroimaging brain initiative advancement data analytics greatly enhanced understanding underlying disease process still lack complete knowledge regarding indicative biomarkers alzheimers disease recently computer aided diagnosis mild cognitive impairment ad functional brain image machine learning method become popular however prediction accuracy remains unoptimistic prediction accuracy ranging % % among support vector machine popular classifier however relatively small sample size amount noise functional brain imaging data single classifier achieve high classification performance instead global classifier aim improve ad prediction accuracy combining three different classifier weighted unweighted scheme rank imagederived feature according importance classification performance show top ranked feature localized brain area found associate progression ad test proposed approach cpib pet scan alzheimers disease neuroimaging initiative adni database demonstrated weighted ensemble model outperformed inidual model knearest neighbor random forest neural net overall cross validation accuracy % �� % specificity % �� % test accuracy % specificity % classification ad mild cognitive impairment healthy elde,1
ML_276,artificial intelligence going transform politics global sustainability next decade become crystal clear writing book machine learning particular making spectacular progress recent year great technological political socioeconomic environmental force unleashed power ai going keep rising whether like ,1
ML_277,chapter learn programming language feature eventdriven programming idea event ie occurrence phenomenon central computer programming manifest almost layer abstraction computer programming example computer hardware trigger event interrupt occurrence clock tick network packet arrival disk read command completed operating system higher layer software abstraction virtual machine application framework trigger event occurrence mouse button click window resizing dialog box click concept event also used representing describing software architecture design software architecture term system event called implicit invocation system sometimes publishsubscribe system software design idea event appears observer pattern needle say eventdriven programming integral part toolbox programmer ,1
ML_278,current approach machine learning lack important capability need developed achieve artificial general intelligence final chapter lay tool need ,1
ML_279,emergence huge amount data require analysis case realtime processing forced exploration fast algorithm handling lage data size analysis xray image medical application cyber security data crime data telecommunication stock market data health record business analytics data area interest application platform including r rapidminer weka provide basis analysis often used practitioner pay little attention underlying mathematics process impacting data often lead inability explain result correct mistake spot error applied data analytics principle application seek bridge missing gap providing sought technique big data analytics establishing strong foundation topic provides practical ease big data analysis undertaken widely available source commercially orientated computation platform language visualisation system book combined platform provides complete set tool required handle big data lead fast implementation application book contains mixture machine learning foundation deep learning artificial intelligence statistic evolutionary learning mathematics written usage point view rich explanation concept mean author thus avoided complexity often associated concept found research paper tutorial nature book application provided reason book suitable undergraduate postgraduate big data analytics enthusiast text ease fear mathematics often associated practical data analytics support rapid application artificial intelligence environmental sensor data modelling analysis health informatics business data analytics data internet thing deep learning application ,1
ML_280,machine learning ml internet thing iot two highly discussed extensively used research area current world highly essential sensitive arena healthcare perfect blend two component pave way striking innovation would potential cure numerous disease healthrelated issue one reason combining iot subset ai complementary plethora perspective iot easily used handle deal voluminous amount data flow processing ml algorithm used extract useful necessary information training data model furthermore unique combination two major technical concept would improve optimize efficiency operation medical field would significantly reduce load effort put medical fraternity indulge exploring deeper dwelling medical science curing disease moreover iot connects different device per need instantiates smooth flow interaction interconnected gadget device mainly talk role iot ml healthcare elucidates necessity wearable system communication standard ,1
ML_281,thirty year ago david bailey published humorous piece supercomputing magazine listing way presenting result artificially boost performance claim time debate cray twooxen machine versus parallel thousandchickens system parallel standard like mpi still unavailable top list didnt yet exist year since david others updated list trick time notably ��� marketing department intel nvidia really going georg hager blog scott pakin hpc wire heterogeneity computing system escalated last decade many remiss reporting tactic continue unabated ala two ingredient entered mix wide adoption machine learning technique science application system research swell concern reproducibility replicability talk twist way fool mass focusing researcher computational science highperformance computing miss mark conducting reporting result poor reproducibility showcasing lighthearted manner set antipatterns aim encourage u see value commit adapting practice achieve trustworthy scientific evidence highperformance comp,1
ML_282,growing demand diagnosing cardiovascular disease lead development solution automatic classification recorded ecg signal creating robust fast algorithm automatic classification ecg signal crucial improve quality healthcare especially country lack experienced specialist issue healthcare system overloaded aim physionetcomputing cardiology challenge create algorithm classification lead ecg based ecg signal multiple database across world shared training set consisted ecg recording lasting second bios team proposed machine learning algorithm based convolutional neural network ecg signal preprocessed moving median filter remove highfrequency noise baseline wandering developed simply convolutional neural network consisting four convolutional block one fully connected layer achieved challenge validation score full test score placing u official ranking ,1
ML_283,distance measurement technique highinterference environment ultrasonic array sensor direct sequence spread spectrum first explain timeofflight calculation method enhancing reflected wave object followed result obtained method object detection environment significant interference could achieved machine learning evaluation result show proposed method measure distance sensor static target range �� cm % accuracy target moving typical human walking speed range �� cm % accuracy also conducted measurement able detect object outdoors,1
ML_284,emergence huge amount data require analysis case realtime processing forced exploration fast algorithm handling lage data size analysis xray image medical application cyber security data crime data telecommunication stock market data health record business analytics data area interest application platform including r rapidminer weka provide basis analysis often used practitioner pay little attention underlying mathematics process impacting data often lead inability explain result correct mistake spot error applied data analytics principle application seek bridge missing gap providing sought technique big data analytics establishing strong foundation topic provides practical ease big data analysis undertaken widely available source commercially orientated computation platform language visualisation system book combined platform provides complete set tool required handle big data lead fast implementation application book contains mixture machine learning foundation deep learning artificial intelligence statistic evolutionary learning mathematics written usage point view rich explanation concept mean author thus avoided complexity often associated concept found research paper tutorial nature book application provided reason book suitable undergraduate postgraduate big data analytics enthusiast text ease fear mathematics often associated practical data analytics support rapid application artificial intelligence environmental sensor data modelling analysis health informatics business data analytics data internet thing deep learning application ,1
ML_285,emergence huge amount data require analysis case realtime processing forced exploration fast algorithm handling lage data size analysis xray image medical application cyber security data crime data telecommunication stock market data health record business analytics data area interest application platform including r rapidminer weka provide basis analysis often used practitioner pay little attention underlying mathematics process impacting data often lead inability explain result correct mistake spot error applied data analytics principle application seek bridge missing gap providing sought technique big data analytics establishing strong foundation topic provides practical ease big data analysis undertaken widely available source commercially orientated computation platform language visualisation system book combined platform provides complete set tool required handle big data lead fast implementation application book contains mixture machine learning foundation deep learning artificial intelligence statistic evolutionary learning mathematics written usage point view rich explanation concept mean author thus avoided complexity often associated concept found research paper tutorial nature book application provided reason book suitable undergraduate postgraduate big data analytics enthusiast text ease fear mathematics often associated practical data analytics support rapid application artificial intelligence environmental sensor data modelling analysis health informatics business data analytics data internet thing deep learning application ,1
ML_286,machine learning uncertainty describes margin error given measurement range value likely contain true data value critical cultural approach digital assistant reframes uncertainty strategy inquiry foreground range cultural value embedded digital assistant particularly useful exposing sort ideological truth enclosed andor foreclosed part parcel design implementation technology exploring anthropomorphic design digital assistant feminist critical race lens requires u confront dominant ideology race gender technology form kind cultural infrastructure undergirds technology design practice perspective uncertainty emerge common sense anthropomorphic design digital assistant particularly surrounding design strategy employed target vulnerable community behest state corporate commercial interest argue digital assistant technology mobilize belief race gender technology interface design way strategically cultivate experience ux interpellate user subject dismantle worker protection otherwise obscure smooth vast intimate datacapture project tracing destabilizing role anthropomorphic design system necessary step mapping larger role digital assistant play facilitating intimate data capture networked data environment ,1
ML_287,many company turning machine learning vast amount data evaluating credit loan application scanning legal contract error looking employee communication customer identify bad conduct tool allow developer build deploy machine learning engine easily ever amazon web service recently launched machine learning box offering called sagemaker nonengineers leverage build sophisticated machine learning model microsoft azure machine learning platform machine learning studio doesnt require coding ,1
ML_288,energyefficient knearestneighbor knn computation key building block computer vision classification machinelearning workload determining distance highdimensional vector large vector database result high compute cost adaptive precision improves energy efficiency eliminating majority vector without costly fullprecision computation asneeded precision refinement guarantee knn accuracy closely matched vector specialpurpose ondie knn accelerator dimension parallel reference vector targeted across mobile socs multicore microprocessor reconfigurable either manhattan euclidean distance fabricated nm trigate cmos partial distance compute circuit b windowbased sort msbtolsbbased selective distance refinement robust ultralow voltage circuit state tracking control selectively resume nextnearest candidate enable nominal energy efficiency njquery vector topsw measured vector cyclesvector mv ��c dense layout occupying mm fig achieving scalable performance vector mw measured mv ii cycle latency pj energy find subsequent net neighbor iii �� higher throughput maintaining fullprecision knn accuracy iv �� searchspace reduction nextnearest neighbor v ultralow voltage operation measured mv vector mw vi peak energy efficiency njvector mv nearthresh,1
ML_289,convolutional neural network cnn provide superior classification accuracy variety machine learning application imagespeechsensor data processing however cnns require intensive compute memory resource making challenging employ energyconstrained edgecomputing device specifically multiplyandaccumulate mac operation consume significant portion total cnn energy ,1
ML_290,never occurred would someday become omniscient practical purpose indeed anyone else access internet information flow internet speed light easier get fact internet book shelf living explosion information many form scientific instrument telescope microscope collecting larger larger data set analyzed machine learning national security agency us machine learning sift data collecting everywhere economy going digital programming skill great demand many company world shift industrial information economy education training adapt already profound impact world ,1
ML_291,emergence huge amount data require analysis case realtime processing forced exploration fast algorithm handling lage data size analysis xray image medical application cyber security data crime data telecommunication stock market data health record business analytics data area interest application platform including r rapidminer weka provide basis analysis often used practitioner pay little attention underlying mathematics process impacting data often lead inability explain result correct mistake spot error applied data analytics principle application seek bridge missing gap providing sought technique big data analytics establishing strong foundation topic provides practical ease big data analysis undertaken widely available source commercially orientated computation platform language visualisation system book combined platform provides complete set tool required handle big data lead fast implementation application book contains mixture machine learning foundation deep learning artificial intelligence statistic evolutionary learning mathematics written usage point view rich explanation concept mean author thus avoided complexity often associated concept found research paper tutorial nature book application provided reason book suitable undergraduate postgraduate big data analytics enthusiast text ease fear mathematics often associated practical data analytics support rapid application artificial intelligence environmental sensor data modelling analysis health informatics business data analytics data internet thing deep learning application ,1
ML_292,maurice wilkes head mathematics laboratory university cambridge england attended summer school taught moore school university pennsylvania learned edvac burk goldstine von neumann et al return voyage began design machine dubbed electronic delay storage automatic calculator edsac edsac running storedprogram computer called mark already operational england university manchester���a project mentioned wilkes piece turing chapter page manchester mark served experimental prototype computational workhorse followon machine put commercial production ferranti,1
ML_293,following topic dealt knowledge management reasoning neural network evolutionary programming image processing pattern recognition machine learning data mining natural language processing speech recognition information retrieval multiagent system ontology bioinformatics medical application intelligent tutoring system formal language automation software engineering data warehousing cryptography security computer network distributed system mobile computing control ,1
ML_294,emergence huge amount data require analysis case realtime processing forced exploration fast algorithm handling lage data size analysis xray image medical application cyber security data crime data telecommunication stock market data health record business analytics data area interest application platform including r rapidminer weka provide basis analysis often used practitioner pay little attention underlying mathematics process impacting data often lead inability explain result correct mistake spot error applied data analytics principle application seek bridge missing gap providing sought technique big data analytics establishing strong foundation topic provides practical ease big data analysis undertaken widely available source commercially orientated computation platform language visualisation system book combined platform provides complete set tool required handle big data lead fast implementation application book contains mixture machine learning foundation deep learning artificial intelligence statistic evolutionary learning mathematics written usage point view rich explanation concept mean author thus avoided complexity often associated concept found research paper tutorial nature book application provided reason book suitable undergraduate postgraduate big data analytics enthusiast text ease fear mathematics often associated practical data analytics support rapid application artificial intelligence environmental sensor data modelling analysis health informatics business data analytics data internet thing deep learning application ,1
ML_295,resistive crossbar array carry energyefficient vector���matrix multiplication crucial operation machine learning application however practical computing task require high precision remain challenging implement array intrinsic device variability herein experimentally demonstrate precisionextension technique whereby high precision attained combined operation multiple device store portion required bit width additionally designed analogtodigital converter used remove unpredictable effect noise source inlineformula texmath notationlatex $ \times $ texmathinlineformula carbon nanotube transistor array perform multiplication operation operand valid bit without error making inmemory computing approach attractive highthroughput energyefficient machine learning accele,1
ML_296,largearea electronics lae enables formation large number sensor capable spanning dimension order square meter example xray imagers scaling dimension number sensor today reaching million pixel however processing sensor data requires interfacing thousand signal cmos ic implementation complex function lae proven unviable due low electrical performance inherent variability active device available namely amorphous silicon asi thinfilm transistor tfts glass envisioning application perform sensing even greater scale present approach whereby highquality image detection performed directly lae domain tfts high variability number process defect affecting tfts sensor overcome machinelearning algorithm known adaptive boosting adaboost form embedded classifier adaboost show highdimensional sensor data reduced small number weakclassifier decision combined cmos domain generate strongclassifier decision ,1
ML_297,unprecedented growth deep neural network dnn size led massive amount data movement offchip memory onchip processing core modern machine learning ml accelerator computeinmemory cim design performing analog dnn computation memory array peripheral mixedsignal circuit explored mitigate memorywall bottleneck consisting memory latency energy overhead embeddeddynamic randomaccess memory edram integrates tc ttransistor ccapacitor dram bitcell monolithically highperformance logic transistor interconnects enable custom cim design offer densest embedded bitcell low pjbit access energy low soft error rate highendurance highperformance highbandwidth desired attribute ml accelerator addition intrinsic charge sharing operation dynamic memory access used effectively perform analog cim computation reconfiguring existing edram column charge domain circuit thus greatly minimizing peripheral circuit area power overhead configuring part edram cim engine data conversion dnn computation weight storage retaining remaining part regular memory input gradient training noncim workload data help meet layerkernel dependent variable storage need dnn inferencetraining step thus high costbit edram amortized repurposing part existing large capacity level edram cache highend microprocessor largescale cim engine ,1
ML_298,cloud edge device artificial intelligence ai machine learning ml widely used many cognitive task image classification speech recognition recent year research hardware accelerator ai edge device received attention mainly due advantage ai edge including privacy low latency reliable effective network bandwidth however traditional computing architecture cpu gpus fpgas even existing ai accelerator asics meet future need energyconstrained ai edge application ml computing datacentric energy architecture consumed memory access order improve energy efficiency academia industry exploring computing architecture namely compute memory cim cim research focused analog approach highenergy efficiency however lack accuracy due low snr disadvantage therefore analog approach may suitable application require high accuracy ,1
ML_299,artificial intelligence system called menndl used nvidia volta gpus oak ridge national laboratory summit machine automatically designed optimal deep learning network order extract structural information raw atomicresolution microscopy data hour menndl creates evaluates million network scalable parallel asynchronous genetic algorithm augmented support vector machine automatically find superior deep learning network topology hyperparameter set human expert find month application electron microscopy system furthers goal improving understanding electronbeammatter interaction realtime imagebased feedback enables huge step beyond human capacity towards nanofabricating material automatically menndl scaled available node summit achieving measured pflops estimated sustained performance pflops entire machine available ,1
ML_300,experimentally demonstrate heterodyne detection snr le db machine learning based optimized carrier phase estimation successful gbaud bpsk signal demodulation achieved without pilot signal ,1
ML_301,emergence huge amount data require analysis case realtime processing forced exploration fast algorithm handling lage data size analysis xray image medical application cyber security data crime data telecommunication stock market data health record business analytics data area interest application platform including r rapidminer weka provide basis analysis often used practitioner pay little attention underlying mathematics process impacting data often lead inability explain result correct mistake spot error applied data analytics principle application seek bridge missing gap providing sought technique big data analytics establishing strong foundation topic provides practical ease big data analysis undertaken widely available source commercially orientated computation platform language visualisation system book combined platform provides complete set tool required handle big data lead fast implementation application book contains mixture machine learning foundation deep learning artificial intelligence statistic evolutionary learning mathematics written usage point view rich explanation concept mean author thus avoided complexity often associated concept found research paper tutorial nature book application provided reason book suitable undergraduate postgraduate big data analytics enthusiast text ease fear mathematics often associated practical data analytics support rapid application artificial intelligence environmental sensor data modelling analysis health informatics business data analytics data internet thing deep learning application ,1
ML_302,emergence huge amount data require analysis case realtime processing forced exploration fast algorithm handling lage data size analysis xray image medical application cyber security data crime data telecommunication stock market data health record business analytics data area interest application platform including r rapidminer weka provide basis analysis often used practitioner pay little attention underlying mathematics process impacting data often lead inability explain result correct mistake spot error applied data analytics principle application seek bridge missing gap providing sought technique big data analytics establishing strong foundation topic provides practical ease big data analysis undertaken widely available source commercially orientated computation platform language visualisation system book combined platform provides complete set tool required handle big data lead fast implementation application book contains mixture machine learning foundation deep learning artificial intelligence statistic evolutionary learning mathematics written usage point view rich explanation concept mean author thus avoided complexity often associated concept found research paper tutorial nature book application provided reason book suitable undergraduate postgraduate big data analytics enthusiast text ease fear mathematics often associated practical data analytics support rapid application artificial intelligence environmental sensor data modelling analysis health informatics business data analytics data internet thing deep learning application ,1
ML_303,gan technology proliferates modern power electronics reliability ganbased circuit become biggest hurdle commercialization sustaining largest voltage current stress power circuit power device average account % failure problem current collapse thermal aging gan power circuit deem face reliability challenge compared silicon counterpart situation health condition monitoring paramount importance shown fig due hot electron injection charge trapping effect current collapse weakens dimensional electron gas deg layer gan switch time elevating dynamic onresistance rdson gradually clear link rdson aging fig make rdson widely accepted precursor gan condition monitoring however measuring rds_ simple traditionally r ds_ measured offline shutting affiliated circuit however approach highly inaccurate due significant discrepancy offline online operation condition mitigate issue insitu condition monitoring employed however still requires designated test period causing interruption operation increased test cost recent applies machine learning ml achieve online aging prognosis however ml algorithm generic built standard digital basis requires sophisticated data processing communication module causing substantial power cost overhead importantly offboard lookuptablebased training process performed offline leading similar drawback encountered approach overall approach reviewed demand significant resource time either trimming calibration training order compensate variation error induced fabrication process condition influence etc would much desirable efficient plugandplay online aging prognosis method developed essential part power circuit requires trimming calibration ,1
ML_304,embedded sensing system conventionally perform atod conversion followed signal analysis many application analysis interest inference eg classification sensor signal involved complex model analytically machine learning gaining prominence enables datadriven training classifier overcoming need analytical model present algorithmic formulation feature extraction classification combined single matrix reducing total multiplication needed matrixmultiplying adc mmadc enables multiplication input sample programmable matrix thus mmadc combine feature extraction classification data conversion mitigating need computation two system demonstrated ecgbased cardiacarrhythmia detector imagepixelbased gender detector ,1
ML_305,following topic dealt evolutionary computing genetic algorithm artificial intelligence data mining search algorithm pattern recognition speech understanding vision understanding learning algorithm planning scheduling fuzzy logic agent system computer network wireless network knowledge management image recognition software engineering computational intelligence image analysis image understanding machine learning optimization bioinformatics ,1
ML_306,following topic dealt information retrieval intelligent agent intelligent tutoring system elearning system knowledge discovery knowledge extraction knowledge representation reasoning machine learning neural network natural language processing speech processing vision video processing ,1
ML_307,respiration status person one vital sign used check health condition person respiration status measured various way medical healthcare sector contact type sensor conventionally used measure respiration contact type sensor used primarily medical sector used limited environment recent study evaluated way detecting human respiration pattern ultrawideband uwb radar relies noncontact type sensor previous study evaluated apnea pattern sleep analyzing respiration signal acquired uwb radar principal component analysis pca however necessary measure various respiration pattern addition apnea order accurately analyze health condition inidual healthcare sector therefore proposed method recognize four respiration pattern based convolutional neural network respiration signal acquired uwb radar proposed method extract eupnea bradypnea tachypnea apnea respiration pattern uwb radar composes learning dataset proposed method learned data cnn recognition accuracy measured result revealed accuracy proposed method % higher conventional classification algorithm ie pca support vector machine svm ,1
ML_308,intrusion detection system id play essential role computer network protecting computing resource data outside attack recent id face challenge improving flexibility efficiency id unexpected unpredictable attack deep neural network dnn considered popularly complex system abstract feature learn machine learning technique propose deep learning approach developing efficient flexible id onedimensional convolutional neural network dcnn twodimensional cnn method shown remarkable performance detecting object image computer vision area meanwhile dcnn used supervised learning timeseries data establish machine learning model based dcnn serializing transmission control protocolinternet protocol tcpip packet predetermined time range invasion internet traffic model id normal abnormal network traffic categorized labeled supervised learning dcnn evaluated model unsw_nb id dataset show effectiveness method comparison performance machine learningbased random forest rf support vector machine svm model addition dcnn various network parameter architecture exploited experiment model run epoch learning rate imbalanced balanced data dcnn variant architecture outperformed compared classical machine learning classifier mainly due reason cnn capability extract highlevel feature representation represent abstract form lowlevel feature set network traffic connection ,1
ML_309,show radial basis function network efficiently implemented systolic array author discus network framework probability density function approximation classification problem fact computation intensive part classification process consist calculating pattern distance initialisation phase algorithm involves calculating mutual intraclass distance matrix classification input vector mainly involves calculation distance vector input vector learning set vector proposed implementation systolic pipeline parallel practical implementation issue discussed mantra machine grid smart neurocomputer ring ,1
ML_310,robot autonomous vehicle unmanned aerial vehicle smart factory significantly change human living style digital society artificial intelligence wireless robotics introduces wireless communication networking technology enhances facilitation artificial intelligence robotics bridge basic multidisciplinary knowledge among artificial intelligence wireless communication computing control robotics unique aspect book introduce applying communication signal processing technique enhance traditional artificial intelligence robotics multiagent system technical content book include fundamental knowledge robotics cyberphysical system artificial intelligence statistical decision markov decision process reinforcement learning state estimation localization computer vision multimodal data fusion robot planning multiagent system networked multiagent system security robustness networked robot ultrareliable lowlatency machinetomachine networking example exercise provided easy effective comprehension engineer wishing extend knowledge robotics ai wireless communication would benefited book meantime book ready textbook senior undergraduate student firstyear graduate student electrical engineering computer engineering computer science general engineering student reader book shall basic knowledge undergraduate probability linear algebra basic programming capability order enjoy deep reading ,1
ML_311,spatial autoregressive ar model extensively used represent texture image machine learning application emphasizes contribution autoregressive model analysis synthesis textural image autoregressive model parameter feature set texture image represent texture used synthesis yule walker least square l method used parameter estimation test statistic choice proper neighbourhood n also suggested brodatz texture image album chosen experimentation parameter estimated texture test statistic decides best neighbourhood proper order model synthesized texture image original texture image compared perceptual similarity inferred proper neighbourhood given texture unique solely depends property texture ,1
ML_312,machine learning magic get something nothing get le programming like engineering lot build everything scratch learning like farming let nature farmer combine seed nutrient grow crop learner combine knowledge data grow program domingo ,1
ML_313,educational data mining edm one emerging field pedagogy andragogy paradigm concern technique research data coming educational domain edm promising discipline imperative impact predicting student academic performance includes transformation existing innovation approach derived multidisciplinary sphere influence statistic machine learning psychometrics scientific computing etc archetype covered book learning example intention reader easily able replicate given example adapt suit need teachinglearning content book based research undertaken author theme mining educational data analysis prediction student academic performance basic knowhow presented book treated guide educational data mining implementation r rattle source data mining tool technical topic discussed book include ��� emerging research direction educational data mining ��� design aspect developmental framework system ��� model development building classifier ��� educational data analy,1
ML_314,emergence huge amount data require analysis case realtime processing forced exploration fast algorithm handling lage data size analysis xray image medical application cyber security data crime data telecommunication stock market data health record business analytics data area interest application platform including r rapidminer weka provide basis analysis often used practitioner pay little attention underlying mathematics process impacting data often lead inability explain result correct mistake spot error applied data analytics principle application seek bridge missing gap providing sought technique big data analytics establishing strong foundation topic provides practical ease big data analysis undertaken widely available source commercially orientated computation platform language visualisation system book combined platform provides complete set tool required handle big data lead fast implementation application book contains mixture machine learning foundation deep learning artificial intelligence statistic evolutionary learning mathematics written usage point view rich explanation concept mean author thus avoided complexity often associated concept found research paper tutorial nature book application provided reason book suitable undergraduate postgraduate big data analytics enthusiast text ease fear mathematics often associated practical data analytics support rapid application artificial intelligence environmental sensor data modelling analysis health informatics business data analytics data internet thing deep learning application ,1
ML_315,handbook ict developing country next generation ict technology second volume handbook ict developing country first volume potential implementation delivery forthcoming g network focus technology service enabled g network broadband internet network including artificial intelligence ai machine learning augmented reality internet thing iot autonomous driving blockchain solution cloud solution etc already globally experiencing growth existing network expected grow substantially future example currently % global organization fully adopted ai penetration expected increase rapidly iot billion device connected estimated show billion device connected expected growth based delivering value business citizen however obvious growth also occur developing country currently digital ide developing country developed country widening mostly due lack infrastructure low level awareness business citizen value made possible technology developing country book discus potential technology developing country need market intervention facilitate demand supply side market designed broad audience including practitioner researcher academic policy maker industry player influencers language approach handbook combination academic writing style professional review ,1
ML_316,signal processing sp landscape enriched recent advance artificial intelligence ai machine learning ml yielding tool signal estimation classification prediction manipulation layered signal representation nonlinear function approximation nonlinear signal prediction feasible large scale dimensionality data size leading significant performance gain variety longstanding problem domain like speech image analysis well providing ability construct class nonlinear function eg fusion nonlinear filtering book help academic researcher developer graduate undergraduate student comprehend complex sp data across wide range topical application area social multimedia data collected social medium network medical imaging data data covid test etc book focus ai utilization speech image communication yirtual reality domain ,1
ML_317,saw previous chapter machine learning believe relationship observation interest know know exact form go ahead write computer program approach collect data example observation analyze discover relationship let u discus mean relationship extract data good idea example make discussion concrete ,1
ML_318,cyber security innovation digital economy considers possible solution relatively scientifictechnical problem developing innovative solution field cyber security digital economy solution proposed based result exploratory study conducted author area big data acquisition cognitive information technology cognotechnologies method analytical verification digital ecosystem basis similarity invariant dimension computational cognitivism involving number existing model method practice successfully allowed creation entity required safe trusted digital ecosystem basis development digital cyber security technology resulting change behavioral preference ecosystem understood certain system organization created around certain technological platform service make best offer customer access meet ultimate need client legal entity iniduals basis ecosystem certain technological platform created advanced innovative development including interface code machine learning cloud technology big data collection processing artificial intelligence technology etc mentioned technological platform allows creating best offer client good service offer external provider real time book contains four chapter devoted following subject ��� relevance given scientifictechnical problem cybersecurity digital economy ��� determination limiting capability ��� possible scientific technical solution ��� organization perspective research study area digital econom,1
ML_319,since creation beginning world ii radar forever transformed practice modern warfare evolution countermeasure conducted electronic warfare system radar radar corresponding counter countermeasure intriguing technical subject book provides accessible introduction broad range radar electronic warfare technology subject covered book range early radar development later technology stealthy technique low probability intercept radar machine learning historical event used illustrate principle electronic warfare help reader apprehend context radar corresponding electronic warfare technique developed ,1
ML_320,since launch secondgeneration network g planning future mobile initiated many year commercial launch g network begun deployed commercially almost ten year planning similarly race g wireless network operational already started fulfill potential upcoming decade g undoubtedly require architectural orchestration based amalgamation existing solution innovative technology book begin evaluating state art current mobile generation looking core building block g implementation require fundamental support artificial intelligence ai machine learning network edge core including radio frequency rf spectrum g case require advanced technique enabling future wireless network humancentric ensuring enhanced quality experience qoe application concept human bond communication beyond knowledge home communication navigation sensing service conasense also profit future wireless communication terahertz domain exploit ultramassive multiple input multiple output antenna ummimo technology support terabit data throughput moreover optical wireless communication owc also come play support indoor outdoor highdata rate expansion g core entity support novel concept society quantum computing processing communication also likely added g ecosystem security managed blockchain orchestration robust network ,1
ML_321,upon time tale artificial intelligence called snow white story wicked queen smart mirror activated command mirror mirror embedded voice assistant tell queen whether fairest course today technology render engineering mirror feasible little effort would camera connection smart mirror kingdom metric evaluate wicked queen appearance user gadget might machine learning algorithm training set derived people magazine beautiful list could based series upvotes downvotes however apprehension contemporary version famous grimm fairy tale outlined technical feasibility rather story reflects outdated value modernizing society truly smart mirror would tell wicked queen obsession triumphing singular beauty standard one prize pale skin youth misguided reductive futile topic though mirror would say seven product brighten skin ! ,1
ML_322,natural language processing nlp method used describe relationship machine human language chapter describes online voicebased test physically disabled applicant extract data candidate learning process called voice recognition nlp implemented speech transformed text format machine store text document detailing actual response text format correlated text document spacy algorithm response need wordbyword mark distributed ground similarity two sentence ,1
ML_323,propose whole brain fmrianalysis scheme identify autism spectrum disorder asd explore biological marker asd classification utilize spatial temporal information fmri method investigates potential benefit sliding window time measure temporal statistic mean standard deviation convolutional neural network cnns capture spatial feature sliding window created channel image used input cnn output cnn convolutional layer asd related fmri spatial feature directly deciphered input format sliding window parameter investigated power aligning channel image shown proposed method compared traditional machine learning classification model proposed ccd method increased mean fscores % ,1
ML_324,localization uhf rfid tag industrial environment difficult due signal reflection multipaths caused steel metal object existing solution shown decent accuracy small distance fail maintain accuracy distance antenna tag increase describe novel uhf rfid localization approach based location fingerprinting approach us machine learning transform localization classification problem location fingerprint generated output bartlett beamformer music algorithm estimate incoming angle signal evaluated approach industrial environment result show achieve high classification accuracy maintain increase distance tag antenna ,1
ML_325,propose approach realization model inspired biological solution pattern recognition approach based hierarchical modular structure capable learn example recognize object digital image adopted technique based multiresolution image correlation neural network performance two different data set experimental timing simd machine also reported ,1
ML_326,depth cue multiple image useful accurate depth extraction monocular cue single still image versatile monocular cue give useful information single frame depth motion optical flow estimated consecutive video frame used produce final depth map machine learning approach promising research direction field depth estimation thus conversion fast automatic technique proposed utilizes fixed point learning framework accurate estimation depth map test image contextual prediction function generated training database color ground truth depth image depth map obtained monocular motion depth cue input video frame used input feature learning process depth generated fixed point model accurate reliable mrf fusion depth cue stereo pair generated depth map predicted fixed point learning final stereo pair converted output video displayed dtv subjective evaluation mo score calculated showing final video different viewer glass ,1
ML_327,virtue simplicity high generalization capability training cost knearestneighbor knn classifier widely used pattern recognition machine learning however computation complexity knn classifier become higher dealing large data set classification problem consequence efficiency decreased greatly proposes general twostage training set condensing algorithm general knn classifier first identify noise data point remove original training set second general condensed nearest neighbor rule based socalled nearest unlike neighbor nun presented eliminate redundant sample training set order verify performance proposed method numerical experiment conducted several uci benchmark database ,1
ML_328,smart vehicle adaptive road condition exchange information vehicle avoid traffic congestion dangerous obstacle even traffic accident earlier technology closely related safety driver therefore must receive special attention vv communication potential threaten interference even attack many study focused finding solution deal disorder first step strengthen system ability detect attack vv hand development machine learning ml look promising support goal proposed scheme step prediction detecting attacker used system two classifier ml two modified training datasets show proposed scheme improve attack detection performance compared one detection step ,1
ML_329,supthsup generation jacinto��� soc platform evolution prior architecture integrates capability support wide set application including automotive industrial broad market drive erse set requirement need ip innovation technique across entire soc stack including highreliability technique automotive including circuit analysis screening ip development including dsp signal processing data movement architecture embedded vision machine learning imaging video acceleration security safety innovation including integrated safety mcu dedicated security controller hardware feature enable asild support soc platform first implementation also integrates technique simplified powersupply management support costsensitive system ondie microarchitecture sol,1
ML_330,better aim perfection miss aim imperfection hit one ��� thomas j watson srsuperscriptsuperscript company human being machine personality product people real estate ��� thomas j watson jrsuperscriptsuperscript feel essential client ��� ginni rometty seemed ibms long history circled back time time good time bad time facing challenge opportunity company adaptable changing circumstance often slowly herman hollerith understood essential notion thomas watson sr relentless tom watson jr behavior still repeated today ibm previous decade larger ecosystem multinational corporation still want learn ibms experience many multinational company entering global economy number interested party expanding especially asia learning western company step outside consumer electronics digital retail firm apple google dell amazon behind longestsurviving company ibm course history generated $,1
ML_331,following topic dealt bankruptcy prediction threefactor structural model credit risk analysis neural network support vector machine portfolio derivative hedging discrete trading genetic programming convertible bond option pricing generalized arbitrage pricing theory economic growth problem stock market hybrid auction mechanism inflation forecasting microeconomic modeling foreign exchange market investment risk high frequency financial data financial time series forecasting reinforcement learning selforganizing map stock prediction ,1
ML_332,conference proceeding published five volume volume deal speech processing volume ii deal sensor array multichannel signal processing signal processing theory method volume iii deal image multidimensional signal processing volume iv deal audio electroacoustics signal processing communication volume v deal design implementation signal processing system industry technology track machine learning signal processing multimedia signal processing signal processing education ,1
ML_333,following topic dealt image processing classification multimedia coding face gesture body analysis active learning multimedia information retrieval advanced video coding technique hdtv video application multimedia semantics graphic processing qos rate control broadcasting multimedia retrieval video coding emerging multimedia security technology digital right management multimedia streaming motion estimation video segmentation summarization structuring layered scalable multiple description transmission multimedia architecture video surveillance medium identification browsing large multimedia collection contentbased retrieval multimedia indexing representation virtual reality content protection smart multimedia acquisition system multimedia learning multimedia compression multimodalitybased medium semantic analysis noise removal face scene human song recognition multimedia editing authoring video streaming speech audio processingrecognition error concealment medium transmission multimedia distribution visual detection tracking video object detection analysis multimedia transcoding mobile imaging wireless multimedia technique humanmachine interface watermarking fingerprinting authentication automatic indexing multimedia communicationsnetworking content based music structure analysis video summarization content understanding transcoding technique medium adaptation interactive tv ,1
ML_334,following topic dealt vision based navigation tracking automation manufacturing process automation security surveillance adaptive navigation humanoid sensor network sensor fusion humanmachine interface visual servoing haptic device robot grasping medical robot application simultaneous localization mapping nanomanipulation probabilistic based planning robot vision petri net robot localization haptic interface human robot interface mem flexible automation smart sensor assembly human assisted robot stereo vision virtual reality application microrobotics robotics education visual tracking technique monitoring automation sensor evaluation telepresence teleoperation mobile robot design mechanism kinematics mechanism dynamic calibration path planning rehabilitation robotics space robot multirobot system multilegged robot underactuated system uav biomechanical system transportation automation manufacturing system automation quadruped robot learning technique supply chain automation reconfigurable robot multiagent system biped locomotion adaptive control omnidirectional robot scheduling disassembly range sensing motion control speech production robot environmental robot actuator map building collision avoidance flexible manipulator redundant manipulator auv discrete event system tracking pose estimation snake robot failure monitoring neuro fuzzy technique imaging ,1
ML_335,following topic dealt granular computing data mining knowledge engineering fuzzy set theory rough set theory uncertainty handling machine learning inference technique ,1
ML_336,following topic dealt neural network brain perceptual motor function cognitive function computational neuroscience artificial life biomimetic pattern recognition brain information processing cognitive neuroscience neurofuzzy modeling control application distribution control fdds selforganisation unsupervised learning language processing yingyang computation brain behavior machine learning sparse representation theory application computational intelligence economics finance kernel method learning dynamic informatics hardware application ,1
ML_337,following topic dealt speech processing spoken language processing image processing multidimensional signal processing signal processing education bio imaging bio signal processing industry technology track communication sensor array multichannel signal processing audio electroacoustics machine learning ,1
ML_338,following topic dealt speech processing spoken language processing image processing multidimensional signal processing signal processing education bio imaging bio signal processing industry technology track communication sensor array multichannel signal processing audio electroacoustics machine learning ,1
ML_339,following topic dealt sourcechannel coding distributed image video coding biomedical image segmentation steganography steganalysis content summarization clustering fingerprint iris analysis image registrationalignment mosaicking stereoscopic coding visual tacking deblurring image restoration facefacial expression detection recognition interpolation inpainting networkaware multimedia processing communication edge detection transcoding machine learning image fusion video networking communication watermarking lowlevel indexing retrieval image wavelet filter bank video streaming video surveillance soft computing image processing authentication cryptography forensics radar imaging block matchingbased motion estimation knowledgebased image processing classification recognition biometrics magnetic resonance imaging image enhancement image quality assessment dtv extraction representation compression transmission remote sensing ,1
ML_340,following topic dealt intelligent system system modeling control manufacturing system industrial application petri net humanmachine system smart sensory network soft computing robotic system application image processing intelligent transportation system enterprise information system grey system medical mechatronics computational intelligence infrastructure system service modeling automation vehicle navigation control distributed intelligent system oceanology pattern classification conflict risk analysis system management vehicle dynamic system control fuzzy system nationalinternational security bioinformatics control system wireless sensor network multimedia system neural network nonlinear optimization communication system fuzzy control medical informatics power system fuzzy system supply chain management multiagent system dynamic workflow modeling management intelligent internet medium computing system management discrete event system intelligent control granular computing machine learning decision support system uncertain system ,1
ML_341,following topic dealt biomedical signal image processing design implementation adaptive filtering detection estimation theory application machine learning bioinformatics genomic signal processing array processing radar sonar image multidimensional signal processing information forensics security data fusion multimedia signal processing joint sourcechannel coding nonlinear signal processing timefrequency timescale signal processing sensor array multichannel system speech language processing blind equalization source separation computer vision pattern recognition musical signal processing ,1
ML_342,following topic dealt machine learning signal processing computer graphic computer vision pattern recognition security information assurance computer network pp network embedded system system architecture wireless sensor network high performance network control high performance network management optical network database management information retrieval document text processing data software engineering information system application data management algorithm ,1
ML_343,following topic dealt audio electroacoustics biomedical imaging biomedical signal processing multidimensional signal processing information forensics security radar signal processing machine learning signal processing multimedia signal processing sensor array multichannel signal processing signal processing communication signal processing education speech processing spoken language processing ,1
ML_344,following topic dealt granular computing granular network modeling fuzzy set theory fuzzy control rough computing ontology learning data mining pattern clustering classification artificial intelligence neural network computing intrusion detection system bioinformatics support vector machine web intelligence information retrieval text mining quantum computing ,1
ML_345,following topic dealt sensor network sensor fusion intelligent sensor information processing sensor network sensor network security machine learning application autonomous configuration control dynamic wireless network middleware computational intelligence sensor network biosignal processing networked sensor healthcare environmental sensor network optimization sensor network ,1
ML_346,following topic dealt human mind modeling data mining human system interaction cognitive communication intelligent space manufacturing education computer supported collaborative medium environment blind people assistance navigation mobility stochastic modeling biology economics engineering hardware software codesign training genetic algorithm decision making learning adaptive system virtual reality web intelligence hci man machine interaction fault modeling simulation fuzzy system neural net robotics computer graphic autonomous agent natural language ontology semantics complex system knowledge based system ,1
ML_347,following topic dealt sensor network ersity multiplexing mimo spacetime code network coding machine learning multiuser information theory game theory distributed optimization fading channel queueing theory geometric learning multiuser interference multiple access channel communication network security stochastic analysis multiterminal source coding channel capacity ,1
ML_348,following concept discussed advanced knowledge modeling language tool knowledge capture machine learning knowledge discovery data base specific knowledge modeling issue cbr system cooperative kb training application knowledge acquisition text www evaluation method technique tool knowledge acquisition knowledge engineering software engineering uncertainty vagueness aspect knowledge modeling knowledge acquisition application library industry commerce government education knowledge acquisition intelligent system inclusive learning formal informal learning hci educational system transforming learning technology generation educational technology web social computing learning educational technology generation realtime assessment learning performance mobile computing learning instruction personalized educational system interdisciplinary program educational technologist cscl technology content authoring technology epedagogy instructional design knowledge management technology education organizational management elearning university e testing test theory data mining text mining web mining education ,1
ML_349,minimally supervised machine learning method based bootstrapping attractive approach advanced information extraction complex pattern signalling relevant semantic relation free text detected way however potential limitation method yet sufficiently understood systematically analyzed bootstrapping approach starting point analysis patternlearning graph subgraph bipartite graph representing connection linguistic pattern relation instance exhibited data shown performance general learning framework actual task dependent certain property data seed construction however greatest improvement obtained systematic learning negative pattern ,1
ML_350,following topic dealt pattern recognition computer vision image processing video motion analysis face recognition biometrics recognition medical image information biological information language speech multimedia robotics machine learning document analysis character recognition speech processing ,1
ML_351,following topic dealt augmented reality serious game social medium game student motivation engineering student gamification sedentary game car racing game formal medical education gamebased career guidance approach tourism marketing electronic game tourist player motivation gameful pedagogy collaborative learning gamebased learning agent crowd behaviour virtual city dapplications dgames serious computer game game engine selection mpeg based character animation framework video game prototype customised exergames gaming sensor vrbased safety evaluation automatically controlled machine tool pervasive gaming educational geogame braincomputer interface realtime rendered virtual environment interactive ant foraging simulator virtual world virtual environment client session opensimulator installation identity federation parkinson disease rehabilitation ,1
ML_352,following topic dealt intelligent system artificial intelligence bioinformatics computational biology knowledge management machine learning data mining knowledge discovery web mining web semantics humanmachine interaction intelligent behavior intelligent information security system rulebased system decisionmaking natural language processing speech processing image processing signal processing robotics identification system analysis multiagent system elearning decision support system evolutionary computation software engineering ,1
ML_353,following topic dealt learning artificial intelligence feature extraction internet thing internet cloud computing data mining cryptography image classification pattern classification support vector machine ,1
ML_354,following topic dealt learning artificial intelligence convolutional neural net neurophysiology medical image processing pattern clustering feature extraction disease image classification support vector machine eye ,1
ML_355,covid emerging disease transmissibility severity far effective therapeutic drug vaccine covid serious complication covid type pneumonia called novel coronavirusinfected pneumonia ncip % mortality rate comparing chest digital radiography dr recently reported chest computed tomography ct useful serve early screening diagnosis tool ncip aimed help physician make diagnostic decision develop machine learning ml approach automated diagnosis ncip chest ct different ml approach often require training thousand million sample design fewshot learning approach combine fewshot learning weakly supervised model training computerized ncip diagnosis total patient retrospectively collected two hospital irb approval first patient clinically confirmed ncip patient without known lung disease training location detector multitask deep convolutional neural network dcnn designed output probability ncip segmentation targeted lesion area experienced radiologist manually localizes potential location ncips chest ct covid patient interactively segment area ncip lesion reference standard multitask dcnn furtherly finetuned weakly supervised learning scheme caselevel labeled sample without lesion label test set patient independently collected evaluation ncipnet test auc system potential serve ncip screening diagnosis tool fight covids endemic pandemic ,1
ML_356,start igsc special session machine learning energy efficient processing ,1
ML_357,sunny march morning youre buttering bagel gulping coffee like youre looking forward commute youll conference call team catch news youre thankful dont actually drive car know way get car presented urgent message car immobilized need pay bitcoin ransom youre going anywhere right world billion connected device weve heard stat really mean iniduals society ? different ? fast shift occur ? ready ? learn one foremost iot thought leader world sensor device machine everywhere see others dont sending vast quantity data affect daily life change behavior influence thought innovation convenience security privacy well examine day life digital citizen identify implication world nearly everything connected question session answer world billion connected device look like ? device ? major way society interpersonal relation change world nearly everything connected ? world coming ready ? implication onslaught connectivity issue like privacy security ? ,1
ML_358,clearly many u needed meet discus teach behind computer screen yet increasing number author submitting ��� ojits confirming interest community gold access journal number submission grew ��� number paper published grew acceptance rate stable % % average time first final decision day respectively running around special topic topic machine learning deep learning led dr chihua chen attracted,1
ML_359,advance machine learning ml internetofthings iot resulted renewed interest analog matrixvector multiplication mvm accelerator classification based task exploited lowtomedium resolution multiplication accuracy boosting algorithm order compensate reduced resolution complementing classification task like source separation localization erse application ranging signal conditioning communication ultrasound electroencephalography eeg source localization spike sorting greatly benefit similar algorithm however due lower resolution limited channel count previously developed system directly applied highresolution analog multiplication introduces challenge limited prior le bit multiplication analog domain alternative approach utilizing high oversampling result inefficient solution high precision matrixmultiplication mitigate effect illconditioned almost singular matrix beamforming separation nearcollinear source task incurring principal component analysis independent component analysis ica seen fig large signal dynamic range input result untenable dynamic range specification downstream dataconverters leading greater �� increase power thus multichannel multipleinput multipleout mimo mixedsignal linear transform system analog signal path digital coefficient control composed array bit nested thermometer multiplying dacs ntmdacs implementing analog multiplication variable gain amplifier vga implementing accumulation demonstrate stateofthe art performance two task spectrally oblivious interference suppression communication signal eeg signal separat,1
ML_360,global influence big data growing seemingly endless trend leaning towards knowledge attained easily quickly massive pool big data today living technological world dr usama fayyad distinguished research fellow discussed introductory explanation knowledge discovery database kdd predicted nearly two decade ago indeed precise outlook big data analytics fact continued improvement interoperability machine learning statistic database building querying fused create increasingly popular sciencedata mining knowledge discovery next generation computational theory geared towards helping extract insightful knowledge even larger volume data higher rate speed trend increase popularity need highly adaptive solution knowledge discovery necessary research introducing investigation development bitquestions metaknowledge template big data processing clustering purpose research aim demonstrate construction methodology prof validity beneficial utilization brings knowledge discovery big data ,1
ML_361,ghz frequency modulated continuous wave radar system recognize human hand gesture implemented us commercial offtheshelf rf frontend ic one transmitter four receiver planar patch array antenna signal conditioning circuit interconnection pc designed system rangedoppler map four receiver channel obtained sawtooth chirping signal transmitted detect hand gesture radar system show realtime highly accurate gesture recognition longshort term memory recurrent neural network supervised machine learning technique used seven kind hand gesture recognized ���� center transmitted antenna % a,1
ML_362,matrix multiplication enabled multiplyandaccumulate hardware ubiquitous signal processing computer graphic machine learning optimization many important application inherent robustness reduced precision matrix multiplication eg inference neural network take advantage analog signal processing energy efficiency present cycle programmable passive switchedcapacitor matrix multiplier scmm codesigned bitlineless memory design exploit af unit fringe capacitor high speed low energy chargedomain processing contains input dac multiplyandaccumulate sar adc local memory two application scmm demonstrated analog frontend image classifier system reduces ad conversion x multiplyandaccumulate compute energy x conventional system coprocessing accelerator solve stochastic gradient descent optimization achieves measured topsw ghz ,1
ML_363,rise alwayslistening sensor integrated energyscarce device watch remotecontrols increase need intelligent scalable interface contemporary sensor interface digitize raw sensor data extract information energyintensive computation fft inefficient end goal extract selective information classification task eg voice activity detection vad previous show energy gain early data reduction analog feature extraction embedded classification hardware however potential energy saving device limited adapt change sensed information content sensing context amounttype acoustic background noise processor design community adaptivity varying operating condition actively researched concept hierarchical computing integrates concept hierarchical operation adaptive early data extraction classification towards power contextaware informationextraction sensor interface specifically report ��w nm cmos vad dynamically adapts sensing resource signal information content context thus spending energy relevant information extraction order maude power saving achieved exploiting hierarchical sensing runtime activatedscalable analog feature extraction tightlyintegrated contextaware mixedsignal machine learning inference enabling novel application area acoustic sensing ,1
ML_364,flipflops ffs key building block highperformance microprocessor discrete graphic hardware accelerator pushing frequency become increasingly critical due emerging application ai machine learning autonomous driving security timeborrowing tb ffs enable mean fix outlier maxdelay path reducing process variation clock skewjitter margin resulting higher frequency operation however tb ffs challenging due higher power cost lack area compatibility conventional ffs postplacement insertion furthermore increased design complexity require ffs scan circuit utilizing either levelsensitive scan design lssd grows area significantly delay overhead alternate areaefficient rnuxd scan higher delay tb fast muxd scan ff without scanmux delay overhead timing power vmin characterization circuit fabricated nm cmos occupying mmsupsup fig fast rnuxd ff achieves measured risefall mean setup time improvement psps psps risefall mean tb window p worstcase delay gain critical path mv ��c ii % energy overhead singlebit isoenergy dualbit tyl % data activity iii mvvmin improvement due writeback elimination iv singledualbit cell area compatibility muxd ff postplacement swapping v % blocklevel performance gain ,1
ML_365,dimensional federated learning dfl framework including vertical horizontal federated learning phase designed cope insufficient training data insecure data sharing issue cps secure distributed learning process considering specific application human activity recognition har across variety different device multiple inidual user vertical federated learning scheme developed integrate shareable feature heterogeneous data across different device full feature space horizontal federated learning scheme developed effectively aggregate encrypted local model among multiple inidual user achieve highquality global har model computationally efficient somewhat homomorphic encryption swhe scheme improved applied support parameter aggregation without giving access enables heterogeneous data sharing privacy protection across different personal device multiple user building precise personalized har model experiment conducted based two datasets comparing three conventional machine learning method evaluation result demonstrate usefulness effectiveness proposed model achieving faster smoother convergence better precision recall f score har application cps ,1
ML_366,atrial fibrillation af common arrhythmia & amp # x worldwide prevalence associated increased risk various cardiovascular disorder including stroke automated routine af detection electrocardiogram ecg based analysis onedimensional ecg signal requires dedicated software type device limiting wide especially rapid incorporation telemedicine healthcare system implement machine learning method af classification region interest roi corresponding long dii lead automatically extracted dicom lead ecg image observed & amp # x & amp # x & amp # x & amp # x sensitivity specificity auc f score respectively result indicate proposed methodology performs similar onedimensional ecg signal input require dedicated software facilitating integration clinical practice ecg typically stored pac image ,1
ML_367,magnetotelluric mt inversion machine learning scheme specifically supervised descent method sdm learns descent direction optimization problem applied mt data inversion inversion composed offline training online prediction offline stage descent direction learned set training data online stage data inversion achieved updating model learned direction sdm offer convinient way incorporate prior information mt inversion furthermore learning scheme achieve fast computation numerical test show may able reconstruct thin layer mt data enough information ,1
ML_368,matching aligning architectural imagery important step many application difficult due repetitive element often building many keypoint descriptor matching method fail produce distinctive descriptor region manmade structure cause ambiguity attempting match area image outline technique reducing search space matching taking twostep approach aligning pair one dimension time abstracting image originally contain many repetitive element set distinct representative patch also simple effective method computing intraimage saliency single image allows u directly identify unique area image without machine learning information find distinctive keypoint match across image pair show pipeline able overcome many pitfall encountered traditional keypoint regional matching technique commonly encountered image urban scene ,1
ML_369,automate bin picking robot pose estimation key challenge identifies locates object thus robot pick manipulate object accurate reliable way proposes novel solution combine machine learning based object localization nonmachine learning based pose estimation method estimate pose randomly piled industrial part given image scene target part localized first result used crop point cloud target part cropped point cloud boundarytoboundaryusingdirectionaltangentline bbdtl point pair feature novel descriptor proposed method could estimate pose industrial part whose point cloud lack key detail example point cloud ridge part algorithm evaluated real scene experimental result show proposed method sufficiently accurate online computation time short make could used real factory environment ,1
ML_370,objective radiomics emerging tool medical image analysis potential towards precisely characterizing gastric cancer gc whether oneslice annotation wholevolume annotation remains longtime debate especially heterogeneous gc comprehensively compared radiomic feature representation discrimination capacity regarding gc via three task tsuplnmsup lymph node metastasis prediction tsuplvisup lymphovascular invasion prediction tsupptsup pt pt stage classification method fourcenter gc patient retrospectively enrolled ided training validation cohort region interest roi annotated radiologist radiomic feature extracted respectively feature selection model construction procedure customed combination two modality three task subsequently six machine learning model modelsuplnmsupsubdsub modelsuplnmsupsubdsub modelsuplvisupsubdsub modelsuplvisupsubdsub modelsupptsupsubdsubs modelsupptsupsubdsub derived evaluated reflect modality performance characterizing gc furthermore performed auxiliary experiment ass modality performance resampling spacing different result regarding three task yielded area curve auc modelsuplnmdsups % confidence interval modelsuplnmsupsubdsubs modelsuplvisupsubdsubs modelsuplvisupsubdsubs modelsupptsupsubdsubs modelsupptsupsubdsubs moreover auxiliary experiment indicated modelssubdsub statistically advantageous modelssubdsub different resampling spacing conclusion model constructed radiomic feature revealed comparable performance constructed feature characterizing gc significance indicated timesaving annotation would better choice gc provided related reference radiomicsbased research ,1
ML_371,proposes scheme dd face recognition problem proposed framework mainly consists restricted boltzmann machine rbms correlation learning model framework singlelayer network based rbms adopted extract latent feature two different modality furthermore latent hidden layer feature different model projected formulate shared space based correlation learning several different correlation learning scheme evaluated proposed scheme evaluate advocated approach popular face datasetfrgcv experimental result demonstrate latent feature extracted rbms effective improving performance correlation mapping dd face recognition ,1
ML_372,gradient synchronization process communication among machine largescale distributed machine learning dml play crucial role improving dml performance since scale distributed cluster continuously expanding stateoftheart dml synchronization algorithm suffer latency thousand gpus article propose dhra twodimensional hierarchical ringbased allreduce algorithm largescale dml dhra combine ring latencyoptimal hierarchical method synchronizes parameter two dimension make full bandwidth simulation result show dhra efficiently alleviate high latency accelerate synchronization process largescale cluster compared traditional algorithm ring based dhra achieves % reduction gradient synchronization time cluster different scale ,1
ML_373,detection novel attack organizational network problem everincreasing relevance today society research area focused detection zeroday black swan event machine learning technology previous technology needed known example malicious behavior detect similar event recent advance anomaly detection network activity shown promise detecting novel attack real word environment however novel behavior occurs relatively frequently user utilize software application standard networking change notable importance network security technician may imminent threat network proposes novel method detection classification change networking behavior dynamic degenerative neural network dn change recognizable activity dynamically classified stored future reference timebased entropy function infrequent activity analyzed given precedence frequent activity aid classification abnormal activity fast efficient assessment relevant person organization proposed method enables detection classification scoring activity network evaluation proposed method based upon data gathered large multinational organization ,1
ML_374,advancement quantum computing security threat classical cryptography algorithm latticebased key exchange protocol show strong promise due resistance theoretical quantumcryptanalysis low implementation overhead contrast physical implementation shown vulnerability sidechannel attack scas even single power measurement stateoftheart scas however limited simple sequentialized execution postquantum keyexchange pqke protocol leaving vulnerability complex parallelized architecture unknown article proposes deepa deeplearning dlbased scatargeting parallelized implementation pqke protocol namely frodo newhope data augmentation technique specifically explore approach convert timeseries power measurement data image formulate sca image recognition result show attack superiority conventional technique including horizontal differential power analysis dpa template attack ta straightforward dl approach demonstrate improvement �� recover % success rate compared dl input data fewer data furthermore show machine learning impr result �� compared ta furthermore perform crossdevice attack obtain profile single device never explored approach especially favored setting improving success rate attacking frodo % % compared approach thus urge countermeasure even parallel architecture singletrace att,1
ML_375,discovering effective subset model pool classifier important remarkable topic ensemble learning scope meticulously selected subset instead entire ensemble lead efficient effective result introduces novel hybrid ensemble selection method firefly forward search algorithm two different selection phase proposed method called p twophase selection method empirical comparison method p two similar method performed ten standard machine learning problem result show method p lead % average accuracy improvement compared rival great success due ersity balancing error correcting capability p due nature firefly algorithm moreover p achieves second great success overhead reduction excluding redundant weaker model prediction due forward search algorithm ,1
ML_376,hardwareassisted malware detection hmd emerged promising solution improve security computer system hardware performance counter hpcs information collected runtime several recent study proposed machine learningbased solution identify malware hpcs rely large number microarchitectural event achieve high accuracy detection rate importantly largely overlooked complexityeffective prediction malware class runtime show detection performance malware classifier highly dependent number available hpcs varies significantly across class malware limited number available hpcs modern microprocessor simultaneously captured make runtime malware detection high detection performance existing solution challenging problem require multiple run application collect sufficient number microarchitectural event response first identify important hpcs hmd effective feature reduction method develop specialized twostage runtime hmd referred smart smart first classifies application multiclass classification technique either benign one malware class virus rootkit backdoor trojan second stage high detection performance smart deploys machine learning model work best class malware realize effective runtime solution relies available hpcs smart customized ensemble learning technique boost performance general malware detector experimental result show smart ensemble technique hpcs outperforms stateoftheart classifier hpcs % term detection performance average across different class malware ,1
ML_377,internet thing iot grown essential aspect modern age provides comfort human life massive connectivity device greater flexibility control security component iot system crucial device iot system exposed numerous malicious attack typical security component iot system performs authentication authorization message content integrity check since iot system resource constraint becomes bit difficult implement traditional security mechanism protocol example authentication implemented crypto module infeasible iot domain due distributed nature iot system physical unclonable function puf considered unique identification device cloned hence pufs beneficial iot domain perform basic security operation like authentication key generation etc however attack proposed various pufs machine learning technique model challengeresponse behavior propose two round sram puf spuf show better resistance machine learning modeling attack mlma wellknown machine learning technique test mlma resistance spuf design result show proposed puf architecture better resistance machine learning modeling attack ,1
ML_378,pneumothorax also called collapsed lung presence air outside lung space lung chest wall generally diagnosed chest xray however case diagnosis difficult medical condition appear similarly machine learning algorithm providing great assistance detecting locating pneumothorax lately propose stage training system segment image pneumothorax system built based unet stateoftheart fully convolutional network fcn architecture backbone residual network resnet pretrained imagenet dataset beginning train network lower resolution load trained model weight retrain network higher resolution moreover utilize different technique including stochastic weight averaging swa data augmentation testtime augmentation tta chest xray dataset provided siimacr pneumothorax segmentation challenge contains training image testing image experiment show stage training lead better faster network convergence method achieves mean dice coefficient placing among top % competitor rank ,1
ML_379,field machine learning image processing costless circuit low energy required instead extreme precision stochastic computing sc type approximate computing attracting attention sc stochastic number sn bit stream value appearance rate ` used sc enables calculation simple circuit make calculation result correct duplication sn generating sn value required sn value conventional sn duplicator composed flipflop ff problem output sn depends input sn therefore ffbased duplicator used circuit reconvergence path output sn becomes erroneous proposes sn duplicator supnsuprrr output independent output improved flexibility bit rearrangement duplicator error hyperbolic tangent function reduced % compared duplicator proposed previously also % circuit area reduced compared implementation binary computing ,1
ML_380,summary form given met workshop summary metamorphic testing mt testing technique exploit relationship among input output multiple execution program test called metamorphic relation mr mt proven highly effective testing program face oracle problem correctness inidual output difficult determine since introduction mt interest testing methodology grown immensely numerous application various domain machine learning bioinformatics computer graphic simulation search engine decision support cloud computing database compiler second international workshop metamorphic testing met bring together researcher practitioner academia industry discus research result experience mt ultimate goal met provide platform discussion novel idea perspective application state research related inspired mt ,1
ML_381,since launch secondgeneration network g planning future mobile initiated many year commercial launch g network begun deployed commercially almost ten year planning similarly race g wireless network operational already started fulfill potential upcoming decade g undoubtedly require architectural orchestration based amalgamation existing solution innovative technology book begin evaluating state art current mobile generation looking core building block g implementation require fundamental support artificial intelligence ai machine learning network edge core including radio frequency rf spectrum g case require advanced technique enabling future wireless network humancentric ensuring enhanced quality experience qoe application concept human bond communication beyond knowledge home communication navigation sensing service conasense also profit future wireless communication terahertz domain exploit ultramassive multiple input multiple output antenna ummimo technology support terabit data throughput moreover optical wireless communication owc also come play support indoor outdoor highdata rate expansion g core entity support novel concept society quantum computing processing communication also likely added g ecosystem security managed blockchain orchestration robust network ,1
ML_382,covid infectious virus caused acute respiratory syndrome sarscov march world health organization declared covid pandemic around case across country highly infectious disease raised significant challenge global health system sustained risk global spread health care industry looking forward technology fight disease artificial intelligence ai internet thing iot blockchain technology robotics etc smart innovative technology revolutionized health care industry recent past chapter focus role ai technology includes machine learning ml deep learning dl computer vision cv technique monitoring controlling spread covid ml technique widely explored predicting spread virus also provides useful information control spread cv technique useful diagnose infected patient computed tomography ct magnetic resonance imaging mri drug industry also exploring ai rapid design development covid vaccine ai enabled robot used hospital decrease workload doctor medical staff near future technology emerge useful tool fight disruption affecting life human ,1
ML_383,discus spam detection different machine learning model detect spam message also discus testing evaluation spam message spam message dangerous computer network bad effect computer security emergence social medium platform many people dependent email communicate need detect prevent spam mail enters user inbox also present analysis different machine learning technique detect spam message finally describes algorithm best detect spam message spam message basically redundant message sent large number seen many form like free service cheap sm plan lottery etc growing spam message mail make inbox filled ridiculous mail slow internet speed retrieve private information like credit card detail many drawback therefore important prevent best way possible ,1
ML_384,every three second human fingernail grows three nanometer much scale machine learning complicated important technologies���transistors���are m,1
ML_385,educational data mining edm one emerging field pedagogy andragogy paradigm concern technique research data coming educational domain edm promising discipline imperative impact predicting student academic performance includes transformation existing innovation approach derived multidisciplinary sphere influence statistic machine learning psychometrics scientific computing etc archetype covered book learning example intention reader easily able replicate given example adapt suit need teachinglearning content book based research undertaken author theme mining educational data analysis prediction student academic performance basic knowhow presented book treated guide educational data mining implementation r rattle source data mining tool technical topic discussed book include ��� emerging research direction educational data mining ��� design aspect developmental framework system ��� model development building classifier ��� educational data analy,1
ML_386,cyber security innovation digital economy considers possible solution relatively scientifictechnical problem developing innovative solution field cyber security digital economy solution proposed based result exploratory study conducted author area big data acquisition cognitive information technology cognotechnologies method analytical verification digital ecosystem basis similarity invariant dimension computational cognitivism involving number existing model method practice successfully allowed creation entity required safe trusted digital ecosystem basis development digital cyber security technology resulting change behavioral preference ecosystem understood certain system organization created around certain technological platform service make best offer customer access meet ultimate need client legal entity iniduals basis ecosystem certain technological platform created advanced innovative development including interface code machine learning cloud technology big data collection processing artificial intelligence technology etc mentioned technological platform allows creating best offer client good service offer external provider real time book contains four chapter devoted following subject ��� relevance given scientifictechnical problem cybersecurity digital economy ��� determination limiting capability ��� possible scientific technical solution ��� organization perspective research study area digital econom,1
ML_387,emergence huge amount data require analysis case realtime processing forced exploration fast algorithm handling lage data size analysis xray image medical application cyber security data crime data telecommunication stock market data health record business analytics data area interest application platform including r rapidminer weka provide basis analysis often used practitioner pay little attention underlying mathematics process impacting data often lead inability explain result correct mistake spot error applied data analytics principle application seek bridge missing gap providing sought technique big data analytics establishing strong foundation topic provides practical ease big data analysis undertaken widely available source commercially orientated computation platform language visualisation system book combined platform provides complete set tool required handle big data lead fast implementation application book contains mixture machine learning foundation deep learning artificial intelligence statistic evolutionary learning mathematics written usage point view rich explanation concept mean author thus avoided complexity often associated concept found research paper tutorial nature book application provided reason book suitable undergraduate postgraduate big data analytics enthusiast text ease fear mathematics often associated practical data analytics support rapid application artificial intelligence environmental sensor data modelling analysis health informatics business data analytics data internet thing deep learning application ,1
ML_388,author eighteenthcentury french encyclop��die midwifed birth language describe artisan machine course century became ancestor know today programming language printing text diagram artisan spoke workshop encyclopedist paired mechanical art liberal art coupling radical intervention time place two kept separate century french encyclopedist translated everyday language workshop language mechanical art language literature learned discourse language liberal ,1
ML_389,signal processing sp landscape enriched recent advance artificial intelligence ai machine learning ml yielding tool signal estimation classification prediction manipulation layered signal representation nonlinear function approximation nonlinear signal prediction feasible large scale dimensionality data size leading significant performance gain variety longstanding problem domain like speech image analysis well providing ability construct class nonlinear function eg fusion nonlinear filtering book help academic researcher developer graduate undergraduate student comprehend complex sp data across wide range topical application area social multimedia data collected social medium network medical imaging data data covid test etc book focus ai utilization speech image communication yirtual reality domain ,1
ML_390,robot autonomous vehicle unmanned aerial vehicle smart factory significantly change human living style digital society artificial intelligence wireless robotics introduces wireless communication networking technology enhances facilitation artificial intelligence robotics bridge basic multidisciplinary knowledge among artificial intelligence wireless communication computing control robotics unique aspect book introduce applying communication signal processing technique enhance traditional artificial intelligence robotics multiagent system technical content book include fundamental knowledge robotics cyberphysical system artificial intelligence statistical decision markov decision process reinforcement learning state estimation localization computer vision multimodal data fusion robot planning multiagent system networked multiagent system security robustness networked robot ultrareliable lowlatency machinetomachine networking example exercise provided easy effective comprehension engineer wishing extend knowledge robotics ai wireless communication would benefited book meantime book ready textbook senior undergraduate student firstyear graduate student electrical engineering computer engineering computer science general engineering student reader book shall basic knowledge undergraduate probability linear algebra basic programming capability order enjoy deep reading ,1
ML_391,artificial intelligence already changing life buy thing amazon watch movie netflix received recommendation thing buy movie watch suggestion made recommender system machine learning algorithm consumer history guess might like next ,1
ML_392,since creation beginning world ii radar forever transformed practice modern warfare evolution countermeasure conducted electronic warfare system radar radar corresponding counter countermeasure intriguing technical subject book provides accessible introduction broad range radar electronic warfare technology subject covered book range early radar development later technology stealthy technique low probability intercept radar machine learning historical event used illustrate principle electronic warfare help reader apprehend context radar corresponding electronic warfare technique developed ,1
ML_393,likely heard automatic speech recognition asr many time past hopefully experienced positive evolution technology however chance exposed asr voluntarily may frustrated annoyed perhaps amused mistake fact speech recognition working well recently least everyone indeed today asrs effectiveness greatly surpasses year ago thanks incredibly large amount data available train much powerful computer see deep learning however even though lab claim asr surpasses human performance task transcribing conversation many situation still inferior human capability highly noisy reverberating environment many people speak time presence highly accented speech people switch among different language utterancesuperscriptsuperscript human communicate effectively even challenging circumstance machine still issue ,1
ML_394,business future son grandson greatgrandsons going forever nothing world ever stop ��� thomas j watson superscriptsuperscript february wall street journal published small article buried page announcing international business machine corp incorporated law york take business asset computingtabulatingrecording co capitalization computingtabulatingrecording co share exchangeable article went explain name change made increasing growth company business development additional line business device change involved name subsidiary company tabulating machine co international time recording co york dayton scale cosuperscriptsuperscript world learned existence ibm unless worked canada employee known employer ibm ,1
ML_395,competition advance artificial intelligence heating quickly age big data technology company google microsoft conducting trailblazing research machine learning electronic manufacturer apple samsung enhancing product feature natural language processing social networking company facebook deep learning software boost profitability targeted advertising online retailer amazon alibaba deploying recommendation engine market brand personalize shopping ,1
ML_396,handbook ict developing country next generation ict technology second volume handbook ict developing country first volume potential implementation delivery forthcoming g network focus technology service enabled g network broadband internet network including artificial intelligence ai machine learning augmented reality internet thing iot autonomous driving blockchain solution cloud solution etc already globally experiencing growth existing network expected grow substantially future example currently % global organization fully adopted ai penetration expected increase rapidly iot billion device connected estimated show billion device connected expected growth based delivering value business citizen however obvious growth also occur developing country currently digital ide developing country developed country widening mostly due lack infrastructure low level awareness business citizen value made possible technology developing country book discus potential technology developing country need market intervention facilitate demand supply side market designed broad audience including practitioner researcher academic policy maker industry player influencers language approach handbook combination academic writing style professional review ,1
ML_397,data representation learning one important problem machine learning unsupervised representation learning becomes meritorious necessity label information observed data due highly timeconsuming learning deeplearning model many machinelearning model directly adapting welltrained deep model obtained supervised endtoend manner feature abstractor distinct problem however obvious different machinelearning task require disparate representation original input data taking human action recognition example well known human action video sequence signal containing visual appearance motion dynamic human object therefore data representation approach capability capture spatial temporal correlation video meaningful existing human motion recognition model build classifier based deeplearning structure deep convolutional network model require large quantity training video annotation meanwhile supervised model recognize sample distinct dataset without retraining article propose deconvolutional network ddn representation learning highdimensional video data highlevel feature obtained optimization approach proposed ddn decomposes video frame spatiotemporal feature sparse constraint unsupervised way addition also regarded building block develop deep architecture stacking highlevel representation input sequential data used multiple downstream machinelearning task evaluate proposed ddn deep model human action recognition experimental result three datasets kth data hmdb ucf demonstrate proposed ddn alternative approach feedforward convolutional neural network cnns attains comparable result ,1
ML_398,recent development machine learning signal processing resulted many technique able effectively capture intrinsic yet complex property hyperspectral imagery hsi task ranging anomaly detection classification solved taking advantage efficient algorithm root representation theory computational approximation time���frequency method one example technique provide mean analyze extract spectral content data hand hierarchical method neural network nns incorporate spatial information across scale model multiple level dependency spectral feature approach recently proven provide significant advance spectralspatial classification hsi fourier scattering transform introduced article amalgamation time���frequency representation nn architecture leverage benefit provided shorttime fourier transform numerical efficiency deep learning network structure test proposed method several standard hyperspectral data set result indicate fourier scattering transform highly effective representing spectral content compared stateotralspatial classification method ,1
ML_399,due detailed spectral information hundred narrow spectral band provided hyperspectral image hsi data employed accurately classify erse material interest one core application hyperspectral remote sensing technology recent year rapid development deep learning convolutional neural network cnns successfully applied many field including hsi classification however random gradient descentbased parameter updating scheme general leading inefficiency cnn model moreover high dimensionality limited training sample hsi data also exacerbate overfitting problem tackle issue article novel deep network multilayer multibranch architecture named gabor cnn dgcnn proposed hsi classification precisely since predefined gabor filter multiple scale orientation could well characterize internal spatial���spectral structure hsi data various perspective gabormodulated kernel gmks employed replace random initialization kernel moreover specially designed multibranch architecture enables network better integrating scalable property galter thus representative ability robustness extracted feature greatly improved alternatively number network parameter substantially reduced due incorporation gabor modulation relieving training complexity also alleviating training process overfitting experimental result four real hsi datasets including two newly released one literature demonstrated proposed dgcnn model achieve better performance several widely used machinelearningbased deeplearningbased approach sake reproducibility code proposed dgcnn model available urihttpjiasentechpapersuri ,1
ML_400,introduce novel approach predicting progression adolescent idiopathic scoliosis spine model reconstructed biplanar xray image recent progress machine learning allowed improve classification prognosis rate lack probabilistic framework measure uncertainty data propose discriminative probabilistic manifold embedding locally linear mapping transform data point highdimensional space corresponding lowdimensional coordinate discriminant adjacency matrix constructed maximize separation progressive p nonprogressive np group patient diagnosed scoliosis minimizing distance latent variable belonging class predict evolution deformation baseline reconstruction projected onto manifold spatiotemporal regression model built parallel transport curve inferred neighboring exemplar rate progression modulated spine flexibility curve magnitude spine deformation method tested reconstruction subject longitudinal reconstruction spine result demonstrating discriminatory framework identify p np scoliotic patient classification rate % prediction difference �� curve angulation outperforming manifold learning method method achieved higher prediction accuracy improved modeling spatiotemporal morphological change highly deformed spine compared learning met,1
ML_401,providing faulttolerance ft support internet thing iot system challenge many implementation providing static tightly coupled ft support adapt evolve like iot system proposes pluggable framework based microservices architecture implement ft support two complementary microservices one us complex event processing realtime ft detection another us online machine learning detect fault pattern preemptively mitigate fault activated provide early evaluation framework handle realworld scenario ,1
ML_402,attractive feature millimeterwave mmwave technology forthcoming g network entail rich set network access challenge technology characterized highgain array antenna overcome huge attenuation requires resort directional transmission every network operation initial access phase one critical properly managed introduce nonnegligible access delay caused multiple transmission attempt several direction believe contextual information network condition boost discovery phase investigate differentlyrich context information impact duration initial cell access propose several initial access procedure exploit different available information cope presence obstacle area finally relying contextual information past access attempt develop recommendation system based machinelearning technique processing information derive best direction explore connect incoming user ,1
ML_403,address problem automating process network troubleshooting largescale wifi network specifically target identifying cause unnecessary active scan wifi network known degrade wifi performance collect hour worth data several thousand episode active scan train various machine learning model data collected device across vendor varied network setup controlled setting unsupervised supervised machine learning technique conclude multilayer perceptron best model detect cause active scanning perform invivo model validation uncontrolled realworld wifi network also compare model static rulebased approach model improves mean fscore accuracy cause detection proposed mechanism potential incorporated existing wifi controller cisco aruba ,1
ML_404,human mobility analysis multidisciplinary research subject attracted growing interest last decade substantial amount recent study driven availability original source realworld information inidual movement pattern important analysis mobility data reliably distinguishing stop location movement phase compose trajectory monitored subject problem especially challenging mobility inferred mobile phone location data oscillation association mobile device base station lead apparent mobility even absence actual movement leverage unique dataset spatiotemporal inidual trajectory allows capturing network operator perspective mobile phone location data investigate oscillation phenomenon probabilistic machine learning approach detecting oscillation mobile phone location data filtering technique removing analysis comparison stateoftheart approach demonstrate superiority solution term removed oscillation error respect groundtruth trajectory ,1
ML_405,recent year downlink dl throughput estimation mobile broadband mbb network gained immense popularity expected become vital component upcoming fifth generation g system plentiful adaptive video streaming algorithm greatly rely accurate dl throughput prediction adapt mechanism ensure high quality qos endusers thus far conventional dl throughput estimation approach also known speed test require extensive exchange tcp traffic network allocated time duration tool appear deliver trustworthy result turn inefficient mobile subscription limited data plan engaged propose supervised machine learning ml solution dl throughput estimation aim delivering highly accurate prediction significantly limiting overtheair data consumption capture network performance metric exploring crowdsourced controlled testing methodology leverage rtrnettest platform broadband measurement provided austrian regulatory authority broadcasting telecommunication rtr monroenettest counterpart wrapper built experiment eaas top measuring mobile broadband network europe monroe result reveal solution achieve % reduction term data consumption delivering median absolute percentage error mdape % show accuracy tradedoff example significant data consumption reduction % achieved mdape % ,1
ML_406,introduction large antenna array facilitating massive multipleinputmultiple output mmimo addition tier pico femto base station b implementing heterogeneous network provides mean improve network throughput capacity g network however addition antenna bs implies additional hardware associated higher energy consumption improving energy efficiency ee reducing power consumption heterogeneous mmimo dense network performed switching base station user serve redistribute user among active neighboring base station one promising solution intelligently map spatial distribution optimal set active bs utilizing radio map rsm propose novel approach effectively switch base station combining reinforcement learning rsm data proposed approach evaluated computer simulation ray tracing model simulation result show benefit rsm machine learning improvement ee considered heterogeneous mmimo network ,1
ML_407,softwaredefined networking sdn emerging paradigm evolved recent year address weakness traditional network significant feature sdn achieved disassociating control plane data plane facilitates network management allows network efficiently programmable however architecture susceptible several attack lead resource exhaustion prevent sdn controller supporting legitimate user one attack nowadays growing significantly distributed denial ddos attack ddos attack high impact crashing network resource making target server unable support valid user current method deploy machine learning ml intrusion detection ddos attack sdn network standard datasets however method suffer several drawback used datasets contain recent attack pattern hence lacking attack ersity propose ddosnet intrusion detection system ddos attack sdn environment method based deep learning dl technique combining recurrent neural network rnn autoencoder evaluate model newly released dataset cicddos contains comprehensive variety ddos attack address gap existing current datasets obtain significant improvement attack detection compared benchmarking method hence model provides great confidence securing network ,1
ML_408,distributed renewable energy source dres considered instrumental modern smart grid broadly various ancillary service contained energy trading market thus adequate power production profiling forecasting dres deployment vital importance support various grid optimisation accounting process variety dres stallation company conjunction ersity ownership dres machinery controller firmware supervisory control data acquisition scada software lead case centralised scada measurement entirely available provided subscriptionbased model consider pragmatic scenario introduce scadaagnostic approach utilises freely available weather measurement explicitly profiling forecasting power generation produced real wind turbine deployment leverage various machine learning ml library demonstrate applicability system compare forecasting output obtained scada measurement demonstrate viable exogenous profiling solution achieving similar accuracy scadabased scheme much lower computational cost ,1
ML_409,consider production management element artificial intelligence humanmachine learning decisionmaking procedure fuzzy qualitative guideline mechanism include heuristic element knowledge decisionmakers expert language rule formulated language problem control mechanism optimal synthesis guideline expert set mechanism model function people condition uncertainty obtained optimal control mechanism includes learning stimulation procedure proved theorem offer solution problem optimal synthesis learning mechanism dichotomous classification procedure supported iterative pattern recognition procedure iterative procedure us formal recursive algorithm result recognition expert image emerging situation result adaptive norm formed evaluate effectiveness stimulate production optimal control mechanism illustrates example wagonrepair production largescale corporation russian railway ,1
ML_410,current state methodological approach agentbased modeling economic system considered critical observation concerning classical modeling method systematized point derived solution provided methodology may useful specialist field machine learning macroeconomic forecasting evolutionary method ,1
ML_411,formal procedure proposed making medical diagnosis based result analyzes satisfy specified requirement type possible disease set analizes formed set analyzes ranked importance disease presentation conducted example specific sample dermatology known repository uci machine learning result indicate proposed procedure may useful medical assistant making definitive diagnosis ,1
ML_412,forecasting financial market trend one important task investor traditional method complemented machine learning method potential find hidden knowledge large amount information nonlinear model method based artificial intelligence neural network considered currently real neural network developing following area stock exchange macroeconomic forecasting speech recognition dialogue person imitation intellectual activity improvement poorquality noisy information identification suspicious person situation shown effective neural network forecasting problem ,1
ML_413,symmetric convex mechanism opinion formation requires iniduals opinion next time moment average current opinion opinion acquaintance evaluate extent dependency describe real data combining machine learning social network analysis approach retrieve time series vkontakte user opinion well information friendship network connecting result absolute value user opinion transformation huge enough direction predicted proposed mechanism sufficiently high accuracy namely magnitude greater accuracy turn change whose absolute value exceed accuracy near one moreover dependency monotonically increasing ,1
ML_414,investigate application machine learning technique particular deep neural network dnn improve decoding algorithm short quasicyclic lowdensity paritycheck ldpc code adopted g standard note straightforward application generalpurpose dnns possible due curse dimensionality problem ��� training set size grows exponentially number information bit opinion way deal problem combine deep learning method existing decoding algorithm start tannerbased neural network decoder minsum activation function proposed nachmani et al extend follows first quasicyclic nature g ldpc code allows u single weight per circular matrix circulant refer weight sharing idea significantly reduces training time preserving errorcorrecting performance second add residual connection nn architecture residual connection improve performance reduce training time also result rate length adaptation technique rate adaptation allows multiple dnns corresponding different coding rate run single set trained weight length adaptation allows optimally reusight multiple lifting size index ,1
ML_415,recognition classification task machine learning wide range application determining handwritten number identifying object video recording diagnostics mri scanning much currently one common application neural network technology face recognition photograph video example corporation facebook currently neural network technology identify user friend face general photo discus development face recognition application neural network technology developed system relatively small size work sufficiently high accuracy ,1
ML_416,intellectual analysis text identifying thematic structure document allows u solve various applied problem associated documental retrieval automatic selection keywords annotation document parsing dynamic topic large number scientific work automatic determination text detail article becomes fundamentally important machine learning method thematic modeling allows u solve problem analyzes multiple data russian science citation index dynamic topic keywords phrase scientific specialty dentistry based analysis russian text scientific article published thematic modeling corpus available document carried base paper title analysis method extracting keywords document identifying topic corpus document dynamic distribution top keywords phrase well change thematic focus article analyzed period analyzed ,1
ML_417,development information technology allows applying complex mathematical algorithm example machine learning ml procedure used almost human life area smart home system online recommendation system intelligent chatbots creates huge demand specialist data analysis ml modern data analysis package often require deep knowledge specialist allows apply ml algorithm without deep understanding however problem data suitable algorithm result algorithm detect pattern incorrectly situation acceptable pet project completely unacceptable case algorithm error cost lot money human life analysis ml algorithm possibility application forest fire data done ,1
ML_418,green supply chain growing evaluation optical selection green supplier increasingly becomes key point recycling economy green environmental protection industry analytical hierarchy process ahp commonly used quantitative research method widely used evaluation indicator solution genetic algorithm one major technology intelligent calculation adaptively dynamic adjustment global optimization capability widely used combinatorial optimization machine learning signal processing adaptive control artificial life based characteristic two method design program making realtime feedback information according ahp adopting genetic algorithm combined ahp dynamic adjusting green supplier evaluation index weight enhance objectivity efficiency system evaluation green supplier reduce asymmetric information green supply chain promotion information technology green industry ,1
ML_419,based classification various voice disorder noninvasive method help machine learning algorithm voice sample three disorder dysphonia vocal fold paralysis laryngitis normal speech sample considered comprehensive database category class created speech processing feature extraction technique relevant feature extracted stored supervector gmmubm supervector projected low dimensional feature vector known ` ivectors total variability factor analysis extracted feature stored feature matrix created parameter obtained hereafter used train system support vector machine na��ve bayes knn trained system capable classification voice disorder accuracy abovementioned classifier range ,1
ML_420,automated news classification categorizing news predefined category based content confidence learned training news dataset research evaluates widely used machine learning technique mainly naive bayes svm neural network automatic nepali news classification problem experiment system selfcreated nepali news corpus different category total document collected crawling different online national news portal used tfidf based feature extracted preprocessed document train test model average empirical result show svm rbf kernel outperforming three algorithm classification accuracy % follows linear svm accuracy % multilayer perceptron neural network accuracy % naive bayes accuracy % ,1
ML_421,concept adversary model widely applied context cryptography designing cryptographic scheme protocol adversary model play crucial role formalization capability limitation potential attacker model enable designer verify security scheme protocol investigation although well established conventional cryptanalysis attack adversary model associated attacker enjoying advantage machine learning technique yet developed thoroughly particular come composed hardware often securitycritical lack model become increasingly noticeable face advanced machine learningenabled attack aim exploring adversary model machine learning perspective regard provide example machine learningbased attack hardware primitive eg obfuscation scheme hardware rootoftrust claimed infeasible demonstrate assumption becomes however invalid inaccurate adversary model considered literature ,1
ML_422,consider existing emerging neural workload hardware accelerator might best suited said workload begin discussion analog crossbar array known wellsuited matrixvector multiplication operation commonplace existing neural network model convolutional neural network cnns highlight candidate crosspoint device device material challenge must overcome given device employed crossbar array computationally interesting neural workload circuit algorithmic optimization may employed mitigate undesirable characteristic devicesmaterials discus two emerging neural workload first consider machine learning model one fewshot learning task ie network trained one representative example given class notably crossbarbased architecture used accelerate said model hardware solution based content addressable memory array also discussed consider machine learning model recommendation system recommendation model emerging class machine learning model employ distinct neural network architecture operate continuous categorical input feature make hardware acceleration challenging discus research challenge opportunity space ,1
ML_423,advent deep learning considerably accelerated machine learning development deployment deep neural network edge however limited high memory energy consumption requirement memory technology available emerging binarized neural network bnns promising reduce energy impact forthcoming machine learning hardware generation enabling machine learning edge device avoiding data transfer network presenting implementation employing hybrid cmos hafnium oxide resistive memory technology suggest strategy apply bnns biomedical signal electrocardiography electroencephalography keeping accuracy level reducing memory requirement investigate memoryaccuracy tradeoff binarizing whole network binarizing solely classifier part also discus result translate edgeoriented mobilenet v neural network imagenet final goal research enable smart autonomous healthcare device ,1
ML_424,recent year deep learning method outperformed method image recognition fostered imagination potential application deep learning technology including safety relevant application like interpretation medical image autonomous driving passage assistance human decision maker ever automated system however increase need properly handle failure mode deep learning module contribution set technique selfmonitoring machinelearning algorithm based uncertainty quantification particular apply semantic segmentation machine learning algorithm decomposes image according semantic category discus false positive false negative error mode instancelevel technique detection error recently proposed author also give outlook future research direction ,1
ML_425,multicore chip expected rely coherent shared memory albeit coherence hardware scale gracefully protocol state space grows exponentially core count design verification requires directed test generation dtg dynamic coverage control tight time constraint resulting slow simulation short verification budget next generation eda tool expected exploit machine learning reaching high coverage le time propose technique address dtg decision process try find decisionmaking policy maximizing cumulative coverage result successive action taken agent instead simply relying learning technique build upon legacy constrained random test generation rtg cast dtg coveragedriven rtg explores distinct rtg engine subject progressively tighter constraint compared three reinforcement learning generator stateoftheart generator based genetic programming experimental result show proper enforcement constraint efficient guiding learning towards higher coverage simply letting generator learn select promising memory event increasing coverage level mesi core design proposed approach led highest observed coverage % time faster baseline generator reach latter maximal coverage ,1
ML_426,performing machine learning task mobile application yield challenging conflict interest highly sensitive client information eg speech data remain private also intellectual property provider eg model parameter must protected cryptographic technique offer secure solution unacceptable overhead moreover require frequent network interactionin design practically efficient hardwarebased solution specifically build offline model guard omg enable privacypreserving machine learning predominant mobile computing platform arm���even offline scenario leveraging trusted execution environment strict hardwareenforced isolation system component omg guarantee privacy client data secrecy provided model integrity processing algorithm prototype implementation arm hikey development board performs privacypreserving keyword recognition tensorflow lite microcontrollers real,1
ML_427,propose machine learning based approach accelerate quantum approximate optimization algorithm qaoa implementation promising quantumclassical hybrid algorithm prove socalled quantum supremacy qaoa parametric quantum circuit classical optimizer iterates closed loop solve hard combinatorial optimization problem performance qaoa improves increasing number stage depth quantum circuit however two parameter introduced added stage classical optimizer increasing number optimization loop iteration note correlation among parameter lowerdepth higherdepth qaoa implementation exploit developing machine learning model predict gate parameter close optimal value result optimization loop converges fewer number iteration choose graph maxcut problem prototype solve qaoa perform feature extraction routine different qaoa instance develop training dataset optimal parameter analysis flavor regression model flavor classical optimizers finally show proposed approach curtail number optimization iteration average % % analysis performed flavor graph ,1
ML_428,nowadays ssd cache play important role cloud storage system associated write policy enforces admission control policy regarding filling data cache significant impact performance cache system amount write traffic ssd cache based analysis typical cloud block storage system approximately % writes writeonly ie writes block read certain time window naively writing writeonly data ssd cache unnecessarily introduces large number harmful writes ssd cache without contribution cache performance hand challenging identify filter writeonly data realtime manner especially cloud environment running changing erse workloadsin alleviate cache problem propose mlwp machine learning based write policy reduces write traffic ssds avoiding writing writeonly data challenge approach identify writeonly data realtime manner realize mlwp achieve accurate writeonly data identification machine learning method classify data two group ie writeonly normal data based classification writeonly data directly written backend storage without cached experimental result show compared industry widely deployed writeback policy mlwp decrease write traffic ssd cache % improving hit ratio % reducing average read latency % ,1
ML_429,machine learning inference increasingly executed locally mobile embedded platform due clear advantage latency privacy connectivity approach online resource management heterogeneous multicore system show applied optimise performance machine learning workload performance defined platformdependent eg speed energy platformindependent accuracy confidence metric particular show deep neural network dnn dynamically scalable tradeoff various performance metric achieving consistent performance executing different platform necessary yet challenging due different resource provided capability timevarying availability executing alongside workload managing interface available hardware resource often numerous heterogeneous nature software requirement experience increasingly complex ,1
ML_430,today factory machine ever connected scada me erp application well external system data analysis different type network architecture must used instance control application lowest level susceptible delay error data analysis machine learning procedure requires move large amount data without realtime constraint standard data format like automation markup language aml established document factory environment machine placement network deployment however automatic technique currently available context industry choose best mix network architecture according spacial constraint cost performance propose fill gap formulating optimization problem first spatial communication requirement extracted aml description optimal interconnection wired wireless channel obtained according application objective finally result backannotated aml used life cycle production system proposed methodology described small complete smart production plant ,1
ML_431,increasing role artificial intelligence ai machine learning ml life brought paradigm shift computation performed stringent latency requirement congested bandwidth moved ai inference cloud space towards enddevices change required major simplification deep neural network dnn memorywise library coprocessors perform fast inference minimal power unfortunately many application natural language processing timeseries analysis audio interpretation built different type artifical neural network ann socalled recurrent neural network rnn due intrinsic architecture remains complex heavy run efficiently embedded device solve issue reservoir computing paradigm proposes sparse untrained nonlinear network reservoir embed temporal relation without hindrance recurrent neural network training lower memory usage echo state network esn liquid state machine notable example scenario propose performance comparison esn designed trained bayesian optimization technique current rnn solution aim demonstrate esn comparable performance term accuracy require minimal training time optimized term memory usage computational efficiency preliminary result show esn competitive rnn simple benchmark training inference time faster maximum speedup x x respectively ,1
ML_432,deep neural network one machine learning technique increasingly used variety application however significantly high memory computation demand deep neural network often limit deployment embedded system many recent work considered problem proposing different type data quantization scheme however technique either require postquantization retraining deep neural network bear significant loss output accuracy propose novel quantization technique parameter pretrained deep neural network technique significantly maintains accuracy parameter require retraining network compared singleprecision floatingpoint numbersbased implementation proposed bit quantization technique generates ~ % ~ % loss top top accuracy respectively vgg network imagenet dataset ,1
ML_433,circuit obfuscation proposed protect digital integrated circuit ic different security threat reverse engineering introducing ambiguity circuit ie addition logic gate whose functionality determined easily attacker order conquer defense technique boolean satisfiabilitychecking satbased attack introduced satattack potentially decrypt obfuscated circuit however deobfuscation runtime could large span ranging millisecond year depending number location obfuscated gate topology obfuscated circuit obfuscation technique used ensure security deployed obfuscation mechanism essential accurately preestimate deobfuscation time thereby one optimize deployed defense order maximize deobfuscation runtime however estimating deobfuscation runtime challenging due complexity heterogeneity graphstructured circuit unknown sophisticated mechanism attacker deobfuscation efficiency scalability requirement practice address challenge mentioned proposes first machinelearning framework predicts deobfuscation runtime based graph deep learning specifically design model icnet input convolution layer characterize circuit topology integrated composite deep fullyconnected layer obtain deobfuscation runtime proposed icnet endtoend framework automatically extract determinant feature required deobfuscation runtime prediction extensive experiment standard benchmark demonstrate effectiveness efficiency beyond many competitive baseline ,1
ML_434,domain specialization energy constraint deeplyscaled cmos driving need agile development system chip socs digital subsystem design flow conducive rapid iteration specification layout analog mixedsignal module face challenge long humaninthemiddle iteration loop requires expert intuition verify postlayout circuit parameter meet original design specification existing automated solution optimize circuit parameter given target design specification limitation schematiconly inaccurate sampleinefficient generalizable present autockt machine learning optimization framework trained deep reinforcement learning find postlayout circuit parameter given target specification also gain knowledge entire design space sparse subsampling technique result show multiple circuit topology autockt able converge meet target specification least % tested design goal schematic simulation average �� faster traditional genetic algorithm berkeley analog generator autockt able design lvs passed operational amplifier hour �� faster start considering layout parasitics ,1
ML_435,thanks imperfection manufacturing process physically unclonable function pufs produce unique output given input signal challenge fed identical circuitry design pufs often used hardware primitive provide security eg key generation authentication purpose however vulnerable modeling attack predict output unknown challenge based set known challengeresponse pair crp addition attacker may benefit power sidechannels break pufs security although attack extensively discussed literature effect device aging efficacy attack still question accordingly focus impact aging arbiterpufs one modelingresistant counterpart voltage transfer characteristic vtc puf result spice simulation used perform modeling attack via machine learning ml scheme device aged week show aging significant impact modeling attack indeed training dataset ml attack extracted different age evaluation dataset attack greatly hindered despite performed device show ml attack via power trace particularly efficient recover response antimodeling vtc puf yet aging still contributes enhance security ,1
ML_436,moore law coming end advent hardware specialization present unique challenge much tighter software hardware codesign environment exploit domainspecific optimization increase design efficiency trend accentuated rapidpace innovation machine learning graph analytic calling faster product development cycle hardware accelerator importance addressing increasing cost hardware verification productivity softwarehardware codesign relies upon better integration software hardware design methodology importantly effectiveness design tool hardware simulator reducing development time developed tango optimizing compiler justintime rtl simulation tango implement unique hardwarecentric compiler transformation speed runtime code generation softwarehardware codesign environment hardware simulation speed critical tango achieves x average speedup compared stateoftheart simulator ,1
ML_437,autonomous system increasingly component incorporate machine learning aibased technique order achieve improved performance address problem assuring correctness safetycritical system component investigate approach formulates problem one performance objective function optimized safety hard constraint must satisfied apply heuristic algorithmic technique optimization theory order solve resulting constrained optimization problem ,1
ML_438,deep neural network dnns transformed field artificial intelligence represent stateoftheart many machine learning task considerable interest dnns realize edge intelligence highly resourceconstrained device wearable iot sensor unfortunately high computational requirement dnns pose serious challenge deployment system moreover due tight cost hence area constraint device often unable accommodate hardware accelerator requiring dnns execute general processor gpp core contain address challenge lightweight microarchitectural extension memory hierarchy gpps exploit key attribute dnns viz sparsity prevalence zero value propose sparsecache enhanced cache architecture utilizes null cache based ternary content addressable memory tcam compactly store zerovalued cache line storing nonzero line conventional data cache storing address rather value zerovalued cache line sparsecache increase effective cache capacity thereby reducing overall miss rate execution time sparsecache utilizes zero detector approximator zda address merger perform read writes null cache evaluate sparsecache four stateoftheart dnns programmed caffe framework sparsecache achieves % reduction missrate translates % reduction execution time % area % power overhead comparison lowend intel atom zseries processor ,1
ML_439,effectively minimize static power wide range application power domain coarsegrained reconfigurable array cgra need finergrained typical asic however special isolation logic needed ensure electrical protection domain make finegrained power domain area timinginefficient propose novel design cgra routing fabric intrinsically provides boundary protection technique reduces area overhead boundary protection power domain cgra around % le % remove delay isolation cell however design choice leverage conventional upfbased flow introduce power domain boundary protection create compilerlike pass iteratively introduce needed design transformation formally verify pass satisfiability modulo theory smt method pass also allow u optimize handle test debug signal tile framework insert power domain soc arm cortex processor cgra �� processing element pe memory tile mb secondary memory depending size application mapped cgra achieves % reduction leakage power % reduction total power versus cgra without multiple power domain ranmage processing machine learning application ,1
ML_440,arithmetic key component ubiquitous today digital world ranging embedded highperformance computing system machine learning fore wide range application domain wearable automotive avionics weather prediction sufficiently accurate yet lowcost arithmetic need day recently several advance domain computer arithmetic includes highprecision anchored number arm posit arithmetic bfloat etc alternative ieee compliant arithmetic optimization fixedpoint integer arithmetic also pursued actively lowpower computing architecture furthermore approximate computing transprecisionmixedprecision computing exciting area research forever academic research domain computer arithmetic long history industrial adoption data type technique early stage expected increase future bfloat excellent example bring academia industry together discus latest result future direction research domain nextgeneration computer arithmetic especially edge computing ,1
ML_441,ever growing complexity highperformance computing hpc system satisfy emerging application requirement eg high memory bandwidth requirement machine learning application performance bottleneck system moved computationcentric communicationcentric silicon photonic interconnection network proposed address aggressive communication requirement hpc system realize higher bandwidth lower latency better energy efficiency many successful effort developing silicon photonic device integrated circuit architecture hpc system moreover many effort made address mitigate impact different challenge eg fabrication process thermal variation silicon photonic interconnects however effort focused single design layer system design space eg device circuit architecture level therefore often gap design technique improve one layer might impair another one discus promise crosslayer design methodology hpc system integrating silicon photonic interconnects particular discus crosslayer design solution based cooperatively designing exchanging design objective among different system design layer help achieve best possible performance integrating silicon photonics hpc system ,1
ML_442,efficiency power management system pm one key performance metric highly integrated system chip socs towards goal improving power efficiency socs make two key technical contribution first develop multioutput switchedcapacitor voltage regulator scvr flying capacitor crossing technique fcct cloudcapacitor method second optimize design parameter scvr introduce novel machine��learning mlinspired optimization framework reduce number expensive design simulation simulation show power loss multioutput scvr fcct reduced % compared conventional multiple singleoutput scvrs mlbased design optimization framework able achieve % reduction number simulation needed uncover optimized circuit parameter proposed s,1
ML_443,machine learning ml provides stateoftheart performance many part computeraided design cad flow however deep neural network dnns susceptible various adversarial attack including data poisoning compromise training insert backdoor sensitivity training data integrity present security vulnerability especially light malicious insider want cause targeted neural network misbehavior explore threat lithographic hotspot detection via training data poisoning hotspot layout clip hidden inference time including trigger shape input show training data poisoning attack feasible stealthy demonstrating backdoored neural network performs normally clean input misbehaves input backdoor trigger furthermore result raise fundamental question robustness mlbased system cad ,1
ML_444,address fundamental question modern big data framework dynamically transparently exploit heterogeneous hardware accelerator presenting major challenge addressed towards goal describe proposed architecture automatic transparent hardware acceleration big data framework application vision retain uniform programming model big data framework enable automatic dynamic justintime compilation candidate code segment benefit hardware acceleration corresponding format conjunction machine learningbased device selection respect userdefined constraint eg cost time etc enable dynamic code execution gpus fpgas transparently addition dynamically resteer execution runtime based availability resource preliminary result demonstrate approach accelerate existing apache flink application x ,1
ML_445,espml opensource systemlevel design flow build program soc architecture embedded application require hardware acceleration machine learning signal processing algorithm realized espml combining two established opensource project esp hlsml fullyautomated design flow soc integration accelerator generated hlsml designed set parameterized interface circuit synthesizable highlevel synthesis accelerator configuration management developed embedded software runtime system top linux hwsw layer addressed challenge dynamically shaping data traffic networkonchip activate support reconfigurable pipeline accelerator needed application workload currently running soc demonstrate verticallyintegrated contribution fpgabased implementation complete soc instance booting linux executing computervision application process image taken google street view database ,1
ML_446,advent deeper larger complex convolutional neural network cnn manual design become daunting especially hardware performance must optimized sequential modelbased optimization smbo efficient method hyperparameter optimization highly parameterized machine learning ml algorithm able find good configuration limited number evaluation predicting performance candidate evaluation case mnist show smbo regression model prediction error significantly impedes search performance multiobjective optimization address issue propose probabilistic smbo selects candidate based probabilistic estimation pareto efficiency formulation incorporates error accuracy prediction uncertainty latency measurement probabilistic pareto efficiency quantifies candidate quality two way likelihood pareto optimal expected number current pareto optimal solution dominate evaluate proposed method four image classification problem compared deterministic approach probabilistic smbo consistently generates pareto optimal solution perform better competitive stateoftheart efficient cnn model offering tremendous speedup inference latency maintaining comparable accuracy ,1
ML_447,privacy latency requirement force move towards edge machine learning inference resource constrained device struggling cope large computationally complex model convolutional neural network limitation overcome taking advantage enormous data reuse opportunity amenability reduced precision however level compute density unattainable conventional binary arithmetic required stochastic computing deliver density lived full potential multiple underlying precision issue acoustic accelerating convolution orunipolar skipped stochastic computing accelerator framework enables fully stochastic highdensity cnn inference leveraging splitunipolar representation orbased accumulation novel computationskipping approach acoustic delivers serverclass parallelism mobile area power budget mmsupsup accelerator much x energy efficient x faster conventional fixedpoint accelerator also x energy efficient stateoftheart stochastic accelerator lowerend acoustic achieves xx inference throughput improvement similar energy area compared recent mixedsignalneuromorphic accelerator ,1
ML_448,utilizes xgboost build machinelearningbased ir drop predictor xgbir power grid capture behavior power grid extract several feature employ locality property save extraction time xgbir effectively applied large design average error predicted ir drop le mv ,1
ML_449,recent year coarse grain reconfigurable architecture cgra accelerator increasingly deployed internetofthings iot end node modern cgra support efficiently accelerate integer floatingpoint fp operation propose ultralowpower tunableprecision cgra architectural template called transprecision floatingpoint programmable architecture transpire associated compilation flow supporting integer fp operation transpire employ transprecision computing multiple single instruction multiple data simd accelerate fp operation boosting energy efficiency well experimental result show transpire achieves maximum �� performance gain consumes �� le energy wrt riscv based cpu enhanced isa supporting simdstyle vectorization fp datatypes executing application nearsensor computing embedded machine learning area over,1
ML_450,advanced technology node resolving design rule check drc violation become cumbersome make desirable make prediction earlier stage design flow show random forest rf model quite effective drc hotspot prediction global routing stage fact significantly outperforms recent prior work fraction runtime develop model also propose first time adopt recent explanatory metricthe shap valueto make accurate consistent explanation inidual drc hotspot prediction rf experiment show rf % % better predictive performance average compared promising machine learning model used similar work eg svm neural network exhibiting good explainability make ideal drc hotspot prediction ,1
ML_451,deeper neural network especially extremely large number internal parameter impose heavy computational burden obtaining sufficiently highquality result burden impeding application machine learning related technique timecritical computing system address challenge proposing architectural approach neural network adaptively trade computation time solution quality achieve highquality solution timeliness propose novel general framework anytimenet gradually insert additional layer user expect monotonically increasing quality solution computation time expended framework allows user select fly retrieve result runtime extensive evaluation result classification task demonstrate proposed architecture provides adaptive control classification solution quality according available computation time ,1
ML_452,constant improvement network architecture training methodology neural network nns increasingly deployed realworld machine learning system however despite impressive performance known input nns fail absurdly unseen input especially realtime input deviate training dataset distribution contain certain type input noise indicates low noise tolerance nns major reason recent increase adversarial attack serious concern particularly safetycritical application inaccurate result lead dire consequence propose novel methodology leverage model checking formal analysis neural network fannet different input noise range methodology allows u rigorously analyze noise tolerance nns input node sensitivity effect training bias performance eg term classification accuracy evaluation feedforward fullyconnected nn architecture trained leukemia classification experimental result show �� % noise tolerance given trained network identify sensitive input node confirm biasness available training data,1
ML_453,identification electrocardiogram ecg emerging due uniqueness convenience ecg signal addition real world application subject may enter existed identification system authorized access private data therefore propose scalable extreme learning machine selm meet demand classincremental ecgbased identification first prove output weight selm learnt classincremental manner regular elm prior information number total class therefore experiment selm immune catastrophic forgetting phenomenon common problem classincremental scenario comparing another classincremental extreme learning machine progressive elm selm outperforms progressive elm % accuracy online dataset comparing another commonly applied classifier support vector machine svm linear radial basis function rbf kernel selm show efficiency % % higher accuracy spends % % inference time therefore proposed selm promising classincremental ecgbased identification ,1
ML_454,machinelearningbased readout channel presented direct data symbol detection via decisiontree classification gradient boosting multipleactuator data storage system proposed learning module integrates energyefficient linear classifier extract feature structure raw readback signal result demonstrate high detection accuracy robust intersymbol interference isi jitter noise lowcomplexity machine learning module classifies low signaltonoise ratio raw data accuracy rate higher % realtime consumes mw ,1
ML_455,recent year machine learning algorithm training data faced many security threat affect security practical application based machine learning generating adversarial patch based generative adversarial net gans emerging however existing attack strategy still far producing local adversarial patch strong attack power ignoring attacked network perceived sensitivity adversarial patch study security threat adversarial patch classifier adding adversarial patch data mislead classifier incorrect result considering attention aggression reality propose datadriven multidwgan simultaneously enhance adversarial patch attack power authenticity multidiscriminators experiment confirm datadriven multidwgan dramatically reduces recall seven classifier attacked four datasets attack datadriven multidwgan group experiment lead decreased recall rate better conventional gans finally proved positive correlation attack intensity attack ability theoretically experimentally ,1
ML_456,employing machine learning algorithm tactile sensing system emerged recently recognizeclassify touch pattern high computational complexity ml algorithm make challenging embedded implementation tactile data processing proposes complexity optimized tensorialbased machine learning algorithm touch modality classification aim introduce efficient algorithm minimizing system complexity term number operation memory storage directly affect time latency power consumption respect state art proposed approach reduces number operation per inference mop mop memory storage kb kb moreover proposed method speed inference time factor �� cost % loss accur,1
ML_457,motorimagery mi brainmachine interface bmi may control machine merely thinking performing motor action practical case require wearable solution classification brain signal done locally near sensor machine learning model embedded energyefficient microcontroller unit mcus assured privacy comfort longterm usage provide practical insight accuracycost tradeoff embedded bmi solution proposed multispectral riemannian classifier reach % accuracy class mi scale model quantizing mixedprecision representation minimal accuracy loss % still % accurate stateofthe art embedded convolutional neural network implement model lowpower mcu parallel processing unit taking m consuming mj per classification ,1
ML_458,method simulate spiking neuron device nonidealities neuron model machine learning algorithm tested spiking neural network simulator ideal mathematical description spiking neuron silicon implementation spiking neuron differ significantly ideal mathematical model device nonidealities restriction range device operation nonidealites affect performance chip implementation neuron dynamical system phase plane neuron circuit produce time domain spiking pattern hardware realistic way time cost saved making design change network sending chip manufacturing ,1
ML_459,equipment includes laptop xilinx zcu dev board harddisk drive hdd interface module fig illustrates demonstration setup device powered power adaptor hdd interface module provided data storage system center dssc carnegie mellon university controlled laptop generate raw readback signal machine learning ml module implemented xilinx zcu perform data symbol detection classified output sent back laptop result analysis demonstration graphical interface gui ,1
ML_460,novel approach developing inputtoneuron interlinks achieve better accuracy spikebased liquid state machine energyefficient spiking neural network suffer lower accuracy image classification compared deep learning model previous lsm model randomly connect input neuron excitatory neuron liquid limit expressive power liquid model large portion excitatory neuron become inactive never fire overcome limitation propose adaptive interlink development method achieves % higher classification accuracy static lsm model neuron also hardware implementation fpga improves performance ~ x ~�� cpu,1
ML_461,conventionalsilicontransistorbased volatile memory vm synapse proposed alternative non volatile memory nvm synapse crossbararraybased neuromorphic inmemorycomputing system spice simulation designed analogdigitalhybrid volatile memory synapse cell vmsc crossbar array vm synapsis vmsc transistor synapse store nearly analog value weight transistor carry weight update transistor synapse designed following principle static cmos logic digital making design energyefficient systemlevel classification accuracy speed energy consumption onchip learning vmscbased crossbar designed popular machine learning data set show despite low value capacitance mosfet synapsis low area footprint hence weight retained long enough vmscbased crossbar exhibit comparable accuracy nvmsynapsebased crossbar ,1
ML_462,hardware trojan take various form manifest integrated circuit ic causing altered functional behavior potential critical consequence eg leaking secret information encryption application present approach us overclocking produce different bit flip pattern clean design trojaninserted design consequently apply machine learning algorithm learn bit flip distribution output ic therefore differentiate ergence pattern bit flip caused trojan ic baseline distribution approach effective detecting trojan placed critical path proposed technique evaluated benchmark trusthub show detection accuracy % ,1
ML_463,google colab cloud jupyter notebook widespread used teach machine learning writing text explanation python code browser introduces colab extension teach logic circuit design verilog language processor gpu architecture colab allows u share reproducible experiment web student become motivated laboratory assignment without downloadconfigure software package dependency computer furthermore almost university shut due covid pandemic forcing u adapt virtual learning scenario colab provides portability accessibility since even run smartphones lab assignment include intermediate guided exercise text explanation figure online quiz problem set basic handson task develop simple setup icarus verilog pyeda cuda valgrind gem framework present verilog teaching computer architecture simulation insight valgrind gem gpu computer architecture profiling thread instruction assembly level ,1
ML_464,recent advancement biotechnology contributed concept precision oncology application machine learning algorithm proposed focus improvement novel deep learning model known reference drugbased deep neural network refdnn applied prediction cancer drug response model utilizes drug structure similarity profile ssp describe similarity different reference cancer drug us ssp vector weigh prepredicted drug response probability obtained elastic net en weighted response input deep neural network prediction performance refdnn improved adding distributed stochastic neighbor embedding tsne based feature extraction estimator integration gene expression copy number variant cnv mutation data adaptation used characterise model customize prediction procedure based cell line data provide precise timeefficient result performance proposed system based fold cross validation compared original refdnn model showing significant improvement accuracy reduction computational processing time ,1
ML_465,present reduced complexity architecture backpropagationbased compensation frequency interleaved analog digital converter fiadc earlier literature described promising adaptive background compensation technique based backpropagation algorithm machine learning suitable mitigate error analog signal path fiadcs technique applicable high speed digital receiver used coherent optical communication key ingredient aforementioned technique mimo equalization backpropagation algorithm used adapt coefficient equalizer presented modifies earlier architecture reduce number required analog mixer factor two simplify also factor two compensation equalizer responsible correcting error analog signal path result much simpler significantly improved fiadc system simulation show analog impairment accurately compensated impact performance receiver essentially eliminated ,1
ML_466,machine learning inference engine great interest smart edge computing computeinmemory cim architecture shown significant improvement throughput energy efficiency hardware acceleration emerging nonvolatile memory envm technology offer great potential instant dynamic power gating inference engine typically pretrained cloud deployed field security concern cloning weight stored envmbased cim chip propose countermeasure weight cloning attack exploiting process variation periphery circuitry particular weight finetuning compensate analogtodigital converter adc offset specific chip instance inducing significant accuracy drop cloned chip instance evaluate proposed scheme cifar classification vgg network result show precisely chosen transistor size employed saradc could maintain % ~ % accuracy finetuned chip set weight cloned chip ~ % accuracy average weight finetune could completed one epoch iteration average % % % cell updated bit bit bit weight precision iteration ,1
ML_467,application machine learning automated robust optimization electronic circuit design combine artificial neural network global optimization neural network regressor constructed predict circuit operation metric power offset delay phase margin based input parameter device size temperature supply voltage current process corner regressor used build objective function global optimization find optimal set controllable parameter optimize objective function subject input constraint device size range output constraint power consumption delay experimental result tuning stateoftheart high performance pll circuit show framework promising much le time find optimized circuit outperform circuit design manually tuned skilled circuit designer ,1
ML_468,achieve higher accuracy machine learning task deep convolutional neural network cnns designed recently however large memory access deep cnns lead high power consumption variety hardwarefriendly compression method proposed reduce data transfer bandwidth exploiting sparsity feature map focus designing specialized encoding format increase compression ratio differently observe exploit sparsity distinction activation earlier later layer improve compression ratio propose novel hardwarefriendly transformbased method named ddiscrete cosine transform channel dimension mask dctcm intelligently combine dct mask coding format compress activation proposed algorithm achieves average compression ratio �� % higher state oftheart transformbased feature map compression work inference resnet bit quantization sch,1
ML_469,convolutional neural network cnn accelerator dominant power consumption caused access external data memory addition power area occupied io interface maintaining low biterrorrate eg e grow data rate increase considering inherent error resilience inference process machine learning application requirement errorfree communication datapath controversial custom cnn accelerator integrating channel emulator designed fpga analyze effect ber io transceiver image classification accuracy order implement channel emulator digitaldomain lookuptable lutbased tap fir filter employed create intersymbol interference isi prbs generator used noise source implementation evaluated running imagenet dataset fpgabased custom accelerator virtex ultrascale+ implementing vgg result show ber e memory access negligible impact inference accuracy ,1
ML_470,homomorphic encryption allows untrusted party process encrypted data without revealing content people could encrypt data locally send cloud conduct neural network training inferencing achieves data privacy ai however combined ai computation could extremely slow deal propose multilevel parallel hardware accelerator homomorphic computation machine learning vectorized number theoretic transform ntt unit designed form lowlevel parallelism apply residue number system rn form midlevel parallelism one polynomial finally fully pipelined parallel accelerator two ciphertext operand proposed form highlevel parallelism address core computation matrixvector multiplication neural network designed support multiplyaccumulate mac operation natively ciphertexts analyzed design fpga zcu experimental result show outperforms previous work achieves order magnitude acceleration software implementation ,1
ML_471,provides comprehensive analysis available eeg datasets used epilepsy prediction system including melbourne chbmit american epilepsy society bonn european epilepsy datasets datasets compared term sampling rate number patient recording time number channel artifact type eeg signal also provide detail challenge one dataset others predicting epilepsy subsequently compare performance various machine learning model datasets epileptic seizure prediction first provides comprehensive analysis various eeg datasets great importance researcher eegbased system epileptic seizure prediction ,1
ML_472,recently indoor air quality important issue human health high concentration toxic volatile organic compound vocs gas btex benzene toluene ethylbenzene xylene harmful respiratory system metabolism detect btex gas indoors metal oxide mox sensor widely used lowcost high sensitivity mox sensor easily affected temperature humidity hence difficult detect btex gas accurately without additional calibration process calibration system heterogeneous mox sensor array machine learning mlbased technique linear regression lr nonlinear curve fitting nlcf artificial neural network ann exploited reduce impact temperature humidity performance evaluation setup gas concentration measurement system recorded sensor output temperaturecycled operation tco response five heterogenous mox sensor proposed calibration system annbased calibration system show reduction gas sensor variation due temperature humidity % average present maximum % reduction benzene % toluene % ethylbenzene % xylene gas respectively ,1
ML_473,electrical impedance spectroscopy also called bioimpedance applied biological tissue electrical measurement technique recently used ass food physiological state combined strong data analysis technique bioimpedance potential become non destructive realtime low cost portable technology food quality control whole supply chain recent work focusing bioimpedance data analysis food matrix briefly describe traditional statistical method recent machine learning solution progress achieved challenge still overcome improve application discussed ,1
ML_474,spiking neural network snns recently employed solve number machine learning problem traditionally addressed classical artificial neural network anns snns different anns incorporate time computation information encoded exact timing frequency discrete event spike snns promise deliver higher energy efficiency anns implemented neuromorphic hardware due eventdriven nature naturally different computational model introduce creates different design challenge implementation largescale network need addressed different architecture spiking accelerator presented aim facilitate accelerate process developing snns ml application traditionally addressed anns help bridge accuracy gap achieves significant speedup �� inference �� training compared software snn simulation certai,1
ML_475,proposes methodology based machine learning find apparent causal relation performance target design variable analog circuit diversified filtering wrapping variable selection algorithm utilized construct causal graph identifies major circuit design parameter used optimize performance analog circuit based constructed causal graph sequence design procedure extracted followed optimize performance design proposed methodology validated twostage opamp obtained causal graph agrees analytical design equation published literature selected twostage opamp result also show proposed methodology accelerate circuit design process effectively help designer understand reasoning behind different design decision ,1
ML_476,novel covid disease declared pandemic event early detection infection symptom contact tracing playing vital role containing covid spread demonstrated recent literature multisensor connected wearable device might enable symptom detection help tracing contact also acquiring useful epidemiological information present design implementation fully opensource wearable platform called hwatch designed include several sensor covid early detection multiradio wireless transmission tracking microcontroller processing data onboard finally energy harvester extend battery lifetime experimental result demonstrated mw average power consumption leading lifetime day small watch battery finally hardware software including machine learning mcu toolkit provided opensource allowing research community build hwatch ,1
ML_477,present experimental evaluation backpropagationbased technique background compensation timeinterleaved analog digital converter tiadc measurement obtained bit g tiadc test chip fabricated nm cmos technology demonstrate effectiveness technique backpropagationbased background compensation tiadc typically used highspeed digital communication receiver historically error backpropagation algorithm used train neural network machine learning application tiadc compensation application error symbol detection stage digital receiver processed backpropagation algorithm compute equivalent error tiadc output otherwise would directly observable backpropagated error applied train lowcomplexity adaptive equalizer compensates tiadc mismatch comparison prior art advantage technique robustness high convergence speed intrinsic background operation measurement aforementioned test chip show impact tiadc mismatch receiver performance eliminated addition improvement sndr sfdr almost db db respectively observed nyquist frequency compensation applied ,1
ML_478,sidechannel attack sca pose significant threat hardware security embedded device various logical circuitlevel countermeasure propose security come different power performance area overhead besides countermeasure guarantee security adversary enough time computing power hacking thus highly accurate realtime attack detection technique needed proposes switchedcapacitor circuit detect power scas intrusion detection current sense resistor external power supply line pulsed current pulled supply line introduce voltage difference proportional ir drop ir drop amplified parasitic insensitive switchedcapacitor amplifier compared predetermined threshold circuit achieved u typical detection time better % accuracy consuming mw nm cmos first mixedsignal ic implementation power sca detection compared prior approach monitor entire onchip power grid circuit computation energyefficient us single sensor need data mining machine learning classification ,1
ML_479,interconnection network networkonchips noc multimanycore processor critical infrastructure system enable data communication among processing core cache memory peripheral given criticality interconnects system severely subverted interconnection compromised threat hardware trojan hts penetrating complex hardware system multimanycore processor increasing due increasing presence third party player systemonchip soc design even deploying na��ve hts adversary exploit noc backbone processor get access communication pattern system discus one hts embedded noc multimanycore processor capable leaking sensitive information regarding traffic pattern external malicious attacker turn analyze ht payload data advanced algorithm machine learning infer application running processor reverse engineer architectural intellectual property ip system entertain idea routing obfuscation achieve desired tradeoff defense hts performance penalty also discus possibility making tradeoff tunable design parameter adjusted runtime based exte threat perception ,1
ML_480,rapid growth data intensive application everincreasing need energy efficient machine learningai hardware accelerator performance energy efficiency accelerator primarily limited due massive amount data movement processing engine offchip memory memory wall bottleneck mitigated performing accelerator specific computation memory cim array embedded rest logic block multiple embedded memory technology explored advance cim design among embedded dynamic random access memory edram backend line beol integrated caxis aligned crystalline caac indium gallium zinc oxide igzo transistor promising candidate igzo transistor extremely low leakage used access transistor edram bitcell enable multilevel cell mlc edram functionality moreover higher bandwidth achieved stacking multiple layer beol integrated igzo device monolithic manner improving cim performance analyze various igzo based edram bitcell topology igzo edram cim architecture support bit inputsactivations bit signed weight bit flash analog digital converter adc used mlc weight bit read sensing representative neural network model igzo edram peripheral b ad converter based cim design achieves % top inference accuracy cifar dataset % ideal software accuracy ,1
ML_481,true random number generator trngs used variety application including cryptography computer simulation gambling game machine learning hyperdimensional computing dynamic randomaccess memory drambased trngs widely used low cost available modern electronic device however existing drambased trngs produce random number either hardware overhead low throughput novel high dense high throughput high entropy drambased trng named dtrng exploit process variation inherited dram cell access transistor sense amplifier dtrng employed commodity dram chip hardware overhead standard memory controller command proposed method based controlling word line voltage supply part dram chip random number mode novel approach provided validated cadence circuit tool constructed x dram chip nm technology addition monte carlo simulation performed verify entropy generated number random sequence generated dtrng passed nist test without postprocessing demonstrating randomness suitability security scheme dtrng considered milestone towards low cost high efficient secure hardware ai iot application ,1
ML_482,visual attention one important mechanism human visual perception recently modeling becomes principal requirement optimization image processing system numerous algorithm already designed saliency prediction however work found content propose saliency model stereoscopic video algorithm extract information three dimension content ie spatial temporal depth model benefit property interest point close human fixation order build spatial salient feature besides perception depth relies strongly monocular cue model extract depth salient feature pictorial depth source since weight fusion strategy often selected adhoc manner suggest machine learning approach used artificial neural network allows define adaptive weight based eyetracking data result proposed algorithm tested versus groundtruth information stateoftheart technique ,1
ML_483,quality assessment stereoscopic image much complex image quality assessment metric image achieved good performance symmetric distorted image given poor performance asymmetric distorted image improve perception consistency symmetric asymmetric distorted image present machine learningbased fullreference image quality assessment method learns multi iqa metric considering change left view right view depth information impact human perception method considers quality two view depth information since symmetric asymmetric distortion impact left right view image differently propose different feature symmetric asymmetric distorted image experimental result show method better performance dbased quality assessment metric state art specially designed quality assessment metric ,1
ML_484,depth estimation great challenge field computer vision machine learning rich literature focusing depth estimation stereo vision monocular imaging domain depth estimation light field image still infancy proposes fully convolutional neural network estimate disparity light field image proposed method parametric able adapt input image arbitrary size lightweight le prone overfitting thanks fully convolutional nature experiment reveal competitive result state art demonstrating potential offered deep learning solution disparity estimation light field image ,1
ML_485,present method generating stereoscopic multiangle video frame computer game grand theft auto v developed mod capture synthetic frame allows u create geometric distortion like occur real video distortion cause viewer discomfort watching movie datasets generated way aid solving problem related machinelearningbased assessment stereoscopic multianglevideo quality trained convolutional neural network evaluate perspective distortion converged camera ax stereoscopic video tested real movie neural network discovered multiple example distortion ,1
ML_486,incremental machine learning required future realtime data analytics introduces multilayer cmosrram accelerator incremental leastsquares based learning neural network given input buffered data hold layer rram memory intensive matrixvector multiplication firstly accelerated layer digitized rramcrossbar remaining incremental leastsquares algorithmic operation feature extraction classifier training accelerated layer cmos asic incremental cholesky factorization accelerator realized consideration parallelism pipeline experiment result shown accelerator significantly reduce training time acceptable accuracy compared dcmosasic implementation achieve x smaller area x faster runtime x energy reduction compared gpu implementation show x speedup x energysaving ,1
ML_487,growth neural network nns machine learning ml usage rapidly increased last decade traditional dynamic randomaccess memory dram struggling meet computational throughput demand nns become bottleneck system one commonly proposed solution nearmemory computation nmc hardware accelerator move computation closer data resulting improved throughput reduced power consumption analyze critical nmc architecture implementation specifically dstacked dram memory organized literature across structure configuration application performance metric challenge opportunity ,1
ML_488,machine learning form artificial neural network anns gained considerable traction application image recognition speech recognition application typically employ subset anns known convolutional neural network cnns reuse parameter thus reduce memory bandwidth however type ann provide reuse opportunity autoencoders long shortterm memory research focused implementing cnns extensive sram ann size restriction performance degradation used application utilize type ann demonstrates customized ddram wide databus combined applicationspecific layer produce system meeting requirement embedded system employing multiple instance disparate anns ,1
ML_489,chirocentric interface sometimes hailed holy grail humancomputer interaction however implementation uis require cumbersome device tethered wearable datagloves limited term functionality obscure algorithm used hand pose gesture recognition limitation inhibit designing deploying formally evaluating interface ameliorate situation describe implementation practical chirocentric ui platform targeted immersive virtual environment infrared tracking system contribution two machine learning technique recognition hand gesture trajectory user hand time hand pose configuration user finger based marker cloud rigid body data preliminary system implementation bimanual duo large immersive tiled display conclude plan system platform design evaluation bimanual chirocentric uis based framework interaction fidelity analysis fifa ,1
ML_490,experiencing immersive virtual environment suitable trigger metaphor often needed eg interaction object physical reach system control blowclick approach based nonverbal vocal input proven valuable trigger technique previous however original detection method vulnerable false positive thus limited potential therefore extended existing approach adding machine learning method reliably classify blowing event found support vector machine gaussian kernel performing best least latency precision furthermore added acoustic feedback nvvi trigger increase user confidence whose absence also stated limitation previous extended technique repeated conducted fitts law experiment participant could confirm possible nvvi reliable trigger part handsfree pointandclick interface furthermore tested reaction time measure trigger performance without influence pointing calculated device throughput ensure comparability ,1
ML_491,research investigates interacting tangible interface tuis affect spatial cognition impact tuis subject conducted n student learned operation anesthesia machine tui compared two interface commonly used anesthesia education graphical interface abstract simulation model anesthesia machine physical interface real world anesthesia machine overall tui found significantly compensate low spatial cognition domain anesthesia machine training ,1
ML_492,introduce letha learning easy data test hard learning paradigm consisting building strong prior high quality training data combining discriminative machine learning deal lowquality test data contribution implementation concept pose estimation first automatically build model object interest highdefinition image devise poseindexed feature extraction scheme train single classifier process feature vector given low quality test image visit many hypothetical pose extract feature consistently evaluate response classifier since process us location recorded learning require matching point anymore boosting procedure train classifier common pose able deal missing feature due context selfocclusion result demonstrate method combine strength global image representation discriminative even tiny image robustness occlusion approach based local feature point descriptor ,1
ML_493,realtime facial performance capture recently gaining popularity virtual film production driven advance machine learning allows fast inference facial geometry video stream learningbased approach significantly influenced quality amount labelled training data tedious construction training set real imagery replaced rendering facial animation rig onset condition expected runtime learn synthetic actorspecific prior adapting stateoftheart facial tracking method synthetic training significantly reduces capture annotation burden theory allows generation arbitrary amount data practical reality training time compute resource still limit size training set construct better smaller training set investigating facial image appearance crucial tracking accuracy covering dimension expression viewpoint illumination reduction training data order magnitude demonstrated whilst tracking accuracy retained challenging onset footage ,1
ML_494,inferring dense depth stereo crucial several computer vision application semi global matching sgm often preferred choice due good tradeoff accuracy computation requirement nevertheless suffers two major issue streaking artifact caused scanline optimization approach core algorithm may lead inaccurate result high memory footprint may become prohibitive high resolution image device constrained resource propose smart scanline aggregation approach sgm aimed dealing issue particular contribution threefold leveraging machine learning proposes novel generalpurpose confidence measure suited stereo algorithm based feature outperforms state oftheart ii taking advantage confidence measure proposes smart aggregation strategy sgm enabling significant improvement small overhead iii overall strategy drastically reduces memory footprint sgm time improves effectiveness execution time provide extensive experimental result including crossvalidation multiple datasets kitti kitti middlebury ,1
ML_495,camera relocalization needed several application augmented reality robot navigation however still challenging realtime accurate method hybrid method combing machine learning approach geometric approach realtime camera relocalization single rgb image introduce sparse feature regression forest improve machine learning part regression forest propose novel split function us whole feature vector instead classical binary test function improve accuracy dd point correspondence moreover sparse feature extraction surf feature reduce time processing result indicate method realtime hybrid method m per frame also achieve result accurate best stateoftheart method hybrid method outperform machine learning based sparse feature based method ,1
ML_496,manually labelling point cloud scene training data machine learning application time labour intensive aim reduce effort associated learning semantic segmentation task introducing semi supervised method operates scene small number labelled point advocate pseudolabelling combination pointnet neural network architecture point cloud classification segmentation also introduce method incorporating information derived spatial relationship aid pseudolabelling process approach practical advantage current method working directly point cloud reliant predefined feature moreover demonstrate competitive performance scene two publicly available datasets provide study parameter sensitivity ,1
ML_497,object symmetry common daily life industrial context often ignored recent literature pose estimation image analytical way link symmetry object appearance image explain symmetrical object challenge training machine learning algorithm aim estimating pose image propose efficient simple solution relies normalization pose rotation approach general used pose estimation algorithm moreover method also beneficial object almost symmetrical ie object detail break symmetry validate approach fasterrcnn framework synthetic dataset made object tless dataset exhibit various type symmetry well real sequence tless ,1
ML_498,wasserstein distance employed determining distance point cloud variable number point invariance point order however high computational cost associated wasserstein distance hinders practical application largescale datasets propose embedding method point cloud aim embed point cloud euclidean space isometric wasserstein space defined point cloud numerical experiment demonstrate point cloud decoded euclidean average interpolation embedding space accurately mimic wasserstein barycenter interpolation point cloud furthermore show embedding vector utilized input machine learning model eg principal component analysis neural network ,1
ML_499,method learning point cloud became ubiquitous due popularization scanning technology advance machine learning technique among method pointbased deep neural network utilized explore design optimization task however engineering computer simulation require highquality meshed model challenging automatically generate unordered point cloud propose pointffd novel deep neural network learning compact geometric representation generating simulationready meshed model built upon autoencoder architecture pointffd learns compress point cloud latent design space network generates polygonal mesh selecting deforming simulationready mesh template benchmark experiment show proposed network achieves comparable shapegenerative performance existing stateoftheart pointbased generative model real worldinspired vehicle aerodynamic optimization demonstrate pointffd generates simulationready mesh realistic car shape lead better optimized design benchmarked network ,1
ML_500,neural radiance field nerf become popular framework learning implicit representation addressing different task novelview synthesis depthmap estimation however downstream application decision need made based automatic prediction critical leverage confidence associated model estimation whereas uncertainty quantification longstanding problem machine learning largely overlooked recent nerf literature context propose stochastic neural radiance field snerf generalization standard nerf learns probability distribution possible radiance field modeling scene distribution allows quantify uncertainty associated scene information provided model snerf optimization posed bayesian learning problem efficiently addressed variational inference framework exhaustive experiment benchmark datasets demonstrate snerf able provide reliable prediction confidence value generic approach previously proposed uncertainty estimation domain ,1
ML_501,many machine learning problem involve regressing variable noneuclidean manifold���eg discrete probability distribution pose object one way tackle problem gradientbased learning differentiable function map arbitrary input euclidean space onto manifold establish set desirable property mapping particular highlight importance preimages connectivityconvexity illustrate property case regarding rotation theoretical consideration methodological experiment variety task various differentiable mapping rotation space conjecture importance local linearity show mapping based procrustes orthonormalization generally performs best among mapping considered rotation vector representation might also suitable restricted small ,1
ML_502,point cloud registration essential problem object scene understanding many realistic circumstance however noise data acquisition large motion two point cloud existing approach hardly satisfactorily without good initial alignment manually marked correspondence inspired popular kernel method machine learning community put forward general point cloud registration framework constructing kernel function point cloud specifically gaussian mixture based point cloud established probability product kernel function exploited registration enhance generality framework se onmanifold optimization scheme employed compute optimal motion experimental result show registration framework work robustly many outlier presented motion point cloud relatively large compare favorably related method ,1
ML_503,recognition three dimensional object challenging problem especially cluttered occluded scene many existing method focus specific type object scene require prior segmentation describe robust efficient general object recognition method combine machine learning procedure local feature without requirement priori object segmentation experiment validate method various object type engineering street data scan ,1
ML_504,applying machinelearning technique inference markov random field build improved model integrating two different modality visual input standard color camera delivers highresolution texture data also enables u enhance data calculated range output timeofflight camera term noise spatial resolution proposed method increase visual quality data make kind camera promising device various upcoming dtv application twocamera setup believe design lowcost fast highly portable scene acquisition system possible near future ,1
ML_505,automatic dtod conversion important application filling gap increasing number display still scant content however existing approach excessive computational cost complicates practical application fast automatic dtod conversion technique proposed us machine learning framework infer structure query color image training database color depth image assuming photometrically similar image analogous structure depth map estimated searching similar color image database fusing corresponding depth map large database desirable achieve better result computational cost also increase clusteringbased hierarchical search compact surf descriptor characterize image proposed drastically reduce search time significant computational time improvement obtained regarding stateoftheart approach maintaining quality result ,1
ML_506,dtod conversion important reducing current gap number display available content automatic dtod image conversion approach based machine learning principle stemming hypothesis image similar structure likely similar structure depth query color image estimated color plus depth image dataset cluster common scene structure computed offline matching process performed select cluster centroid similar query image prior depth map computed fusing depth map image cluster edgebased postprocessing stage applied prior depth map estimation enhance final scene depth estimation promising result obtained two commonly used database achieving similar performance much complex stateoftheart approach ,1
ML_507,automatic dtod conversion aim reduce existing gap scarce content incremental amount display reproduce content automatic dtod conversion algorithm extends functionality existing machine learning based conversion approach deal moving object scene static background assumption image high similarity color likely similar structure depth query video sequence inferred color + depth training database first depth estimation background image query video computed adaptively combining depth similar image query one optical flow enhances depth estimation different moving object foreground promising result obtained widely used database ,1
ML_508,last year machine learning ml seen explosive growth wide range research field industry advancement software defined radio sdr allows intelligent adaptive radio system built wireless communication field number opportunity apply ml technique novel approach demodulation sequence sequence seqseq model proposed type model shown effectively psk data also number useful property machine learning algorithm basic seqseq implementation bpsk qpsk demodulation presented learned property automatic modulation classification amc ability adapt different length input sequence demonstrated exciting avenue research provides considerable potential application next generation g network ,1
ML_509,g network expected able satisfy variety vertical service mobile user business demand automotive industry network slicing promising technology g provide network naas wide range service run different virtual network deployed shared network infrastructure moreover son selforganizing network g expected significant evolution guarantee full intelligence automatic faster management optimization deal requirement recently softwaredefined networking sdn network function virtualization nfv big data machine learning proposed emerging technology necessary tool g especially network slicing aim integrate various machine learning ml algorithm big data sdn nfv build comprehensive architecture experimental framework future son network slicing finally based framework successfully implemented early state traffic classification network slicing mobile broadband traffic application implemented broadband mobile lab bml national chiao tung university nctu ,1
ML_510,neural network architecture used problem ? common question encountered nowadays searched slew paper published last year cross domain machine learning wireless communication author found several researcher working multidisciplinary field continue question regard make attempt provide guide choosing neural network example application field wireless communication specifically consider modulation classification deep learning used address modulation classification quite extensively real world data none paper give intuition neural network architecture must chosen get good classification performance experiment realized simple example simple wireless channel model used reference understand choose appropriate deep learning model specifically neural network model based system model problem consideration provide numerical result support intuition arises various case ,1
ML_511,known adopting variableresolution vr adcs millimeterwave mmwave massive multipleinput multipleoutput mamimo receiver improves energy efficiency ee however effect imperfect channel state information csi receiver detrimental achieving ee none previous work consider imperfect csi designing adc bit allocation ba mamimo receiver propose deep learning based framework achieve nearoptimal ee mamimo receiver contribution include machine learning approach arrive ba achieves nearoptimal ee training framework combination perfect imperfect channel condition derived capacity maximization simulation show ee obtained proposed approach close brute force perfect imperfect channel also simulation claim computational complexity advantage proposed approach compared brute force sufficient learning channel presented system ,1
ML_512,cognitive radio cr expected play important role g wireless communication meet challenging requirement massive machinetomachine mm connectivity internet thing iot cr network capable wideband spectrum sensing w provide opportunistic spectrum access abate spectrum scarcity however w approach severely limited analog digital converter adc speed subnyquist sampler alleviate burden adc compressively sampling wideband signal focus two sampler analog information converter aic modulated wideband converter mwc exploit spectral sparsity specifically partitioned w scheme proposed modified aic mwc sampler realtime signal uhf tv band mhz acquired software defined radio sdr occupiedvacant band detected proposed w approach orthogonal matching pursuit omp sparse bayesian learning sbl based sparse recovery approach aided detection support recovery performance simulation experimental investigation show proposed approach good potential w mm iot application ,1
ML_513,ultrareliable low latency communication urllc key feature g requires improved mobility performance reliability future number device going increase many time g compared current g number mobility handover scenario bound increase many fold without proper technology may induce handover failure according test done north america observed handover failure hof rate % urban area % downtown area successful recovery hof % also observed equipment ue face radio link failure rlf lead hof interruption time therefore ensure better quality experience qoe g nr radio important minimal interruption time high handover success rate propose novel machine learning ml beam measurement based advance handover ho algorithm concept ho initiated advance ue run rlf ensure le hof proposed algorithm network parameter used train ml model based serving cell reference signal received power rsrp block error rate bler timing advance ta serving beam direction proposed idea performance existing handover mechanism show reduction hof rate % ,1
ML_514,recent research suggests physical unclonable function pufs useful security tool internet thing however pufs vulnerable many known machine learning attack threaten effectiveness present unique taxonomy known machine learning attack exploit pufs offer balanced comprehensive evaluation serve invaluable single point reference undertaking research area ,1
ML_515,apply suitable precoder downlink dl mumimo system imperative reference signal estimating dl channel quality ue reported back gnb feedback sent used precoder selection codebook gnb applied multiplexing different user downlink data transmission since typical wireless channel fading nature important estimate channel least every coherence interval feedback step result significant improvement system performance incurs large overhead hence reduces spectral efficiency system especially fastfading environment consequently high mobility scheduled mumimo set avoid large overhead also reduce interuser interference therefore facilitate scenario consider application machine learning ml predicting channel quality report thus enabling mumimo transmission high mobility analyze performance different ml algorithm prediction csi typeii parameter subsequently impact overall system performance wrt different periodicity feedback obtained result promising improved system performance achieved compared conventional approach addition enhanced spectral efficiency furthermore simulation result corroborate efficacy proposed machine learning technique ,1
ML_516,investigates effect offloading machine learning autonomous vehicle algorithm edge g network describes implementation field test experiment canadian encqor g network edge computing command supthsup scaled rc vehicle vehicle us camera feed predict steering prediction computed server edge network contains pretrained neural network found autonomous vehicle performance similar without offloading discus limit result provides overview future opportunity obstacle offloading machine learning functionality autonomous vehicle g ,1
ML_517,age information aoi reflects time elapsed generation packet g equipment ue reception packet controller design aoiaware radio resource scheduler ues via reinforcement learning proposed consider remote control environment number ues transmitting timesensitive measurement remote controller consider aoi minimization problem formulate problem tradeoff minimizing sum expected aoi ues maximizing throughput network inspired success machine learning solving large networking problem low complexity develop reinforcement learningbased method solve formulated problem used stateoftheart proximal policy optimization algorithm solve problem simulation result show proposed algorithm outperforms considered baseline term minimizing expected aoi maintaining network throughput ,1
ML_518,recently many attempt apply machine learning mlbased prediction mechanism wireless network one question reliable prediction well ml model learn radio environment initial result quality qos prediction example throughput prediction focus suggesting set feature improve prediction performance different prediction horizon thereby identify important feature large impact radio environment data input ml model end consider information space time network domain particular show feature cell throughput previous user data significantly improve ml model performance besides importance input feature also investigate prediction performance deteriorates different prediction horizon ,1
ML_519,traditionally resource management capacity allocation controlled networkside cellular deployment autonomicity added network design machine learning technology largely followed paradigm benefiting higher compute capacity informational context available network core however network service disaggregated decentralized model rely assumed level network information availability may longer function reliably present inverted view resource management paradigm one client device executes learning algorithm manages mobility scenario network corresponding data underneath centrally managed ,1
ML_520,indoor location information increasing importance contemporary communication service application discus long shortterm memory lstm performance indoor localization nonlineofsight nlos condition received signal strength r channel state information csi obtained wifi signal describe csi r acquisition system used build rich dataset experiment classical machine learning deep learning model distance range error matrix combined confusion matrix obtain distance range error probability demonstrated lstm model exhibit maximum range error le % probability ,1
ML_521,throughput prediction remains relevant challenging problem area wireless networking user provider would benefit predictive quality qos potential improve perceived quality user also provide valuable insight network planning optimization deployment many factor hinder adoption machine learning ml model data collection overhead network operator prediction uncertainty ml model lack transparency ml inference process provide result instantaneous throughput prediction ml technique data throughput prediction collected network one biggest operator asia improves confidence result also discus custom loss function extract value prediction error finally look explainability method providing transparency prediction ml algorithm various explainability method prove without explicitly programmed ml algorithm exploit learn underlying physical phenomenon operating principle wireless network ,1
ML_522,ability various machine learning ml algorithm analyse predict spectral occupancy high frequency hf spectrum compared one data june ���june hf spectral occupancy measurement collected dedicated measurement system installed cyprus investigated advance data analysis observational predictive eight ml algorithm applied one one model hf spectral occupancy procedure measuring modeling congestion function time day day featured result show xgboost algorithm performs best root mean squared error rmse mean absolute error mae low respectively correlation high result may encourage ml model frequency usage planning management reduce spectral congestion hf broadcast,1
ML_523,determining whether network provide required resource result required quality qos connected automated mobility cam application crucial human safety involved order identify potential qos deterioration machine learning currently considered momentous enabler g beyond system exploited order timely predict change qos proactively notify cam application order flexibly adapt explores validity viability recurrent neural network rnns specifically lstms potential enablers realizing prediction end novel qos prediction mechanism presented us lstm architecture networkrelated qos metric order identify specific pattern predict advance qos available near future connected automated vehicle cav simulationbased evaluation proposed scheme prove potential gain cam domain ,1
ML_524,increasing demand heterogeneous service generates redundant signalling leading communication overhead congestion network core propose novel aienabled edge architecture minimize signalling redundancy deploy clusterbased signalling admission control framework maximize efficiency link bandwidth resource edge core network minimize redundant signalling two classical unsupervised machine learning algorithm kmean rankingbased clustering result show proposed framework provides substantial latency reduction maximizing resource utilization proposed approach % superior reducing redundant signalling compared recent ,1
ML_525,transportation network desirable detect count people around bus station achieve goal unified dynamic human activity recognition people counting harc applied dataset wifibased activity recognition wiar performance evaluation carried machine learningbased data processing framework processing result reported show accuracy achieved harc % adam optimizer method used ,1
ML_526,order satisfy evergrowing quality qos requirement innovative service cellular communication network constantly evolving recently g nonstandalone nsa mode deployed intermediate strategy deliver highspeed connectivity early adopter g incorporating long term evolution lte network infrastructure addition technological advancement novel communication paradigm anticipatory mobile networking aim achieve intelligent usage available network resource exploitation context knowledge novel method proactive prediction endtoend behavior seen key enablers first empirical analysis clientbased endtoend data rate prediction g nsa vehicletocloud communication although operation mode characterized massive fluctuation observed data rate result show conventional machine learning method utilize locally acquirable measurement achieving comparably accurate estimation endtoend behavior ,1
ML_527,machine learning method adapt parameter model constrained lie given model class fixed learning procedure based data active observation adaptation done pertask basis retraining needed system configuration change resulting inefficiency term data training time requirement mitigated domain knowledge available selecting suitable model class learning procedure collectively known inductive bias however generally difficult encode prior knowledge inductive bias particularly blackbox model class neural network metalearning provides way automatize selection inductive bias metalearning leverage data active observation task expected related future priori unknown task interest metatrained inductive bias training machine learning model potentially carried reduced training data andor time complexity provides highlevel introduction metalearning application communication system ,1
ML_528,benchmark qlearning method various action selection strategy intelligent orchestration network edge qlearning reinforcement learning technique aim find optimal action policy taking advantage experience past without utilizing model describes dynamic environment experience refer observed causality action corresponding impact environment environment qlearning composed virtualized networking resource dynamic monitored spindump innetwork latency measurement tool support quic tcp optimize orchestration networking resource introducing qlearning part machine learning driven intelligent orchestration applicable edge based benchmarking result identify action selection strategy support network orchestration provides low latency packet loss considering network resource allocation edge ,1
ML_529,machine learningbased data rate prediction one key driver anticipatory mobile networking application dynamic radio access technology rat selection opportunistic data transfer predictive caching equipment uebased prediction approach rely passive measurement network quality indicator successfully applied forecast throughput vehicular data transmission however achievable prediction accuracy limited ue unaware current network load overcome issue propose cooperative data rate prediction approach brings together knowledge client network domain real world proofofconcept evaluation utilize software defined radio sdrbased control channel sniffer falcon order mimic behavior possible networkassisted information provisioning future g network result show proposed cooperative prediction approach able reduce average prediction error % respect ongoing standardization effort regarding implementation intelligence network management argue future g network go beyond networkfocused approach actively provide load information ues order fuel pervasive machine learning catalyze uebased network optimization technique ,1
ML_530,development fifthgeneration g system capability flexibility enables emerging application stringent requirement ultrahighresolution video streaming online interactive virtual reality vr gaming hence resource management problem becomes complicated past machine learning powerful tool provide solution article deep deterministic policy gradient ddpg used schedule resource edge network environment integrate radio resource structure componentized markov decision process mdp action interactivitybased group simulation result see user satisfied ddpgbased radio resource management especially bandwidth latency demanding situation ,1
ML_531,nonorthogonal multiple access noma mmwave two complementary technology support capacity demand arises g beyond network increasing number user served simultaneously providing solution scarcity bandwidth method clustering user mmwavenoma system objective maximizing sumrate unsupervised machine learning technique namely hierarchical clustering utilized automatic identification optimal number cluster simulation prove proposed method maximize sumrate system satisfying minimum qos user without need number cluster prerequisite compared clustering method kmeans clustering ,1
ML_532,exponential increase size digital image database past year traditional way manually annotating image text textbased query image retrieval giving way contentbased image retrieval cbir system visual content image automatically index retrieve digital image however gap highlevel human perception image lowlevel image feature used describe content gap lowlevel image feature semantic image content major bottleneck faced traditional cbir system modern cbir system overcome problem interactive learning bringing loop system learn feedback given relevance irrelevance current retrieval result present framework interactive contentbased image retrieval considering relevance feedback learning problem learning machine based radial basis function rbf neural network nn implemented system tested effectiveness database image ,1
ML_533,wearable device recently gained foothold market uptake smartwatches strong tie smartwatch owner highly predictable position smartwatch body internal sensor enabling wide array application leverage context focus gesture recognition system augment interaction multimedia application define set seven gesture relevant across several application collect extensive dataset two smartwatches motorola moto apple watch long short term memory neural network gesture recognition based sensor data smartwatches provide extensive evaluation classification accuracy system provide sensitivity analysis find long short term memory configuration maximizes classification accuracy also show extent long short term memory neural network outperform traditional machine learning approach also illustrate application built android io platform allows developer easily integrate gesture recognition system conclude description case underscore potential impact contribution ,1
ML_534,troubleshooting millimeterwave mmwave wireless network complex due directionality communication issue deafness misaligned antenna blockage may severely impact network performance identifying crucial improve network deployment end access lowerlayer information important however commercial offtheshelf mmwave wireless device typically provide information even would detecting effect deafness based information single node form part network typically hard design evaluation external sniffing device infer aforementioned performance issue narrowband physical layer energy trace sniffer need decode data resulting simple effective approach also preserve privacy work encrypted network key contribution machine learning framework enables automated energy trace analysis coping nonstationarity trace evaluate performance practice offtheshelf wireless device operating ghz band result show framework correctly infers physical layer event virtually case thus providing valuable information troubleshoot issue mmwave network ,1
ML_535,interarea oscillation one challenge secure stable operation largescale interconnected acdc power system voltage source converter high voltage direct current vschvdc transmission system feature fast flexible power regulation capability supplementary damping controller sdc designed vschvdc suppress interarea oscillation largescale acdc power system innovative adaptive dynamic programming approach namely goal representation heuristic dynamic programming grhdp proposed design sdc vschvdc grhdp based sdc consists three neural network automatically form internal adaptive reward signal facilitate better mapping system state control action therefore grhdp based sdc significantly improve dynamic performance power system without knowing exact mathematic model power system grhdp based sdc still conduct quick learning universal control characteristic strong adaptability superior conventional leadlag sdc case undertaken based twoarea four machine power system one vschvdc transmission line conventional leadlag sdc also studied comparison simulation result show proposed grhdp based sdc better performance damping interarea oscillation conventional leadlag sdc wide range system operating condition ,1
ML_536,covid pandemic impact associated air quality aq mortality index significantly affected high pollution level significant mobility limitation contributed slow pandemic italy side effect definite decrease pollution level phase easing limit still see significant reduction commuting school related car traffic emission high resolution aq monitoring allow obtain picture aq smart city capable reach long sought emission goal furthermore could support identification forecasting possible future local sarscov outburst outcome high resolution aq monitoring opportunistic campaign achieved deployment field data driven calibration trough machine learning smartphone centered iot infrastructure capable store visualize give exposome feedback monitoring volunteer ,1
ML_537,italy government countermeasure covid large impact citizen company industry affecting electric energy consumption lombardy surely affected region term covid case slowdown production activity city two brescia milan impact electric distribution analysed keeping entry force government action relevant time reference different response emergency two city point prevalent service activity milan industrial character brescia moreover brescia studied variation electric demand daily load profile specific feeder representative consumer category analysis underline need distribution system operator build infrastructure able manage data driven approach big data machine learning unexpected variation daily profile order make electric grid resilient ,1
ML_538,present integration fexwaves feature extraction waveform segmentation application queen distribution network monitoring system application attribute shape factor voltage dip make easier classify voltage dip origin namely ass event source location upstream downstream point measurement classification carried machine learning algorithm integration queen system achieved thanks queen pyservice automated tool developed rse aimed extraction event voltage signal queen database application allowed integration fexwaves classifier real scenario making possible intensive validation latter large number voltage dip first time ,1
ML_539,experimental investigation reported machine learning based regressive approach artificial neural network evaluate quality experience quality network measurement packet loss delay traffic congestion control performance slice defined inside wide area network test bed method allows network recover best performance according knowledge defined network approach ,1
ML_540,present analysis method capable monitoring thermal behavior medium voltage line theoretical concept method based analysis frequency response line admittance measurement used identify operating temperature underground cable several factor affect conductor temperature overload current variation environmental condition health status insulating material situation increase cable temperature consequently resistance conductor electrical parameter cable change frequency response also change monitoring system based machine learning technique used classify magnitude phase monitoring method proposed us feedforward multilayer neural network multivalued neuron order classify working temperature cable allowing prevention catastrophic failure ,1
ML_541,tor anonymous internet communication system based second generation onion routing network protocol tor really difficult trace user internet activity reason usage tor intended order protect privacy user freedom ability conduct confidential communication without monitored tor even used cyber criminal order cover illegal activity tor community observed instance alarming increase number malware abuse popular anonymizing network hide command control infrastructure technique able identify whether host generating torrelated traffic resort wellknown machine learning algorithm order evaluate effectiveness proposed feature set real world environment addition demonstrate proposed method able recognize kind activity eg email pp application analysis tor network ,1
ML_542,intended bring added value interdisciplinary domain computer science engineering particular electrical machine machine learning two approach principal component analysis polynomial interpolation reduce dimension family q axis current curve describe magnetostatic characteristic synchronous reluctance machine synrm ,1
ML_543,nowadays private company constant race increase profitability chasing cost reduction facing market competition also agriculture analysis costeffectiveness measuring technological innovation profitability becomes necessary ` smart farm model exploit information coming technology like sensor intelligent system internet thing iot paradigm understand influential noninfluential factor considering environmental productive structural data coming large number source goal design deploy practical task exploit heterogeneous real datasets aim forecast reconstruct value comparing innovative machine learning technique standard one application methodology field apparently refractory technology agricultural one show ample margin innovation investment supporting request need coming company wish employ sustainable optimized agricultural industrial business ,1
ML_544,neural network nns discussed connection possible induction machine drive mathematical model nn well commonly used learning algorithm presented possible application nns induction machine control discussed simulation nn successfully identifying nonlinear multivariable model inductionmachine stator transfer function presented previously published application discussed possible future application proposed ,1
ML_545,proposes technique designing robust power system stabilizer combine hsubinfinsub optimal control bilinear transformation bilinear transformation used prevent polezero cancellation phenomenon inherent hsubinfinsub mixed sensitivity design assign dominant pole desired location splane technique applied design power system stabilizer single machine connected infinite bus proposed controller compared conventional leadlag controller controller design based evolutionary algorithm called pbil population based incremental learning frequency time domain simulation presented demonstrate effectiveness proposed design approach ,1
ML_546,addition well known linguistic alignment process dyadic communication eg phonetic syntactic semantic alignment provide evidence genuine multimodal alignment process namely semiotic alignment communicative element different modality ldquoroutinize intordquo crossmodal ldquosupersignsrdquo call multimodal ensemble computational model human communication need expressive model multimodal ensemble exemplify semiotic alignment mean empirical example building multimodal ensemble propose graph model multimodal dialogue expressive enough capture multimodal ensemble line model define novel machine learning aim training classifier detect semiotic alignment dialogue model support approach need gain insight realistic human machine communication ,1
ML_547,propose combination machine learning socially constructed concept sentiment polarity identification detecting word polarity difficult due limitation current sentiment dictionary also due colloquial term often used current approach disregard dynamic language ie word often created comprising different polarity fact online community creative coining term certain subject ldquotweetuprdquo request meet friend via twitter ldquowhackrdquo street slang meaning bad approach utilizes generated dictionary urban term definition resource polarity concept therefore able map newly created word respective polarity also enhance common expression additional feature reinforce polarity strengthening initial finding empirically show polarity reinforcement improves sentiment classification ,1
ML_548,several industrialgrade power system simulation tool commercially available market expensive acquire timeconsuming learn result institution utility academicresearch organization afford one power system simulation tool simulation tool differ component modelling different simulation tool give different result system model understanding reason discrepancy result trivial investigate effect variation modelling generator saturation carried eigenvalue analysis single machine infinite bus smib system psse powerfactory eurostag ssat matneteig simulation result show effect saturation local mode erratic need research saturation representation power system stability simulation tool ,1
ML_549,extreme learning machine elm simplified neural network nonlinearly embeds input data higher dimensional space randomly generated sigmoidal basis function training target vector approximated linear weighted sum basis function elm algorithm applied classify static hand gesture represent different letter auslanaustralian sign language dictionary elm offer fast learning consistent performance one tuning parameter adapted multiclass classification multi output regression without increase training time low computational intensity short training time make superior traditional algorithm hidden markov model hmms single recurrent feed forward neural network real time translation preliminary experimental result shown elm produce good generalization performance classifier increasing dimensionality data result better separation consequently gesture become distinguishable improving probability correct classification investigation classification performance entire alphabet currently way ,1
ML_550,many complex real world phenomenon difficult directly controlled experiment instead computer simulation become commonplace feasible alternative due computational cost high fidelity simulation surrogate model often employed dropin replacement original simulator order reduce evaluation time context neural network kernel method modeling technique become indispensable surrogate model proven useful task optimization design space exploration visualization prototyping sensitivity analysis fully automated machine learning tool generating accurate surrogate model active learning technique minimize number simulation maximize efficiency ,1
ML_551,contentbased image retrieval system extract retrieve image lowlevel feature color texture shape nevertheless visual content allow formulate semantically meaningful image query image annotation system solution solve inadequacy cbir system allow text based image retrieval several study automatic image annotation utilizing machine learning technique image representation low level feature extracted either global local method however typically approach suffer low correlation globally assigned annotation visual feature used obtain annotation automatically approach enhance effectiveness cbir learning based automatic image annotation based bag visual word image representation created automatically set manually annotated training image experimentation performed annotated image training image testing imagenet result shown % performance accuracy result believed one step towards enhancing performance effectiveness existing cbir minimizing semantic gap ,1
ML_552,cloud computing one fastest growing technology developing country like ethiopia growing ict cloud computing attractive choice adopt however adoption technology planned ahead time taking consideration various factor make adoption successful objective research propose cloud readiness assessment framework expert system ass cloud readiness recommend cloud deployment model adopt research grounded wellstudied technological innovation adoption theory technology organization environment framework toe diffusion innovation doi technology acceptance model tam based theoretical foundation cloud readiness framework proposed survey designed based framework survey initial dataset generated expanded synthetic data generator expert system relies predictive modeling assessing cloud readiness weka machine learning platform j decision tree algorithm experimented various setting train obtain acceptable model accuracy training performed original dataset synthetically generated dataset best obtained model accuracy % original dataset ,1
ML_553,simple term speech synthesis process generating spoken language machine basis text input texttospeech specific type take input raw text aim mimic human process reading computerassisted learning cal defined learning teaching computer packaged knowledge content learning material cal involves computer program file developed specifically educational purpose mobile learning mlearning ability obtain provide educational content personal pocket device pda smartphones mobile phone mlearning educational activity make sense technology facilitates support mobility learning discus development mathematical computerassisted learning mobile application integrates texttospeech synthesis module south african lowresourced language initially targeting sepedi language system aimed assisting mathematically illiterate person foundation phase learner learn understand representation articulation mathematical expression incorporating four basic arithmetic operation addition subtraction multiplication ision also incorporates numeracy function result obtained experiment conducted prototype cal system show % participant impressed developed mobile application great need enhance development software application support teaching learning activity foundation phase education south africa ,1
ML_554,background telecentre implementation developing country ghana inundated failure various method proposed mitigate failure considering substantial amount invested various method proposed recent shown casebased reasoning cbr used predict sustainability telecentre unfortunately factor play major role collapse telecentres yet determined objective combine two approach ictd evaluation machine learning identify important factor sustainability telecentre case applies wellestablished feature subset selection f methodology identify influential factor method apply cbr f real life dataset predict design reality gap score drgs compare two machine learning f method expert based selection eb method benchmark archangel also union intersection selected factor predict drgs finding demonstrate experiment based real world data set combination machine learning information system identify important factor give refreshing indication suggesting feasible cbr f identify important factor ict initiative adequately predict outcome initiative implication approach possible manager owner telecentres focus important factor affords managersowners opportunity channel limited resource important factor thereby saving ailing centre ,1
ML_555,advance artificial intelligence general machine learning particular resulted need pay attention provision privacy data anlyzed example sensitive data analysis might analysis iniduals medical record case might need draw insight data time maintaining privacy participant case given birth privacypreserving data analyitics privacy typically guaranteed differentially private mechanism novel mechanism privacypreserving quantum machine learning mechanism tested sensitive dataset contains feature target label breast cancer prediction result obtained underline utility mechanism ,1
ML_556,pid control algorithm used industrial control method owing simplicity ease however tuning pid parameter trivial many method reported literature seek show machine learning approach multivariate regression gradient descent normal equation first order cruise control system used example result show good progress towards automatic pid tuning learned data ,1
ML_557,data high volume velocity variety veracity brings experience curve analytics big data higher education come different source include blog social network student information system learning management system research machinegenerated data data analysed promise better student placement process accurate enrolment forecast early warning system identify assist student atrisk failing dropping big data becoming key creating competitive advantage higher education like organization traditional data processing analysis structured unstructured data rdbms data warehousing longer satisfy big data challenge lack adequate conceptual architecture big data tailored institution higher education led many failure produce meaningful accessible timely information decision making therefore call development conceptual architecture big data higher education present architecture big data analytics higher education ,1
ML_558,speaker recognition technique automatically identifies speaker recording voice speaker recognition technology taking trend due progress artificial intelligence machine learning widely used many domain continuing research field speaker recognition spanned year half century great deal progress made towards improving accuracy system decision successful machine learning algorithm present development automatic speaker recognition system based optimised machine learning algorithm algorithm optimised better improved performance four classifier model namely support vector machine knearest neighbor random forest logistic regression artificial neural network trained compared system resulted artificial neural network obtaining stateoftheart accuracy % outperforming knn svm rf lr classifier ,1
ML_559,network security remains critical issue due ongoing advancement information communication technology ict concomitant rise number security threat intrusion detection system emerged essential countermeasure preserve network security however year challenge finding detection mechanism accurate enough low false alarm rate become increasingly difficult attain high level accuracy conventional anomaly detection system due dynamic nature network traffic pattern recent year machine learning based detection technique emerged viable id solution comparison patternbased detection approach machine learning solution reported high detection accuracy literature ineffective practical situation due unreal nature datasets used evaluation moreover case solution single classifier known outperformed ensemblers proposes flow based intrusion detection method utilizes ensemble classification machine learning technique analyze network flow data performance evaluation ensemble decision tree probabilistic nonprobabilistic classification method conducted ensemble method adaptive boosting bootstrap aggregation random forest majority voting analyzed cidds flow based id evaluation datasets experimental result indicate ensemble decision tree based classification method perform better compared ensemble probabilistic nonprobabilistic based classification method additionally nonprobabilistic based ensemble method take longer train classify instance ,1
ML_560,fault detection power system high reliability subject concern protection engineer year model kv distribution system power world software package various type fault case obtained model stationery wavelet transform swt used decompose signal coefficient extract statistical feature subsequent extraction feature support vector machine svm artificial neural network ann scheme used fault detection classification support vector regression svr scheme used fault location hybrid technique fault diagnostic comprising swtsvm ann svr proposed method showed good accuracy classification minimum error fault estimation proposed method tested machine learning platform weka ,1
ML_561,novel approach predicting voltage collapse point based quadratic line voltage stability index qlvsi auditory machine intelligence technique called ami presented technique applied bus nigerian kvbus power network order validate proposed technique comparison made group method data handling time series gmdhsubtimeseriessub stateoftheart polynomial function fitting neural network based inductive learning selforganization result simulation study show ami technique competitive gmdhsubtimeseriessub technique number experimental simulation run ,1
ML_562,sentiment imperative decide iniduals organization due rapid growth awngi text web sufficiently available sentiment corpus used research developed corpus collecting around one thousand five hundred post online source even infrequent text available web mostly transliterated latin due lack accessibility convenience typing proposed featurelevel sentiment analysis method based machine learning opinionated awngi music sentiment thus preprocessing technique employed clean data convert transliteration native ethiopic script change word base form removing inflectional morpheme improve calculation method feature selection weighting proposed suitable sentiment analysis algorithm feature extraction named chi weight calculation called tf idf increasing proportion weight sentiment word feature word experiment result show among two learning setup accuracy svm found promising ,1
ML_563,espouses quick gain hate speech identification achieved simple hierarchical structure highlevel feature map low level feature eg hate lexical term mapped term frequencyinverse document frequency feature implement approach us supervised machine learning train classifier k human annotated tweet automatically identify hate speech generated presidential election kenya preliminary result indicate accuracy higher baseline data set labeled human annotator ,1
ML_564,world experiencing paradigm shift towards intelligent agent form machine learning modeling given process human vehicle driver agent operate stochastic environment full agent environment complex perceive model explores utilitybased agent could used model human vehicle driver motivation behind established assumption driver agent founded gps data mixture model probabilistic reasoning methodology could effectively model human vehicle driver data collected gps receiver appropriately analysed establish driver behaviour dataset dataset ided three set training test validation set used formulate driver agent agent successive action evaluated set performance metric determine accuracy precision recall level evaluation yielded % successful performance rate level significance fourfold first function system could extended providing advisory service driver realtime second data gathered system could used road safety stakeholder vet driver diagnose cause road accident thirdly resulting knowledgebase could establish standard rationality driving andor formulate rule driverless vehicle control system finally model could used build dataset driver behaviour given vehicle driver type nature operational environment ,1
ML_565,data generated sensor internet thing iot space experience data loss data loss caused many occurrence including network failure faulty sensor duplicate unreliable sensor factor attempt make decision knowing data loss used neural network promising approach taking consideration nature data used data used fast growing labelled lost due afore mentioned possibility hence adopted supervised learning approach work better labelled data first theoretically evaluated convolutional neural network cnn knearest neighbor knn na��ve bayes support vector machine svm logistic regression longshort term memory lstm promising potential classifiersalgorithms waste collection case challenge finding effective waste collection method best performing classification model showed high accuracy recall precision f score working lost data able tell u action take two decision important save cost andor protect environment citizen metropolitan area result indicate data loss threshold taken per sample % data loss result also indicate algor % % % data loss ,1
ML_566,implementation machine learning model lie heart traditional financial institution like bank primarily remained black box technique extreme gradient boosting random forest support vector machine challenging interpret restricts commercial application technique lack transparency often hide potential bias inherited machine learning algorithm ultimately limit ability technique ass iniduals ability pay loan bias lead credit application rejected iniduals offered unfair credit term based credit risk recently attempt predict credit default risk literature however majority study conducted data developed country iniduals banked data complete therefore aim investigate compare statistical classification technique machine learning technique focus interpreting result explaining feature contribute credit approval process may excel developed developing country achieve goal explored three datasets fintech organisation namely home credit xente super lender two datasets uganda nigeria developing country africa one usa developed country north america adopted shapley additive explanation shap interpret model shap identified three datasets external rating total due loan duration increase likelihood inidual defaulting loan additionally also found treebased algorithm particularly extreme gradient boosting algorithm outperforms logistic regression random forest statistical learning technique ,1
ML_567,student dropout among challenge face school developing country particularly africa addressing student dropout problem thorough understanding fundamental causative factor essential several researcher identified proposed cause method strategy help reduce stop student dropout problem however proposed solution show promising result dropout trend continue increase time machine learning hand gained much attention addressing society problem different sector including education attributed fact machine learning model accurately trained provide convenient reliable result compared traditional approach focused developing machine learning model help predict identify student risk dropping school three datasets tanzania kenya uganda used develop model disclose best classifier three commonly used ie multilayer perceptron logistic regression random forest classifier evaluated geometric mean fmeasure examine performance result revealed logistic regression achieved highest performance compared two therefore recommends developed model used relevant authority identifying predicting student risk dropping school make informative decision addressing student dropout problem ,1
ML_568,educational data mining edm become interesting field machine learning ml since enabled searcher mine knowledge educational database improvement student instructor performance challenging prediction identify feature algorithm select give satisfactory result research hybrid algorithm weighted voting classifier wvc conjunction fold cross validation cv five machine learning algorithm support vector machine svm multilayer perceptron mlp logistic regression lr knearest neighbor knn naive bayes nb used evaluated proposed model student grade prediction dataset taken kaggle metric measured included accuracy precision recall fscore area curve auc accuracy % achieved proposed model able identify student fair good excellent therefore recommending model school student performance prediction since devise mechanism alleviate student dropout rate improve performance ,1
ML_569,talent management process identifying vacant position recruiting suitable person developing skill expertise person make person suitable position retaining achieve long term business objective institution research develop machine learning model talent recruitment management human resource department research therefore proposes human resource ensemble neural network model talent recruitment management employee development retention model developed attained predictive accuracy % showed machine learning model used successively talent recruitment human resource department explores literature neural network used give basis ,1
ML_570,community network infrastructure run citizen citizen network often run limited resource compared traditional internet provider network careful traffic classification play important role improving quality deep learning technique shown effective classification especially since classical approach struggle deal encrypted traffic however deep learning model often tend computationally expensive limit suitability lowresource community network explores computational efficiency accuracy long shortterm memory lstm multilayer perceptron mlp deep learning model packetbased classification traffic community network find lstm model attain higher outofsample accuracy traditional support vector machine classifier simpler multilayer perceptron neural network given computational resource constraint improvement accuracy offered lstm tradeoff slower prediction speed weakens relative suitability realtime application however observe reducing size input supplied lstms improve prediction speed whilst maintaining higher accuracy simpler model ,1
ML_571,design biomimicry autonomous underwater robot monitoring harvesting invasive weed lake presented systematic design robot focus integrating gaiiot effective technological tool autonomously monitor harvest invasive weed order replace traditional weed control approach robustness versatility robotic platform structural topology autonomous navigation us convolutional neural network method unsupervised learning technique demonstrated robotic concept design investigate real time sensing mapping visualization invasive weed system based realtime mapping information obtained swarm drone also manage control underwater robot equipped smart networked sensor state art iot technology mechanical dislodging machine guided mapped area accurately controlled guided smart sensor via g ultrareliable lowlatency communication control urllc tactile control system dislodge invasive weed impact organism bioersity lake ,1
ML_572,disinformation fake news ongoing problem society become easily spread social medium cost timeeffective way filter large amount data combination human technical intervention identify technical perspective natural language processing nlp widely used detecting fake news social medium company nlp technique identify fake news warn user fake news may still slip undetected especially problem localised context outside united state america adjust fake news detection system better local context south africa investigate fake news detection south african website curate dataset south african fake news train detection model contrast widely available fake news datasets mostly usa website also explore making datasets erse combining observe difference behaviour writing nation fake news interpretable machine learning ,1
ML_573,monitoring wild animal taken different approach aim provide vital information used animal protection natural habitat recognize animal specie without human tracker requires machine learning model extract specie feature image project proposes method counting animal image specifying specie animal unet variant squeezenet model train unet model image corresponding mask used training data different optimizers applied model inference unet output binary mask one animal detected zero elsewhere squeezenet model trained image corresponding six class bushbuck impala llama warthog waterbuck zebra three variant squeezenet model trained first contains original backbone two original backbone additional fire module one model fire module similar fire module original backbone model extra fire module contains batch normalization layer trained model show unet trained nadam optimizer achieves highest dice coefficient squeezenet extra fire module containing batch norm layer rmsprop optimizer achieves highest training accuracy combined system containing two model take image output image bounding box around animal corresponding animal specie system achieves counting recognition specie image placed input ,1
ML_574,according european environment agency water demand across europe steadily increased past year partly due population growth people moving city town especially densely populated area household reported account % total water europe effective water management practice put place euwide target residential end user limited awareness campaign promoting purchase watersaving device system aim bridge gap consumer appliance accurate ontime monitoring household water consumption inidual appliance level helping user ease enduring watersaving practice system platform incorporates advanced signal processing methodology combined supervised machine learning classifier classify water flow thus identifying residential water appliance high accuracy experimentation confirms model achieve accuracy ~ % classifying four used household water appliance crucial assisting end user reducing household overall water consumption ,1
ML_575,atlas assisted image segmentation quite popular medical imaging last two decade atlas able provide prior information imaged organ shape appearance local texture intensity distribution case segmenting image via pixelwise classification final segmentation result obtained fusion classification outcome local atlas information word atlas guide classifier towards shape local structure normally situated given location proposes demonstrate advantage multiatlas bring segmentation process tissue infant brain based multispectral mri record three supervised machine learning method deployed segment brain tissue without atlas difference evaluated statistical accuracy indicator atlas improved overall segmentation accuracy % depending deployed classifier method ,1
ML_576,one security problem become hardest serious threat called distributed denial ddos attack specifically synchronize syn flood attack research focused performance evaluation classification machine learning ml algorithm syn flood attack detection classification model trained tested packet captured dataset gathered ethio telecom network generating capturing packet hping wireshark tool respectively dataset preprocessed evaluated four classification ml algorithm three training approach implementation performed waka waikato environment knowledge analysis data mining tool experimental result show j algorithm performs % accuracy adaboost na��ve bayes ann algorithm % % % accuracy respectively accordingly based performance model j algorithm recommended syn attack detect,1
ML_577,proactive monitoring one health could avoid serious disease well better maintain iniduals wellbeing today internet thing iot world numerous wearable technological device monitormeasure different health attribute increasing number attribute wearable becomes unclear iniduals one aim provide novel recommendation engine personalized advised wearable iot solution given inidual way engine work first identifying disease person risk given hisher attribute medical history done via analyzing iniduals unstructured medical history text mining adding hisher structured demographic attribute feeding data machine learning classification model predicts eventual disease map disease attribute need measured order monitor lastly mathematical optimization model developed recommend optimal wearable device iot solution inidual thus solution enables proactive health monitoring thus provide significant human benefit ,1
ML_578,principal component analysis pca simple loss le fast efficient method dimensionality reduction however dozen nonlinear method isomap locallylinear embedding proposed tackle problem related rampant complex nonlinear data particular field machine learning scrutinize compare pca different nonlinear method face recognition first step method contourlet transform extracting transformed coefficient element dataset seize advantage dimensionality reduction nonlinear method addition pca method �� drawn outcome carried experiment realworld face dataset novel artificial one delineate linear nonlinear algorithm show almost identical performance difference classification rate trivial infer algorithm dominating nonlinearity measure used determine amount nonlinearity data collection dimensionality reduced subspace criterion help deduce effectiveness nonlinear method logical man,1
ML_579,persian handwritten digit reorganization zoning feature projection histogram extracting feature vector dimension presented classification stage support vector machine svm three linear kernel polynomial kernel gaussian kernel used classifier tested algorithm dataset contained sample persian handwritten digit performance analysis sample learning stage another sample testing stage result got every three kernel support vector machine achieved maximum accuracy gaussian kernel gamma equal preprocessing stage image binarization used image dataset normalized center size �� recognition rate method test dataset % sample dataset % ear,1
ML_580,abundance healthcare data collection populationwide information electronical medical record would promising implementation product artificial intelligence machine learning enables development advanced software application clinical practice especially large vendor year long experience developing medical software application nevertheless introduction artificial intelligence machine learning product development process make daily life software engineer challenging brings factor consider development product must meet high standard clinical world describes experience software development clinical decision support system siemens healthineers intention project build software platform handling patient longitudinal data provide supportive functionality clinician application machine learning artificial intelligence method deliver relevant information ,1
ML_581,machine learning clinical practice pose hard requirement explainability reliability replicability robustness system therefore developing reliable software monitoring critically ill patient requires close collaboration physician software engineer however two different discipline need find research perspective order contribute medical software engineering domain address problem establish collaboration software engineering medicine meet design robust machine learning system used patient care describe designed software system monitoring patient carotid endarterectomy particular focusing process knowledge building research team result show consider setting collaboration develops time kind system constructed based conclude challenge find good research team different competence committed common goal ,1
ML_582,collaborative ai system aim working together human shared space achieve common goal setting imposes potentially hazardous circumstance due contact could harm human being thus building system strong assurance compliance requirement domain specific standard regulation greatest importance challenge associated achievement goal become even severe system rely machine learning component rather topdown rulebased ai introduce risk modeling approach tailored collaborative ai system risk model includes goal risk event domain specific indicator potentially expose human hazard risk model leveraged drive assurance method feed turn risk model insight extracted runtime evidence envisioned approach described mean running example domain industry robotic arm endowed visual perception component implemented machine learning collaborates human operator productionrelevant ,1
ML_583,artificial intelligence aimachine learning mlbased system widely soughtafter commercial solution automate augment core business service intelligent system improve quality service offered support scalability automation describe experience engineering exploratory system assessing quality essay supplied customer specialized recruitment support problem domain challenging openended customersupplied source text considerable scope ambiguity error making model analysis hard build also need incorporate specialized business domain knowledge intelligent processing system address challenge experimented exploited number cloudbased machine learning model composed applicationspecific processing pipeline design allows modification underlying algorithm data improved technique become available describe design challenge faced namely keeping check quality control model testing software deploying computationally expensive ml model cloud ,1
ML_584,increasing availability machine learning ml framework tool well promise improve solution datadriven decision problem resulted popularity ml technique software system however endtoend development mlenabled system well seamless deployment operation remain challenge one reason development deployment mlenabled system involves three distinct workflow perspective role include data science software engineering operation three distinct perspective misaligned due incorrect assumption cause ml mismatch result failed system conducted interview survey collected validated common type mismatch occur endtoend development mlenabled system analysis show role prioritizes importance relevant mismatch varies potentially contributing mismatched assumption addition mismatch category identified specified machine readable descriptor contributing improved mlenabled system development finding implication improving endtoend mlenabled system development ,1
ML_585,following continuous software engineering practice increasing interest rapid deployment machine learning ml feature called mlops importance mlops context data scientist daily activity based survey collected response professional different country ml domain indicating working last three month based result % respondent say model infrastructure majority revolves around relational time series data largest category problem solved predictive analysis time series data computer vision biggest perceived problem revolve around data although awareness problem related deploying model production related procedure hypothesise believe organisation represented survey ided three category figuring best data ii focusing building first model getting production iii managing several model version training datasets well retraining frequent deployment retrained model result majority respondent category ii focusing data model however benefit mlops emerge category iii need frequent retraining redeployment hence setting mlops pipeline natural step take organization take step ml proofofconcept ml part nominal activity ,1
ML_586,log common way record detailed runtime information software modern software system evolve scale complexity log become indispensable understanding internal state system time however manually inspecting log become impractical recent time emphasis statistical machine learning ml based method analyzing log result shown promise literature focus algorithm stateoftheart sota largely ignoring practical aspect demonstrate endtoend log classification pipeline linnaeus besides showing traditional ml flow also demonstrate solution adaptability reuse integration towards large scale software development process cope lack labelled data hope linnaeus serve blueprint inspire integration various ml based solution large scale industrial setting ,1
ML_587,artificial intelligence ai machine learning ml pervasive current computer science landscape yet still exists lack software engineering experience best practice field one best practice static code analysis used find code smell ie potential defect source code refactoring opportunity violation common coding standard research set discover prevalent code smell ml project gathered dataset opensource ml project installed dependency ran pylint resulted top detected code smell per category manual analysis smell mainly showed code duplication widespread pep convention identifier naming style may applicable ml code due resemblance mathematical notation interestingly however found several major obstruction maintainability reproducibility ml project primarily related dependency management python project also found pylint reliably check correct usage imported dependency including prominent ml library pytorch ,1
ML_588,emerging age connected digital world mean ton data distributed various organization database since data confidential nature openly shared seek artificial intelligence ai machine learning ml solution instead need integration mechanism analogous integration pattern information system create multiorganization aiml system two realworld case first integration two organization detail second address scaling aiml multiorganization context setup assume continuous deployment often referred devops software development also ml component deployed similar fashion term mlops used towards end list observation draw final conclusion finally propose direction future ,1
ML_589,following recent surge adoption machine learning ml negative impact improper ml user society also widely recognised address issue policy maker stakeholder european commission nist proposed highlevel guideline aiming promote trustworthy ml ie lawful ethical robust however guideline specify action taken involved building ml system argue guideline related development trustworthy ml translated operational practice become part ml development life cycle towards goal ran multivocal literature mined operational practice white grey literature moreover launched global survey measure practice adoption effect practice total identified practice used complement existing catalogue ml engineering practice initial analysis survey result reveals far practice adoption trustworthy ml relatively low particular practice related assuring security ml component low adoption practice enjoy slightly larger adoption providing explanation user extended practice catalogue used ml development team bridge gap highlevel guideline actual development trustworthy ml system contribution ,1
ML_590,increasingly common data application programming interface apis together progress data science artificial intelligence ai especially machine learning ml create opportunity build novel service combining data different source experience describe firsthand experience data domain marine traffic finland sweden identified technological opportunity novel service enumerate five challenge encountered application data relevant data historical data licensing runtime quality api evolution challenge affect business model technical implementation discus challenge could alleviated better governance practice provided apis data ,1
ML_591,increasing usage machine learning ml coupled software architectural challenge modern era resulted two broad research area software architecture mlbased system focus developing architectural technique better developing mlbased software system ii ml software architecture focus developing ml technique better architect traditional software system focus former side spectrum goal highlight different architecting practice exist current scenario architecting mlbased software system identify four key area software architecture need attention ml software practitioner better define standard set practice architecting mlbased software system base area light experience architecting mlbased software system solving queuing challenge one largest museum italy ,1
ML_592,reliability crucial component machinelearningasaservice platform critical application depend thus mechanism employed assure integrity computation performed platform pivotal robust functioning moreover privacy protection performance guarantee scale major challenge surrounding platform mean straightforward overcome time proposed novel distributed approach us specialized composable proof system core respond challenge high level adopt ideandconquer approach build efficient proof system machinelearningbased service order ensure correctness result precisely mathematical formulation machine learning ided multiple part handled different specialized proof system proof system combined commitandprove methodology guarantee correctness whole privacy safeguard built design approach also assures neither data model parameter constitute intellectual property provider exposed process showcased usability approach machine learning provider offer classification service linear support vector machine svm model complexity analysis indicates system could used practical setting ,1
ML_593,child autism spectrum disorder asd find difficult detect human emotion social interaction speech emotion recognition system developed aim help child better identify emotion communication partner system developed machine learning deep learning technique ensemble learning multiple machine learning algorithm joined provide final prediction recorded input utterance ensemble model includes support vector machine svm multilayer perceptron mlp recurrent neural network rnn three model trained ryerson audiovisual database emotional speech song ravdess toronto emotional speech set te crowdsourced emotional multimodal actor dataset cremad fourth dataset used created adding background noise clean speech file datasets previously mentioned describes audio processing sample technique used include background noise feature extraction coefficient considered development training model present performance evaluation inidual model datasets inclusion background noise combination sample three datasets evaluation made select optimal hyperparameters configuration model evaluate performance ensemble learning approach majority voting overall performance ensemble learning reached peak accuracy % reaching higher performance emotion classification accuracy mlp model reached % ,1
ML_594,highlight trend field predictive maintenance machine learning continuous development fourth industrial revolution iot technology artificial intelligence evolving result industry technology optimize production scientific research conducted conclusion drawn trend predictive maintenance application machine learning bridging artificial intelligence iot trend related type industry predictive maintenance applied model artificial intelligence implemented mainly machine learning type sensor applied iot application six sector presented production sector dominant accounted % total publication term artificial intelligence model prevalent among ten artificial neural network support vector machine random forest % % % respectively finally category sensor emerged widely used sensor temperature vibration percentage % % correspondingly ,1
ML_595,deal identification machine smart city environment concept machine biometrics proposed first time way authenticate machine identity interacting human everyday life definition imposed modern year autonomous vehicle social robot etc considered active member contemporary society context case car identification engine behavioral biometrics examined sound feature extracted discrimination capability tested combination different machine learning classifier towards identifying car manufacturer experimental result revealed ability proposed biometrics identify car high accuracy % case multilayer perceptron mlp neural network model ,1
ML_596,introduces done evaluate machine learning regression technique predict link quality communication done iot node proposed methodology able predict link quality typical cloud communication protocol cellular wifi sigfox lorawan based node location discover best model achieve set machine learning technique implemented including linear regression decision tree random forest neural network result compared result showed decision tree achieve best efficiency margin error dbm crossvalidation includes detailed description methodology implementation experimental result ,1
ML_597,advancement recent iot device led catastrophic attack device breaching user privacy exhausting resource organization cost user organization time money one malware extremely harmful mirai created worldwide recognition impacting digital world several way mitigate mirai machine learningbased approach proved accurate reliable averting malware novel approach detecting mirai machine learning algorithm proposed implemented matlab b evaluate proposed approach mirai benign datasets considered training performed dataset artificial neural network provides consistent result accuracy precision recall f score found considered accurate reliable best performance achieved accuracy % false negative rate efficient detecting mirai similar anomalybased malware detection term metric ,1
ML_598,essential part internet thing iot internet medical thing iomt play essential role healthcare industry timely prediction diagnosis disease avoid chronic illness massive information processed healthcare industry factor security processing power accuracy information great importance predicting diagnosis numerous disease overcome challenge machine learning algorithm used literature increase accuracy patient data hand research patient data collected several iomt device ambulance medical imaging wearable doctor report patient history lab data collected several source used machine learning algorithm categorize cluster forecast treatment diagnosis provided result demonstrate random forest algorithm give % accuracy hoeffding tree algorithm give % accuracy patient heart data compared suggested algorithm literature several clustering algorithm applied em kmeans density filtered farthest clustering kmeans filtering density algorithm give reliable clustering result others ,1
ML_599,covid affected many area life worldwide economy education security social life health survey research paper machine learning internet thing iot medical imaging software application prevent diagnose reduce manage covid artificial intelligence important research area solve problem emergent domain homeland security biomedical engineering artificial intelligence subdomains image processing data mining network graph theory natural language processing computer vision frequently applied covid data iot sensor collect data patient elderly people home hospital room elsewhere early prediction monitoring collected data used machine learning algorithm decision tree na��ve bayes classifier neural network kmeans algorithm classification clustering computed tomography also commonly used determine presence covid infection damage patient lung image segmentation object detection object tracking used extract feature medical image experimental result surveyed paper demonstrate approach promising predicting diagnosing managingid ,1
ML_600,introduces done evaluate machine learning regression technique predict weather condition agricultural field smart irrigation system proposed methodology able predict temperature precipitation wind speed evapotranspiration based field location day discover best model achieve set machine learning technique implemented including linear regression decision tree random forest neural network result compared result shown random forest decision tree achieve best efficiency crossvalidation includes detailed description methodology implementation experimental result ,1
ML_601,federated machine learning defines machine learning framework allows collective model constructed data distributed across repository owned different organization device guide provides blueprint data usage model building across organization device meeting applicable privacy security regulatory requirement defines architectural framework application guideline federated machine learning including description definition federated machine learning categorizes federated machine learning application scenario category applies performance evaluation federated machine learning associated regulatory requirement ,1
ML_602,federated machine learning defines machine learning framework allows collective model constructed data distributed across repository owned different organization device guide provides blueprint data usage model building across organization device meeting applicable privacy security regulatory requirement defines architectural framework application guideline federated machine learning including description definition federated machine learning categorizes federated machine learning application scenario category applies performance evaluation federated machine learning associated regulatory requirement ,1
ML_603,framework architecture machine learning model trained encrypted data aggregated multiple source processed trusted third party defined standard functional component workflow security requirement technical requirement protocol specified standard ,1
ML_604,course discus computational cyberinfrastructure necessary enabling machine learning big data explores big data lake data warehouse discussing two alternative enterprise repository relative strength drawback computational system facilitate machine learning enterprise reviewed well concept technique necessary deploying scalable machine learning business process ,1
ML_605,course focus understanding software versus algorithm versus model review machine learning model training integration lifecycle also review provenance tractability machine learning model best practice machine learning model integration business process ,1
ML_606,course address application data mining diagnostic analytics measure business performance build upon business performance measurement achieve advanced insight predictive perspective analytics examines common technique used measure efficacy machine learning integration business process review realworld business case leveraging machine learning advanced analytics process automation reducing business operation cost ,1
ML_607,course focus comprehending erse enterprise data source machine learning discus managing multifacet enterprise data enable machine learning review exploratory analysis multifacet enterprise data training validating testing machine learning model ,1
ML_608,course focus foundation big data machine learning artificial intelligence computational intelligence look enhancing business intelligence machine learning examines fundamental type machine learning drive business insight review advanced computational intelligence business process ,1
ML_609,motivation method visual object recognition focus machinelearning machinelearning algorithm consider deeplearning approach visual object detection recognition categorization ,1
ML_610,examine visual object categorization standard machine learning algorithm deep learning approach consider motivation visual object detection recognition intelligent vehicle method object visual detection find important object image ,1
ML_611,tutorial learn create virtual machine window r well create vm vmdepot run application next create disk mount disk window linux vms followed creating azure storage account azure storage explorer manage storage account ,1
ML_612,tutorial learn access aws management console vm instance linux also create amazon linux instance amazon machine image ami next access amazon machine instance ssh client maclinux window also create amazon bucket access internet create elastic block storage volume eb amazon elastic load balancer elb amazon ec spot instance request ,1
ML_613,tutorial part series elearning course designed help prepare examination become certified software development professional csdp learn specific software engineering topic course series address one fifteen knowledge area comprise software engineering body knowledge swebok upon certification exam based course module list textbook course relevant reference material assist preparing certification exam mathematical fundamental software engineering provide mathematical underpinnings construction software product desired attribute provide mathematical foundation model facilitate reasoning product interrelation well form basis predictable design process course intended ass understanding mathematical foundation inline quiz feedback specific topic addressed course basic propositional predicate logic mathematical set function relation technique making valid argument way counting discrete event evaluate efficiency graphical representation abstract problem solving discrete probability formal grammar finite state machine regular expression numerical precision accuracy number theory algebraic structure boolean algebra ,1
ML_614,course examines information theory effort develop informationtheoretic criterion utilized adaptive filtering neurocomputing aim research develop signal processing technique going beyond basic assumption linearity gaussianity stationarity capturing higher order statistic data information theory solve variety problem biomedical signal processing communication machine learning ,1
ML_615,sift analyze massive increasingly available data protein researcher need computing method author machinelearning method novel threestep strategy protein structure prediction ,1
ML_616,shop scheduling problem genetic algorithm data mining developed genetic algorithm generates learning population optimal solution used c decision tree mind population decision rule finding machine affectation order operation finally induced ,1
ML_617,investigates application recently introduced learning technique referred relevance vector machine rvm construct blockadaptive kernelbased nonlinear multiuser detector mud directsequence codeision multipleaccess dscdma signal transmitted multipath channel demonstrated rvm mud capable closely matching performance optimal bayesian oneshot detector aid significantly sparse kernel representation required stateoftheart support vector machine svm technique ,1
ML_618,develop learning system schedule workshop production well possible elaboration tool joined problem posed community working knowledge data discovery kdd initially introduce need making learning system schedule workshop describe specificity system develop phase process kdd underline contribution first stage data warehousing filtering method criterion data selection put perspective among existing criterion elaborate filtering algorithm prepares data step data mining us software c extract knowledge form decision tree supervised machine learning applied case flow shop machine knowledge concern choice best heuristic workshop ,1
ML_619,recent work shown simulation optimization manufacturing system efficiently addressed evolutionary algorithm drawback algorithm notoriously slow bring understanding behavior system propose add algorithm machine learning module highlight several critical parameter guide research solution benefit approach demonstrated example optimizing assembly kanban system ,1
ML_620,present data mining dm solution based evolutionary method framework emphasizes suitability genetic algorithm genetic programming data mining context first describe concept closed link machine learning ml statistic two data mining task considered classification association analysis classification intensively studied ml association analysis typically related dm may achieved efficiently geneticbased method clear distinction two data mining functionality result syntactically comparable pattern established geneticbased technique used dm context presented show iniduals genetic operator fitness function mapped order address specific database issue suitable characteristic database analysis pointed research challenge presented ,1
ML_621,one task machine learning build device predicts next input symbol sequence take one input symbol sequence studied approach suggest deterministic finite automaton dfa good building block device together genetic algorithm gas let automaton evolve predict next input symbol sequence moreover combine highly fit automaton network would compensate others weakness predict better single automaton studied simplest approach combine automaton building tree automaton specialpurpose automaton may called switchboard switchboard automaton located internal node tree take input symbol input sequence automaton predict subtree make correct prediction next input symbol gas play crucial role searching switchboard automaton studied various way growing tree automaton tested sample input sequence mainly note pitch note duration updown note bach fugue ix test result show dfas together gas seem effective type pattern learning ,1
ML_622,speculative threadlevel parallelization code fully compileranalyzed aggressively executed parallel hardware detects crossthread dependence violation squash offending thread resume execution unfortunately frequent squashing cripple performance proposes framework hardware mechanism eliminate squash due data dependence multiprocessor framework work learning predicting violation applying delayeddisambiguation value prediction stall release framework suited directorybased multiprocessor track memory access system level coarse granularity memory line simulation processor machine show framework effective adding framework speculative ccnuma byte memory line speedup application average time moreover resulting system even % faster machine track memory access fine granularity wordsa sophisticated system compatible mainstream cache coherence protocol ,1
ML_623,major evolutionary step computer technology user come rely readymade application software rather writing program computer user longer program follow art programming taught computing professional ? argue case programming component general education direct utilitarian benefit order gain personal experience mean take specify process evolve time analogy mathematics education show school teach concept proof although daily life people mathematical formula without knowledge proof programming practiced educational exercise free utilitarian constraint best learned toy environment designed illustrate selected concept simplest possible setting example programming system kara based concept finite state machine ,1
ML_624,data cleaning vital process ensures quality data stored realworld database data cleaning problem frequently encountered many research area knowledge discovery database data warehousing system integration eservices process identifying record pair represent entity duplicate record commonly known record linkage one essential element data cleaning address record linkage problem adopting machine learning approach three model proposed analyzed empirically since existing model including proposed proved superior developed interactive record linkage toolbox named tailor backwards acronym record linkage toolbox user tailor build record linkage model tuning system parameter plugging inhousedeveloped publicdomain tool proposed toolbox serf framework record linkage process designed extensible way interface existing future record linkage model conducted extensive experimental evaluate proposed model synthetic also real data result show proposed machinelearning record linkage model outperform existing one accuracy performance ,1
ML_625,robot soccer challenging platform multiagent research involving topic realtime image processing control robot path planning obstacle avoidance machine learning robot soccer game present uncertain dynamic environment cooperating agent dynamic role switching formation control crucial successful game fuzzy logic based strategy described employ arbiter assigns robot shoot pas ball ,1
ML_626,parallel genetic programming approach induce decision tree large data set presented population tree evolved employing genetic operator every inidual evaluated fitness function based jmeasure method able deal large data set since us parallel implementation genetic programming grid model experiment data set uci machine learning repository show better result respect c furthermore performance result show nearly linear speedup ,1
ML_627,process aging cause significant alteration facial appearance iniduals compared source variation face image appearance variation due aging display unique characteristic change facial appearance due aging even affect discriminatory facial feature resulting deterioration ability human machine identify aged iniduals describe effect aging facial appearance explained learned age transformation experimental result show reasonably accurate estimate age made unseen image also show improve result taking account fact different iniduals age different way considering effect lifestyle proposed framework used simulating aging effect face image order predict inidual might look like future heshe used look past methodology presented also used designing face recognition system robust aging variation context perceived age subject training test image normalized training classification procedure aging variation eliminated experimental result demonstrate age normalization used performance face recognition system improved ,1
ML_628,cray td te noncachecoherent ncc computer numa structure shown exhibit stable scalable performance variety application program considerable evidence suggests stable scalable many sharedmemory multiprocessor however principal drawback machine lack programmability caused absence global cache coherence necessary provide convenient shared view memory hardware force programmer keep careful track piece data stored complication unnecessary pure sharedmemory view presented believe remedy problem advanced compiler technology experience compiler framework automatic parallelization communication generation potential reduce timeconsuming handtuning would otherwise necessary achieve good performance type machine experiment learned compiler performs well variety application td te found sophisticated technique could improve performance even fully implemented compiler ,1
ML_629,discrimination algorithm based analysis ventricular electrogram egm onset proposed order discriminate supraventricular ventricular tachycardia svts vt implantable cardioverter defibrillator icds due absence detailed statistical model ventricular activation algorithm based support vector method svm learning machine plus bootstrap resampling avoid overfitting svm classifier trained available arrhythmia episode viewed containing statistical model differential diagnosis however blackbox model character learning machine present problem clinical environment solution extraction statistical information enclosed blackbox model svm could appropriate given support vector represent critical sample classification article propose two svmoriented analysis building two differential diagnosis algorithm based ventricular egm onset criterion ,1
ML_630,recent year several proposal realization model inspired biological solution pattern recognition propose approach based hierarchical modular structure realize system capable learn example recognize object digital image adopted technique based multiresolution image analysis neural network performance two different data set experimental timing single instruction multiple data simd machine also reported ,1
ML_631,support vector machine svm learns decision surface two distinct class input point many application input point may fully assigned one two class apply fuzzy membership input point reformulate svms different input point make different contribution learning decision surface call proposed method fuzzy svms fsvms ,1
ML_632,twostep method speedup object detection system computer vision support vector machine svms classifier first step perform feature reduction choosing relevant image feature according measure derived statistical learning theory second step build hierarchy classifier bottom level simple fast classifier analyzes whole image reject large part background top level slower accurate classifier performs final detection experiment face detection system show combining feature reduction hierarchical classification lead speedup factor similar classification performance ,1
ML_633,accurate automatic image orientation detection great importance image library automatic image orientation detection algorithm adopting illuminance structural chrominance color lowlevel content feature statistical learning support vector machine svms used approach classifier different source extracted image feature well binary classification nature svm require system able integrate output multiple classifier static combiner averaging trainable combiner also based svms proposed evaluated addition two rejection option regular reinforced ambiguity rejection employed improve orientation detection accuracy sieving image low confidence value classification number experiment database image performed validate approach ,1
ML_634,scheme learning similarity measure proposed contentbased image retrieval cbir learns boundary separate image database two part image positive side boundary ranked euclidean distance query scheme called restricted similarity measure rsm take consideration perceptual similarity image also significantly improves retrieval performance based euclidean distance measure two technique support vector machine adaboost utilized learn boundary compared respect performance boundary learning positive negative example used learn boundary provided relevance feedback rsm metric evaluated large database natural image accurate ground truth experimental result demonstrate usefulness effectiveness proposed similarity measure image retrieval ,1
ML_635,componentbased trainable system detecting frontal nearfrontal view face still gray image system consists twolevel hierarchy support vector machine svm classifier first level component classifier independently detect component face second level single classifier check geometrical configuration detected component image match geometrical model face propose method automatically learning component head model approach advantage manual interaction required choosing extracting component experiment show componentbased system significantly robust rotation depth comparable system trained whole face pattern ,1
ML_636,describes machine learning approach visual object detection capable processing image extremely rapidly achieving high detection rate distinguished three key contribution first introduction image representation called integral image allows feature used detector computed quickly second learning algorithm based adaboost selects small number critical visual feature larger set yield extremely efficient classifier third contribution method combining increasingly complex classifier cascade allows background region image quickly discarded spending computation promising objectlike region cascade viewed object specific focusofattention mechanism unlike previous approach provides statistical guarantee discarded region unlikely contain object interest domain face detection system yield detection rate comparable best previous system used realtime application detector run frame per second without resorting image differencing skin color detection ,1
ML_637,bayesian approach supervised learning prior classifier parameter however prior aim achieving sparse classifier irrelevantredundant parameter automatically set zero two wellknown way obtaining sparse classifier zeromean laplacian prior parameter support vector machine svm whether one us laplacian prior svm one still need specifyestimate parameter control degree sparseness resulting classifier propose bayesian approach learning sparse classifier involve parameter controlling degree sparseness achieved hierarchicalbayes interpretation laplacian prior followed adoption jeffreys noninformative hyperprior implementation carried em algorithm experimental evaluation proposed method show performs competitively often better best classification technique available ,1
ML_638,simple art neural network nn model artist show simple exposure music unsupervised learning able simulate high level perceptual human cognitive ability amongst thing able predict high degree accuracy good short musical sequence sound human ear artist exposed kind music listener model able recover rule music aesthetic according particular musical environment totally control many application distribution music world wide web straightforward application build accurate profile user musical preference based musical content avoid usual drawback current search engine musical advisor base advice rigid musical style classification general impersonal application range assisted composition interactive manmachine duet improvisation creation online alternative version song remix ,1
ML_639,present design philosophy initial design decision herald highly scalable global event notification system designed built microsoft research herald distributed system designed transparently scale respect including number subscriber publisher number event subscription point event delivery rate event delivery occur single machine local network intranet throughout internet herald try take account lesson learned success internet web notably herald designed like internet operate correctly presence numerous broken disconnected component herald constructed set protocol governing federation machine cooperating mutually suspicious domain trust like web herald try avoid extent possible maintenance globally consistent state make failure part clientvisible interface ,1
ML_640,combining computing physiological sensing technology transform humanmachine interaction usher wide range application electrophysiologically interactive computer system epic combine physiological sensing technology interactive computer application system support erse range monitoring training discipline epic provide interesting usability metric form backbone braincomputer interface prosthetics handsfree control technology identified two basic epic system monitoring epic quantify measure electrophysiological signal interest scale training epic feed back physiological information subject real time enable operant conditioning instrumental learning control occur process commonly known biofeedback ,1
ML_641,support vector machine svms become popular tool machine learning large amount high dimensional data approach incremental learning support vector machine presented improves existing approach syed et al insight interpretability support vector also given ,1
ML_642,learning bayesian belief network bbn corpus support vector machine svm applied automatic acquisition verb subcategorization frame modern greek incorporating minimal linguistic resource ie basic morphological tagging phrase chunking demonstrate verb subcategorization great significance developing robust natural language human computer interaction system could achieved large corpus without generalpurpose syntactic parser addition apart bbn svm previously used experimented three wellknown machine learning method feedforward backpropagation neural network learning vector quantization decision table also applied verb subcategorization frame defection first time argue bbn svm well suited learning identify verb subcategorization frame empirical result support claim performance methodically evaluated two different corpus type one balanced one domainspecific order determine unbiased behaviour trained model limited training data proved endow satisfactory result able achieve precision exceeding % identification subcategorization frame known beforehand ,1
ML_643,svms support vector machine suffer problem large memory requirement cpu time trained batch mode large data set overcome limitation time make svms suitable learning data stream constructing incremental learning algorithm first introduce compare different incremental learning technique show capable producing performance result similar batch algorithm case superior condensation property consider problem training svms stream data objective maintain updated representation recent batch data apply incremental scheme problem show accuracy comparable batch algorithm ,1
ML_644,many realworld problem deal ordering object instead classifying object although majority research machine learning data mining focused latter modeling ordering problem generalize notion information table ordered information table adding order relation attribute value problem mining ordering rule formulated finding association ordering attribute value overall ordering object ordering rule may state example value object x attribute ordered ahead value another object attribute x ordered ahead mining ordering rule first transform ordered information table binary information apply standard machine learning data mining algorithm illustration analyze detail macleans university ranking ,1
ML_645,previous study propose associative classification high classification accuracy strong flexibility handling unstructured data however still suffers huge set mined rule sometimes biased classification overfitting since classification based single highconfidence rule author propose associative classification method cmar ie classification based multiple association rule method extends efficient frequent pattern mining method fpgrowth construct class distributionassociated fptree mine large database efficiently moreover applies crtree structure store retrieve mined association rule efficiently prune rule effectively based confidence correlation database coverage classification performed based weighted spl chisup analysis multiple strong association rule extensive experiment database uci machine learning database repository show cmar consistent highly effective classification various kind database better average classification accuracy comparison cba c moreover performance show method highly efficient scalable comparison reported associative classification method ,1
ML_646,rule commonly used classification modular intelligible easy learn existing classification rule learning assumes goal produce categorical classification maximize classification accuracy recent machine learning pointed limitation classification accuracy class distribution skewed error cost unequal accuracymaximizing rule set perform poorly flexible rule set produce instance score indicating likelihood instance belongs given class ability apply rule set effectively distribution skewed error cost unequal empirically investigates different strategy evaluating rule set goal maximize scoring roc performance ,1
ML_647,demonstrates artificial intelligence technique based learning applied control complex dynamic system development adaptive rulebased automatic controller first considered heuristic condition action control rule applied human derived observation inidual skill controller tested compared rulebased controller heuristic rule derived considering system dynamic equation data gathered experimental trial two controller physical system postprocessed induction rule generator see form automatically generated rule would take called passive learning finally artificial neuralnet controller constructed trained operate machinelearned controller domain comparative controller study simulation showed neuralnet controller adapted changing system parameter better controller & ltetx & gtetx ,1
ML_648,creating conversational interface child challenging several respect include acoustic modeling automatic speech recognition asr language dialog modeling multimodalmultimedia interface design first issue asr childrens speech introduced analysis developmental change spectral temporal characteristic speech signal data obtained child age five year acoustic modeling adaptation vocal tract normalization algorithm yielded stateoftheart asr performance childrens speech described second experiment designed better understand child interact machine spoken language described realistic conversational multimedia interaction data obtained child played voiceactivated computer game wizard oz woz scenario result data developing novel language dialog model well unified maximum likelihood framework acoustic decoding asr semantic classification spoken language understanding described leveraging lesson learned woz concurrent experience evaluation multimedia personal agent prototype child designed detail architecture application detail described informal evaluation child found positive especially animated agent speech interface ,1
ML_649,discus development prototype resource optimizing access delimited road laboratory energy conversion electric machine power system signal processing course road laboratory remote experimentation facility combine hardware software system provide client student user unsupervised roundtheclock access energy conversion laboratory host computer network full development version software interface offer engineering program option setting laboratory local host enabling access remote host might equipped hardware available local laboratory educational tool offer worldwide access energy conversion lab facility provides infrastructure carrying true collaborative learning serve ideal facility performing machineryrelated experiment distance learning program ,1
ML_650,multifunction microprocessorbased protection relay intelligent electronic device ied created opportunity measurement power system signal diagnosis quantity complexity information enhanced extent well beyond required immediate operational issue significant amount data continually available serious operational incident fault may become excessive impossible substation operator handle technique used extract concise information data received microprocessorbased relay described data analysis technique based rough set theory already used many area artificial intelligence including machine learning knowledgebased system kv distribution network modeled different type fault scenario emtdc resulting event database uploaded rough set data analysis module rsdam eliminates superfluous data whilst keeping essential information ,1
ML_651,safetycritical system require assessment activity verify able perform function specified environment activity benefit evaluation method consider system whole simple sum part indeed analysis accident involving system shown rarely due simple failure one component accident outcome composite causal scenario human software hardware failure combine complex pattern unfortunately dependability analysis evaluation safety critical system usually based technique method consider human computer separately whose result hardly integrated analogy process softwarereliability growth due testing related fault removal improvement manmachine interface due preliminary operative feedback improvement operator performance due learning activity suggest common evaluation approach first one process currently modeled mathematical method extends method reliabilitygrowth process system component operator manmachine interface feasibility approach analyzes result experiment reliability system evaluated trend analysis reliabilitygrowth model evaluation concern graphic manmachine interface operator could easily extended software control system experimental result show trend analysis reliabilitygrowth model could complementary qualitative evaluation performed cognitive science approach could offer quantitative support especially information based analysis average value case could assist several decision operator training especially interface design comparing effect different possible interface operator behavior moreover support share tool related knowhow field human software dependability ,1
ML_652,technique described us model agricultural crop growth microwave interaction earth surface together clustering machinelearning method provide classification remotelysensed agricultural scene croptype demonstrated overall accuracy % obtained classification five different crop data obtained airborne radar scatterometer agriscatt campaign technique easily extendable nonmicrowave data could also used application landuse seaice monitoring & ltetx & gtetx ,1
ML_653,support vector machine svm important learning method statistical learning theory also powerful tool pattern recognition problem study speaker identification verification problem support vector machine present svm training method largescale sample according speech signal textindependent speaker recognition system based svm implemented result show good performance ,1
ML_654,focus problem optimally scheduling closed reentrant system one type part two center consisting one machine algorithm based reinforcement learning proposed result experiment indicate reinforcement learning outperform familiar heuristic method closed workload balancing policy ,1
ML_655,human capability learn birth analogy seems machine let brain mental development system learn task without need programming discus automated mental development multi agent environment mage including framework model future goal agent autonomously learn like human various knowledge memorised relevant form autonomously ,1
ML_656,data acquisition system type optical disdrometer presented device must measure size velocity raindrop small mm diameter real time presence high noise variable baseline algorithm design challenge combining standard signal processing technique machine learning method case neural network essential obtaining good performance ,1
ML_657,optimal bayesian linear classifier studied literature many decade demonstrate known result consider scenario quadratic polynomial coincident root indeed complete analysis case optimal classifier two normally distributed class pairwise linear focus special case normal distribution nonequal covariance matrix determine condition mean vector covariance matrix satisfy order obtain optimal pairwise linear classifier opposed state art case discussed linear classifier given pair straight line particular case general equation second degree also provide empirical result synthetic data minskys paradox case demonstrated linear classifier achieves good performance finally tested approach real life data obtained uci machine learning repository empirical result obtained show superiority scheme traditional fisher discriminant classifier ,1
ML_658,clustering important topic pattern recognition since structure data dictate grouping unsupervised learning information theory obvious criterion establish clustering rule describes novel valley seeking clustering algorithm information theoretic measure estimate cost partitioning data set information theoretic criterion developed evolved renyi entropy estimator renyi proposed recently successfully applied machine learning application jc principe et al improved version kchange algorithm used optimization stepwise nature cost function existence local minimum even applied nonlinearly separable data algorithm performs well able find nonlinear boundary cluster algorithm also applied segmentation magnetic resonance imaging data mri promising result ,1
ML_659,investigates reinforcement learning electrical power system oscillation damping approach consists temporaldifference learning algorithm control fact flexible alternative current transmission system damp power system oscillation proposed approach based local measurement free knowledge power system dynamic illustration carried one machine infinite bus system ,1
ML_660,distributed algorithm computing minimum description length mdl learning bayesian inference network data learning algorithm exploit property mdlbased score metric distributed asynchronous adaptive search technique called nagging nagging intrinsically faulttolerant dynamic load balancing feature scale well demonstrate viability effectiveness scalability approach empirically several experiment networked machine specifically show distributed algorithm provide optimal solution larger problem well good solution bayesian network variable ,1
ML_661,trial fibrillation common sustained cardiac arrhythmia result series machine learning experiment detection promising paroxysmal atrial fibrillation predictor based ratio short long rr interval possibility generate rule paf screening predicting paf screening calculated ratio successive rr interval problem imminent paf prediction much difficult concept normalisation hail implemented optimal seems ratio shortest longest rr interval least time larger ratio normalisation time patient also detected maximal distance longest shortest rr interval six rr interval ,1
ML_662,minor component analysis mca deal recovery eigenvector associated smallest eigenvalue autocorrelation matrix input data important tool signal processing data analysis almost exclusively solved linear neuron present linear neuron endowed novel learning law called mca exinn analyzes feature neural literature mca poor sense little theoretical basis given almost focusing ode asymptotic approximation experiment toy problem fourdimensional problem presented without numerical analysis address problem lay sound theoretical foundation neural mca theory particular classifies mca neuron according riemannian metric justifies analysis degeneracy error cost different behavior approaching convergence cost landscape studied used basis analysis asymptotic behavior phase dynamic mca algorithm investigated detail together numerical analysis lead identification three possible kind ergence called sudden dynamic numerical importance choice low initial condition also explained lot importance given experimental part simulation highdimensional problem arepresented analyzed orthogonal regression total least square tl technique also presented together realworld application identification parameter electrical machine concluded mca exin best mca neuron term stability finite time ergence speed accuracy ,1
ML_663,describes stateoftheart modular actuator advantage conventional actuator present testing actuator testbed devised testing nextgeneration robot actuator intelligent actuator fundamental unit openarchitecture reconfigurable machine actuator robotic application highly complex nonlinear device numerous parameter condition considered order obtain maximum performance machine necessary obtain parameter creating specification characterizing actuator system highly advanced measurement equipment acquired lesson learned broadbased testing evaluation effort accelerate development actuator technology recent research activity developing modular actuator comparison conventional recent actuator technology introduced performance testing actuator explained together purpose measurement parameter hardware software environment testbed used testing various parameter described test result summarized characterizing performance actuator ,1
ML_664,distributed computing majority computing power local area network resides computer user directly access researcher learned placing computational resource close possible end user prevented resource bottleneck supercomputer reduced networking cost provided superior user improved network server technology increased administrative cost reliability concern led sun microsystems introduce sunray sunray promise bring back day centralized server accessed dumb terminal appropriately called network appliance sunray relatively simple piece computer hardware designed exclusively accept input mouse keyboard deliver information centralized server receive calculation result server display result monitor stateless contain hard drive memory designed maintain information user action operating system information sunray need programmed firmware software upgrade necessary client machine update needed administrator issue appropriate command server sunray download update rebooted ,1
ML_665,present method experiment adaptive posture control four legged walking machine starting analysis implemented movement behaviour bisam identify adequate task adaptive control component adaptive posture control mechanism statically stable dynamically stable movement reflexbased posture control implemented via fuzzy control reinforcement learning integration posture control control architecture also described ,1
ML_666,smart lighting become universal smart product solution global revenue u $ billion technology driven six factor lightemitting diode led lighting sensor control analytics intelligence internet thing iot concept end device platform application layer play essential role optimizing advantage led lighting emergence smart lighting ultimate aim smart lighting research introduce low energy efficiency high comfort latter still infancy stage present systematic literature slr bird eye view covering fulllength research topic smart lighting including issue implementation target technological solution prospect addition also provides detailed extensive overview emerging machine learning technique key solution overcome complex problem smart lighting comprehensive improving comfort also presented methodology taxonomy activity recognition promising solution comfort metric including light utilization ratio unmet comfort ratio light comfort ratio power reduction rate flickering perception kruithof comfort curve correlated color temperature relative mean square error finally indepth discussion issue future challenge increasing comfort smart lighting activity recognition also provided ,1
ML_667,context amount ersity data increased drastically recent year however certain situation data trained machine learning model significantly different testing data problem known concept drift cd cd serious issue wealth research detect around however literature focus classification task objective making systematic literature slr cd context regression research question detect cd build cd technique regression problem machine learning ? method ran automatic search process reference database selecting paper august following methodological process proposed kitchenhame charter resultswe selected paper drift detection method based ensemble neural network highlight oselm frequent selected paper superior performance however two paper confirm superiority statistically furthermore identify cd problem batch size drift point drift happens conclusion slr focus highlighting existing literature cd applied regression ,1
ML_668,substantial change occurring electric distribution system due ambitious target towards carbonneutrality many region around world one key challenge analyze interaction massive amount energy endusers electric distribution grid operator introduce comprehensive simulation platform aldist capable perform wide collection distribution system study capture multiple timescales ranging market planning transient event analysis aldist designed effortlessly integrate offtheshelf machine learning package algorithm implementation envision aldist serve platform empower researcher different expertise contribute development low carbon electricity sector ,1
ML_669,missing data universal data quality problem many domain leading misleading analysis inaccurate decision much research done investigate different mechanism missing data proper technique handling various data type last decade machine learning utilized replace conventional method address problem missing value efficiently studying analyzing recently proposed method machine learning approach vital adoption accuracy performance time consumed highlighted aimed help data analyst researcher address limitation machine learning imputation method conducting systematic literature provide comprehensive overview method impute missing value novel proposed machine learning approach used data imputation analyzed summarized assist researcher selecting proper machine learning method based several factor setting performed research study published adopting machine learning impute missing value focusing strength limitation total research article various scientific database analyzed search engine selected primary study finally several recommendation given guide future researcher applying machine learning impute missing value ,1
ML_670,semisupervised deep learning ssdl popular strategy leverage unlabelled data machine learning labelled data readily available realworld scenario different unlabelled data source usually available varying degree distribution mismatch regarding labelled datasets begs question unlabelled dataset choose good ssdl outcome ftentimes semantic heuristic used match unlabelled data labelled data however quantitative systematic approach election problem would preferable first test ssdl mixmatch algorithm various distribution mismatch configuration impact ssdl accuracy propose quantitative unlabelled dataset selection heuristic based dataset dissimilarity measure designed systematically ass distribution mismatch labelled unlabelled datasets affect mixmatch performance refer proposed method deep dataset dissimilarity measure dedims designed compare labelled unlabelled datasets feature space generic wideresnet applied prior learning quick evaluate model agnostic strong correlation test mixmatch accuracy proposed dedims suggests approach good fit quantitatively ranking different unlabelled datasets prior ssdl training ,1
ML_671,concern evolutionary approach distributed stochastic blackbox optimization worker inidually solve approximation problem natureinspired algorithm propose distributed evolution strategy de algorithm grounded proper modification evolution strategy family classic evolutionary algorithm well careful combination existing distributed framework smooth nonconvex landscape de convergence rate competitive existing zerothorder method exploit sparsity applicable match rate firstorder method de method us gaussian probability model guide search avoids numerical issue resulted finitedifference technique existing zerothorder method de method also fully adaptive problem landscape convergence guaranteed parameter setting propose two alternative sampling scheme significantly improve sampling efficiency leading similar performance simulation study several machine learning problem suggest proposed method show much promise reducing convergence time improving robustness parameter setting ,1
ML_672,conventional wisdom improve economic dispatch effectiveness design load forecasting method accurately possible however approach problematic due temporal spatial correlation system cost load prediction error observation motivates u jointly treat two form correlation adopting notion endtoend machine learning thus first propose taskspecific learning criterion conduct economic dispatch maximal economic benefit reduce computational burden overfitting issue taskspecific approach design efficient optimization kernel speed learning process additionally propose practical robust modelfree endtoend learning framework offer theoretical analysis empirical insight highlight effectiveness efficiency three proposed learning framework numerical highlight modelfree framework decrease additional cost inaccurate prediction % ieee bus system compared conventional approach ,1
ML_673,belief opinion evolution social network sn aid understanding people influence others decision social relationship large number user involved sn complexity traditional optimization technique high deal interaction user separately moreover state variable opinion highdimensional person usually opinion many different social issue incorporating classical opinion dynamic formulate opinion evolution sn highdimensional stochastic mean field game mfg numerical method highdimensional mfgs practically nonexistent need gridbased spatial discretization thus propose machinelearning method tractably solve highdimensional stochastic mfgs approach solving mfgs regarded special case training generative adversarial network simulation analyze effect random social issue stubbornness opinion evolution moreover social evolution data set show proposed algorithm efficiently predict diffusion opinion sn ,1
ML_674,article present noniterative inverse modeling technique based machine learning regression application microwave design optimization proposed inverse model accepts highdimensional sparameters computed many frequency point input estimate optimal geometricalphysical parameter microwave component output leastsquares support vector machine regression combined principal component analysis simultaneously overcome highdimensional input space illposed challenge inverse modeling also propose empirical method find optimum number principal component ie compression level example automated way make proposed model general easy compared existing datadriven inverse modeling technique inverse model trained set scattering parameter computed via dd solver configuration geometrical parameter feasibility accuracy proposed optimization scheme investigated comparing prediction corresponding optimal configuration estimated via commercial solver ,1
ML_675,extracting effective feature image crucial image classification challenging due high variation across image genetic programming gp become promising machine learning approach feature learning image classification representation existing gpbased image classification method usually treebased structure method typically learn useful image feature according output gp program root node however flexible enough feature learning since feature produced internal node gp program seldom directly used propose image classification approach gp program structure flexibly reuse feature generated different node including internal node gp program method automatically learn various informative image feature based function set terminal set effective efficient image classification furthermore instead relying predefined classification algorithm proposed approach automatically select suitable classification algorithm based learned feature conduct classification simultaneously single evolved gp program image classification experimental result benchmark datasets varying difficulty suggest approach achieves better performance many stateoftheart method analysis demonstrates effectiveness efficiency flexible feature reuse proposed approach analysis evolved gp programssolutions show potentially high interpretability ,1
ML_676,power efficiency become nonneglected issue modern cpu therefore accurate robust power model highly demanded academia industry however hard existing power model balance modeling speed generality accuracy well introduces mcpatcalib microarchitecture power modeling framework combine mcpat machine learning ml calibration active learning al sampling mcpatcalib quickly accurately estimate power different benchmark executed different cpu configuration provide effective evaluation tool early design stage first mcpatnm introduced support preliminary analytical power modeling nm technology node wide range modeling feature identified automatic feature selection advanced nonlinear regression used calibrate mcpatnm modeling result greatly improving accuracy moreover novel al approach termed power greedy sampling powergs embedded domain knowledge leveraged reduce modeling cost effectively configuration riscv berkeley outoforder machine boom benchmark targeting nm technology extensively evaluate mcpatcalib compared stateoftheart sota microarchitecture power model mcpatcalib reduce mean absolute percentage error mape different crossvalidation strategy % ��� % absolute reduction meanwhile powergs superior existing al approach significantly reduce demand labeled sample speed model construction effectiveness overall modeling estimation flow al sampling also ver,1
ML_677,edge artificial intelligence ai receiving tremendous amount interest machine learning community due everincreasing popularization internet thing iot unfortunately incorporation ai characteristic edge computing device present drawback power area hungry typical deep learning technique convolutional neural network cnns propose powerandarea efficient architecture based exploitation correlation phenomenon stochastic computing sc system proposed architecture solves challenge cnn implementation sc sccnn may high resource used binarytostochastic conversion inaccuracy produced undesired correlation signal complexity stochastic maximum function implementation prove architecture meet requirement edge intelligence realization embed fully parallel cnn single fieldprogrammable gate array fpga chip result obtained showed better performance traditional binary logic sc implementation addition performed full vlsi synthesis proposed design showing present better overall characteristic recently published vlsi architecture ,1
ML_678,step detection critical many application including health indoor navigation however remains challenging achieve robust step detection type human gait sensor location user body challenge increase blind people whose gait different sighted affected navigation aid propose evaluate machinelearningbased step detection method smartstep advantage method rely sensorposition stepmode hand motion mode preclassifications threshold calibration method already shown promising performance % recall precision applied challenging condition young adult gait ability method generalize blind gait put question performance assessed two different blind people walking datasets including various challenging condition different walking speed smartphone placement hand motion mode sensor type navigation aid smartstep achieves % precision % overcount rate % recall % undercount rate demonstrates robustness method encourages usage application population ,1
ML_679,industrial internet thing iot rapidly developing industry current iot industry intrusion detection system id remains one key technology industrial iot security protection researcher considered applying algorithm machine learning deep learning network id cope complex changing network environment automatically extract key feature highdimensional feature data however real industrial iot environment data imbalance factor affect performance deeplearningbased id article network intrusion detection model based data level three databased research scheme constructed step step article data augmentation scheme based variational autoencoder vae databalancing scheme based conditional vae databalancing scheme based random undersampling conditional vae three datalevelbased scheme combined deeplearningbased id article build experiment based csecicids dataset verify effectiveness three data processing scheme data enhancement third scheme macrofscore convolutionalneuralnetworkbased id model improved % macrofscore gatedrecurrentunitbased id model improved % ,1
ML_680,semisupervised learning ssl machine learning approach integrates supervised unsupervised learning mechanism integration may done different way one possibility wrapperbased strategy aim wrapperbased strategy small number labelled instance create learning model created model used labelling process unlabelled instance labelled consequently instance incorporated labelled set one important aspect wrapperbased ssl method selection unlabelled instance labelled labelling process word efficient selection process play important role design wrapperbased ssl method since lead efficient labelling process turn creation efficient learning model propose three selection method applied wrapperbased ssl method idea two different selection criterion prediction confidence classification agreement distance metric perform efficient selection unlabelled instance order ass feasibility proposed approach selection method applied two wellknown wrapperbased ssl method selftraining cotraining additionally empirical analysis conducted compare standard selftraining cotraining method proposed version two ssl method classification datasets ,1
ML_681,privacy protection attracted increasing attention privacy concern often prevent flexible data utilization industry data distributed across multiple organization due privacy concern federated learning fl enables crossorganizational machine learning communicating statistical information stateoftheart technology used solve problem however gradient boosting decision tree gbdts fl balancing communication efficiency security maintaining sufficient accuracy remains unresolved problem propose fl scheme gbdts ie efficient fl gbdts eflboost minimizes accuracy loss communication cost information leakage proposed scheme focus appropriate allocation local computation performed inidually organization global computation performed cooperatively organization updating known structure incur high communication cost global computation whereas leaf weight require cost expected contribute relatively accuracy thus proposed eflboost tree structure determined locally one organization leaf weight calculated globally aggregating local gradient organization specifically eflboost requires three communication per update one communication efficient method statistical information low privacy risk leaked organization performance evaluation datasets roc auc log loss fscore used metric proposed eflboost outperformed existing scheme incur low communication cost comparable scheme offer privacy protection ,1
ML_682,cohesive distributed satellite system cd key enabling technology future remote sensing communication mission however meet strict synchronization requirement generalized clock local oscillator signal generated locally distributed node achieving exact synchronization absolute phase frequency time complex problem addition satellite system significant resource constraint especially small satellite envisioned part future cd thus development precise robust resourceefficient synchronization technique essential advancement future cd context survey aim summarize categorize relevant result synchronization technique distributed satellite system ds first important architecture system concept defined synchronization method reported literature reviewed categorized article also provides extensive list application example synchronization technique ds addition significant advance operation closely related synchronization intersatellite ranging relative position survey also provides discussion emerging datadriven synchronization technique based machine learning ml finally compilation current research activity potential research topic proposed identifying problem challenge useful researcher field ,1
ML_683,nonautoregressive decoder neural machine translation paid increasing attention due faster decoding autoregressive decoder however apparent problem low performance mainly originated wrong prediction target sentence length attack problem proposes novel machine translation model nonautoregressive decoder named iterative lengthadjustive nonautoregressive decoder iland decoder adopts masked language model avoid generation lowconfident token change length target sentence iteratively optimal length complete goal iland consists three complementary submodules token masker length adjuster token generator token masker token generator take charge masked language model length adjuster optimizes target sentence length sequencetosequence training translation model also introduced training length adjuster token generator jointly trained since share similar structure effectiveness translation model proven showing empirically model outperforms model various nonautoregressive decoder thorough analysis suggests performance gain translation model come target sentence length adaptation joint learning addition iland also shown faster iterative nonautoregressive decoder still robust multimodality problem ,1
ML_684,millimeterwave radar machine vision important mean intelligent vehicle perceive surrounding environment aiming problem multisensor fusion proposes object detection method millimeterwave radar vision fusion radar camera complement radar data fusion machine vision network effectively reduce rate missed detection insufficient light condition improve accuracy remote small object detection radar information processed mapping transformation neural network obtain mask map radar information visual information scale multidata source deep learning object detection network msyolo based millimeterwave radar vision fusion proposed homemade datasets used training testing maximized sensor information improved detection accuracy premise ensuring detection speed compared original yolov fifth version look network result show msyolo network meet accuracy requirement better among model large model msyolo highest accuracy map reaching small model msyolo good accuracy speed map reach maintaining high frame rate fps ,1
ML_685,focus problem stable prediction across unknown test data test distribution might different training one agnostic model training case previous machine learning method might exploit subtly spurious correlation induced noncausal variable training data prediction spurious correlation changeable across data leading instability prediction across unknown test data address problem propose conditional independence test based algorithm screen part noncausal feature reduce spurious correlation stable prediction leveraging seed variable show theoretically empirical experiment algorithm precisely screen isolated noncausal variable causal relationship variable remove spurious correlation induced increasing stability prediction across unknown test data extensive experiment synthetic realworld datasets demonstrate algorithm outperforms stateoftheart method stable prediction across unknown test data ,1
ML_686,deep graph network dgns family machine learning model structured data finding heavy application life science drug repurposing molecular property prediction social network data recommendation system privacy safetycritical nature domain motivates need developing effective explainability method family model far progress field challenged combinatorial nature complexity graph structure respect novel local explanation framework specifically tailored graph data dgns approach leverage reinforcement learning generate meaningful local perturbation input graph whose prediction seek interpretation perturbed data point obtained optimizing multiobjective score taking account similarity structural level well level deep model output mean able populate set informative neighboring sample query graph used fit interpretable model predictive behavior deep network locally query graph prediction show effectiveness proposed explainer qualitative analysis two chemistry datasets tox estimated solubility esol quantitative result benchmark dataset explanation cycliq ,1
ML_687,cloud application increasingly shifting large monolithic service complex graph looselycoupled microservices despite benefit microservices prone cascading performance issue lead prolonged period degraded performance sage machine learningdriven root cause analysis system interactive cloud microservices accurate practical show sage correctly identifies root cause performance issue across erse set microservices take action address leading predictable performant efficient cloud system ,1
ML_688,introduce tunable loss function called ��loss parameterized �� ��� ��� interpolates exponential loss �� logloss �� loss �� ��� machine learning setting classification theoretically illustrate fundamental connection ��loss arimoto conditional entropy verify classificationcalibration ��loss order demonstrate asymptotic optimality via rademacher complexity generalization technique buildupon notion called strictly local quasiconvexity order quantitatively characterize optimization landscape ��loss practically perform class imbalance robustness classification experiment benchmark image datasets convolutionalneuralnetworks practical conclusion certain task may benefit tuning ��loss away logloss �� end provide simple heuristic practitioner particular navigating �� hyperparameter readily provide superior model robus,1
ML_689,deployment g technology number iov internet vehicle device connected internet explosively grow however kind edge network device iov device also face problem including weak password authentication lack security protection lagged firmware updating largely threatening security legitimacy device iov device identification important discovering monitoring protecting device although existing proactive identification method based device fingerprint used identifying largescale internetconnected iov device satisfy finegrained requirement security risk assessment due increase type brand iov device fingerprint granularity insufficient proposed retransmissionbased tcp fingerprint largescale finegrained proactive device identification firstly probing scheme designed obtain tcp retransmission packet increase granularity space traditional tcp fingerprint selecting multigroup feature tcp retransmission message bagging strategy ensemble learning combined classifier five predominant machine learning algorithm generated experimental result showed identification accuracy recall iov device respectively reached % % ,1
ML_690,decentralized learning involves training machine learning model remote mobile device edge server cloud server keeping data localized even though many study shown feasibility preserving privacy enhancing training performance introducing byzantine resilience none simultaneously considers therefore face following problem \textit { efficiently coordinate decentralized learning process simultaneously maintaining learning security data privacy entire system } address issue propose spdl blockchainsecured privacypreserving decentralized learning system spdl integrates blockchain byzantine faulttolerant bft consensus bft gradient aggregation rule gar differential privacy seamlessly one system ensuring efficient machine learning maintaining data privacy byzantine fault tolerance transparency traceability validate approach provide rigorous analysis convergence regret presence byzantine node also build spdl prototype conduct extensive experiment demonstrate spdl effective efficient strong security privacy guarantee ,1
ML_691,dexterous control robotic hand driven human motor intent drawn lot attention industrial rehabilitation scenario providing simultaneous proportional control become prevailing solution recently towards improving finger kinematics estimation precision reducing computational cost convolution model attention mechanism cnnattention proposed comparison two previously used deep learning model long shortterm memory lstm sparse pseudoinput gaussian process spgp also included surface electromyogram semg kinematic signal corresponding six hand grasp movement estimation performance three model evaluated three measure pearson correlation coefficient cc root mean square error rmse coefficient determination r real estimated joint angle result demonstrated proposed cnnattention model outperformed lstm spgp significantly pvalue & lt average value cc rmse r degree respectively also cnnattention model stable versatile various subject joint angle comparison model additionally computational time build cnnattention obviously shorter train lstm model min v min finding suggest cnnattention would promising model continuous estimation hand movement humanmachine interaction cooperation ,1
ML_692,space industry growing tremendous pace generating attraction industry academia various governmental industrial institution embarking program aiming exploration industry impact recent advance control system computational technology networking internet thing iot robotics manufacturing machine learning mlartificial intelligence ai could support space industry providing possibility detailed mass exploration deeper space regard article review multidiscipline area space exploration perspective article focus recent advancement aforementioned technology control system theory considering impact longdistance controlling station intended site exploration also provided casestudy analysis martian surface identifying technical research challenge ,1
ML_693,machine learning ml approach widely developed enable realtime stability assessment largescale electricity grid however also extensively recognized ml model vulnerable adversarial example instance slightly perturbed original example remain invisible human eye however adversarial example power system result incorrect decision also follow electricity law transfer limit bypass bad data detector end proposes novel concept named physicsconstrained robustness verification aim compute lowerbound adversarial perturbation evaluating vulnerability intelligent stability assessment isa power system first propose general formulation compute physicsconstrained robustness considering physical constraint stealthyinvisible requirement analytical result provided robustness isa mislabelling power balance invisible requirement constraint consecutively furthermore static stability assessment employed example evaluate robustness applied ml model providing explicit formulation finally extensive experiment conducted evaluate physicsconstrained robustness isa different setting realworld load profile provide suggestion select ml model ,1
ML_694,bthis special issue ofb iieee design & amptesti benchmarking machine learning ml application special issue benchmarking long overdue last one find one edited way back issue covered itc benchmark put together introduced special session international test conference used comparing automatic test patterngeneration atpg algorithm ,1
ML_695,fig orientationportrait positionfloat graphic orientationportrait positionfloat xlinkhrefpandetif xmlnsxlinkhttpwwwworgxlink figbthe article inb issue ided two group first group belongs special issue benchmarking machine learning ml system application second group consists general interest paper ,1
ML_696,model size number layer increase deep neural network dnns demand enormous computational power throughput meet exceedingly high prediction accuracy today machine learning ml application spatial hardware accelerator proposed optimize dataflow exploit sparsity provide significant decrease power consumption spatial architecture traditionally designed metallic interconnects significant power expended data movement different dataflows exploit extended wireless technology design powerefficient highthroughput dnn accelerator ewinn configured representative dataflows arithmetic precision leverage novel circuit design utilizing daddaalgorithm based multiplyandaccumulate mac circuit bit bit bit input reduce area power delay constraint nm predictive technology novel wireless transmitter integrates onoff keying ook modulator power amplifier result significant energy saving reduce area overhead cluster wireless transceivers group four weight input feature effectively multicast reduce data movement energy efficient transceiver circuit implemented stateoftheart bsim nm finfet technology model link budget considers required rf power different frequency interpe distance three different antenna directivity including isotropic detailed rtl modeling cycleaccurate simulation result show ewinn achieves % latency reduction % energy saving compared stateofart wire interconnected accelerator % area reduction % energy saving cost % latency increase compared prior wireless accelerator various neural network alexnet vgg resnet ,1
ML_697,crop plant disease significant threat productivity sustainable development agriculture early prediction disease attack useful effective control disease taking proactive action attack modern information communication technology icts predominant role precision agriculture pa application support sustainable development immense need solution early prediction disease attack proactive control plant disease attack solution disease detection computer vision approach detect existence disease disease already appeared aim propose machine learning ml approach early prediction probability disease attack based internet thing iot directly sensed crop field environmental condition plant disease life cycle strongly correlated environmental condition crop field environmental condition used predict occurrence plant disease multiple linear regression mlr applied ml model due existence linear relationship disease attack environmental condition internet thing iot based crop field environmental condition help accurately predict occurrence plant disease ml approach proposed model implemented prediction blister blight exobasidium vexans tea camellia sinensis plant check effectiveness proposed solution implementation proposed model reveals accuracy prediction occurrence disease reach % ,1
ML_698,logistics important driver competitiveness industry material supply development smart logistics powered precise positioning communication technology significantly improve efficiency logistics emerging technology ultrawideband uwb precision positioning attracted significant attention throughout previous decade owing promising capability radio frequencybased indoor localisation system addition uwb characterised large bandwidth data rate short message length low transmission power high penetration capability favourable indoor positioning application however uwb localisation technology face several challenge somewhat similar technology mitigating error originate nonlineofsight nlos situation tackling signal interference dense environment required operate extreme condition review recent advance made uwb positioning system last five year focus highranking article addition going conventional solution uwb challenge modern solution involve machine learning sensor data fusion discussed highlight promising finding recently implemented foreseen uwb positioning system providing summary reviewed article additionally address major challenge face uwb positioning technology nlos situation focusing proposed remedy multisensor fusion machine learning application introduces uwb technology promotes smart logistics offering indoor positioning improve efficiency delivery good source customer furthermore demonstrates benefit uwb technology accurate positioning tracking stationary moving item machinery indoor logistics environment ,1
ML_699,present approach detect interturn shortcircuit itsc fault permanent magnet synchronous motor pmsms machine learning pmsms posse many attractive advantage high efficiency highpower density however widespread application preventive fault diagnosis secure safe operation reduce maintenance cost becomes increasingly critical achieve objective machine learning employed fault diagnosis wherewith minor itsc fault detected preventive manner therefore faulty motor replaced early ensure system healthy operation moreover machine learning also utilized classify fault level eg minor moderate serious fault reference appropriate maintenance action proposed method adopts support vector machine svm convolutional neural network cnn training diagnosis model experimental data collected test laboratory svm appropriate feature required training selected analysis pmsm mathematical model considering itsc fault allows efficient training much le data contrast cnn purely datadriven approach requires much data training accuracy method validated another set measured data found method achieve accuracy % however svm requires much le amount data achieve accuracy demonstrates advantage modelaided machine learning method would suitable application faulty motor data easily acquired ,1
ML_700,fingerprintbased localization play important role indoor locationbased service position information usually collected distributed client gathered centralized server however overloaded transmission well potential risk ulging private information burden application owning ability address challenge federated learning flbased fingerprinting localization come people sight aim train global model keeping raw data locally however distributed machine learning ml scenario unavoidable database heterogeneity usually degrades performance existing flbased localization algorithm fedloc first characterize database heterogeneity computable metric ie area convex hull verify experimental result novel heterogeneous flbased localization algorithm area convex hullbased aggregation fedlocac proposed extensive experimental result including realword case conducted conclude proposed fedlocac achieve obvious prediction gain compared fedloc heterogeneous scenario ,1
ML_701,machine learning problem usually assume validation accuracy good estimation prediction accuracy datasets without ground truth reality assumption may hold therefore propose approach estimate prediction accuracy target model unlabeled datasets proposed approach us multiple target homogeneous model assign unlabeled sample confidence value based number model agreeing predicted label confidence value prediction accuracy target model datasets estimated experiment target model convolutional neural network cnn model homogeneous model differ initial weight experiment conducted datasets wide variety music genre estimation performance proposed approach compared reversed testing quality rtq ensemble average quality eaq approach rtq approach proposed estimate prediction accuracy trained model eaq approach originally designed estimating predictive uncertainty inidual sample apply three compared model estimate prediction accuracy datasets linear model parameter linear model either computed multiple labeled datasets one labeled dataset experimental result show compared rtq approach proposed approach much lower estimation error datasets compared eaq approach proposed approach robust datasets large distribution shift finally show additional benefit proposed approach case estimated accuracy unsatisfactory may retrain target model training set contains original training sample plus training sample manual labeling unlabeled dataset experimental result confirm effective select label sample low confidence value randomly selected overall proposed approach promising approach estimating prediction accuracy unlabeled datasets ,1
ML_702,since stroke disease often cause death serious disability active primary prevention early detection prognostic symptom important stroke disease ided ischemic stroke hemorrhagic stroke minimized emergency treatment thrombolytic coagulant administration type first essential detect real time precursor symptom stroke occur differently inidual provide professional treatment medical institution proper treatment window however prior study focused developing acute treatment clinical treatment guideline onset stroke rather detecting prognostic symptom stroke particular recent study image analysis magnetic resonance imaging mri computed tomography ct mostly used detect predict prognostic symptom stroke patient methodology difficult diagnose early realtime also limitation term long test time high cost testing propose system predict semantically interpret stroke prognostic symptom based machine learning multimodal biosignals electrocardiogram ecg photoplethysmography ppg measured realtime elderly predict stroke disease realtime walking designed implemented stroke disease prediction system ensemble structure combine cnn lstm proposed system considers convenience wearing biosignal sensor elderly biosignals collected sampling rate hz per second three electrode ecg index finger ppg walking according experimental result c decision tree showed prediction accuracy % randomforest showed prediction accuracy % walking elderly addition cnnlstm model raw data ecg ppg showed satisfactory prediction accuracy % result realtime prediction elderly stroke patient simultaneously showed high prediction accuracy performance ,1
ML_703,metaverse m digital universe accessible virtual environment established merging virtually improved physical digital reality metaverse m offer enhanced immersive experience interactive learning experience student learning educational setting expanded synchronous communication setting allows different user share experience aim evaluate student perception application m united arab emirate uae medicaleducational purpose university student surveyed examine model study conceptual framework consisted adoption construct including technology acceptance model tam personal innovativeness pi perceived compatibility pco satisfaction u perceived triability ptr perceived observability pob unique model correlated technologybased feature inidualbased feature also used hybrid analysis machine learning ml algorithm structural equation modelling sem also employ importance performance map analysis ipma ass importance performance factor find u essential determinant user intention metaverse ums study finding useful stakeholder educational sector understanding importance factor making plan based order significance factor also methodologically contributes information system literature one study used complementary multianalytical approach ml algorithm investigate ums metaverse system ,1
ML_704,order make image denoising effective high noise level environment gray image denoising method based symmetric dilation residual network proposed additive gaussian white noise first incremental & amp dilated convolution bn batch normalization leaky relu rectified linear unit used extract learn feature input noise image image reconstructed combining descending & amp dilated convolution relu finally effective separation image noise realized integrating deep residual network bn experimental data specific denoising model stochastic denoising model show method achieves better objective result based small resolution input & amp large resolution input small dataset & amp large dataset compared method series subjective visual comparison result also show proposed method perform image denoising well high noise level environment problem damaged edge texture detail boundary artifact poor definition denoised image proposed method improves image denoising ability also improves denoising productivity extent related made comprehensive discussion current mainstream image denoising method based traditional machine learning deep learning extent make lack review addition existing problem future development direction image denoising discussed detail ,1
ML_705,establishing accurate wireless propagation model essential highquality communication aiming low accuracy complexity traditional wireless propagation model novel accurate wireless propagation model proposed based bidirectional long shortterm memory bilstm algorithm machine learning model us machine learning technology driven big data achieve high realtime performance low complexity also accurately predict wireless signal coverage intensity environment order allow model accommodate actual environment target area propagation model dynamically corrected deep learning training bilstm used describe relationship feature relationship feature target value reference signal receiving power rsrp bilstm also used represent relationship fullconnection layer obtain result sufficient parameter space provided model parameter propagation model searched fitted fullconnection optimization training tuning predicted value poor coverage recognition rate pcrr model reach predicted value root mean squared error rmse demonstrates better accuracy proposed model ,1
ML_706,article special section focus machine learning artificial intelligence ai power system market power engineering professional seeing another wave ai arguably second wave power industry third wave ai community since technological advancement ai making universal solution everything compared human counterpart application aibased solution accurate faster execution higher tolerance level tedious job extreme environment ,1
ML_707,experience power machine learning ml everyday lives���be picture speech recognition customized suggestion virtual assistant unlocking phone underlying mathematical principle applied since middle last century known istatistical learningi however enormous increase computational power even device small smartphone enabled significant advance wide adoption ml nearly every part life scientific ,1
ML_708,hear one selfdriving car wrote autobiography ? hear groan introducing issue devoted artificial intelligence ai machine learning ml need icebreaker iieee power & amp energy magazinei topic tend focus power system challenge cool technique technology applied address topic ai ml issue inverts paradigm explore data science methodology underlying ai disciplinary toolbox power system application ,1
ML_709,machine learning model successfully employed diagnosis schizophrenia disease impact classification model feature selection technique diagnosis schizophrenia evaluated sought access performance classification model different feature selection approach structural magnetic resonance imaging data data consist subject schizophrenia healthy control subject evaluated different classification algorithm based support vector machine svm random forest kernel ridge regression randomized neural network moreover evaluated ttest receiver operator characteristic roc wilcoxon entropy bhattacharyya minimum redundancy maximum relevance mrmr neighbourhood component analysis nca feature selection technique based evaluation svm based model gaussian kernel proved better compared classification model wilcoxon feature selection emerged best feature selection approach moreover term data modality performance integration grey matter white matter proved better compared performance grey white matter inidually evaluation showed classification algorithm feature selection approach impact diagnosis schizophrenia disease indicates proper selection feature classification model improve diagnosis schizophrenia ,1
ML_710,power electronic traction transformer failure singlephase pwm rectifier lead performance degradation system thus feasible datadriven method proposed realize online fault diagnosis singlephase pwm rectifier principle datadriven method construct signal predictor based historic database utilizing nonlinear autoregressive exogenous narx model randomized learning algorithm named extreme learning machine elm besides ensemble method employed improve prediction accuracy robustness load fluctuation online diagnosis predictor sensor operate simultaneously residual generated afterward fault detection conducted comparing residual fault threshold fault classification completed based system fault symptom fault residual analysis several hardwareinloop test implemented verify applicability proposed diagnosis method test result show datadriven method effective perform online fault diagnosis fast fault detection speed high classification accuracy robust load fluctuation ,1
ML_711,federated learning fl capable performing large distributed machine learning task across multiple edge user periodically aggregating trained local parameter address key challenge enabling fl wireless fogcloud system eg noniid data user heterogeneity first propose efficient fl algorithm based federated averaging called fedfog perform local aggregation gradient parameter fog server global training update cloud next employ fedfog wireless fogcloud system investigating novel networkaware fl optimization problem strike balance global loss completion time iterative algorithm developed obtain precise measurement system performance help design efficient stopping criterion output appropriate number global round mitigate straggler effect propose flexible aggregation strategy train fast user first obtain certain level accuracy allowing slow user join global training update extensive numerical result several realworld fl task provided verify theoretical convergence fedfog also show proposed codesign fl communication essential substantially improve resource utilization achieving comparable accuracy learning model ,1
ML_712,separable nonlinear leastsquares snlls problem considered article frequently appear wide range research field machine learning computer vision system identification signal processing variable projection algorithm proposed golub pereyra reduces dimension parameter projecting linear parameter problem quite valuable solving snlls problem previous implementation variable projection algorithm based matrix factorization article propose iterative implementation variable projection algorithm compared previous implementation based matrix decomposition proposed method effectively avoid suffering large condition number matrix even matrix decomposition failure dealing illposed snlls problem numerical experiment realworld data synthetic data show efficiency robustness proposed iterative variable projection algorithm ,1
ML_713,soil moisture sm important parameter used control broad range environmental application increasing attention recently given machine learning ml method sm retrieval provide promising performance nevertheless based supervised learning strategy depend used labeled training sample fact unaffordable costly letter teacherstudent soil moisture estimation called t sme relying teacherstudent framework synthetic aperture radar sar optical data proposed estimate sm advantage framework enrolls large amount unlabeled data together small amount labeled data experiment carried two arid area southern tunisia input data include backscatter coefficient twomode polarization ����vv ����vh sentinela normalized difference vegetation index ndvi normalized difference infrared index ndii sentinela insitu measurement extensive experimental result demonstrated t sme framework capable generating wellperformed student model estimation accuracy superior teacher model artificial neural network ann extreme gradient boosting orest regressor rfr water cloud model wcm highly correlated insitu measurement high pearsons correlation coefficient r rrf rann rxgboost rwcm rts sme low root mean square error rmse rmserf % rmseann % rmsexgboost % rmsewcm % rmsets sme % respectively ,1
ML_714,millimeter wave mmwave massive mimo system intrinsic component g beyond system rely beamforming codebooks initial access data transmission current beam codebooks however generally consist large number narrow beam scan possible direction leading large training overhead codebooks normally account hardware impairment possible nonuniform array geometry calibration process expensive overcome limitation develops efficient online machine learning framework learns adapt codebook beam pattern specific deployment surrounding environment distribution hardware characteristic done designing novel complexvalued neural network architecture neuron weight directly model beamforming weight analog phase shifter accounting key hardware constraint model learns codebook beam online selfsupervised training avoiding need explicit channel state information respect practical situation channel imperfect hard obtain simulation result highlight capability proposed solution learning environment hardware aware beam codebooks reduce training overhead improve robustness possible hardware impairment ,1
ML_715,business failure prediction important sustainable development enterprise machine learning algorithm especially ensemble algorithm shown great economic benefit enterprise financial early warning however highly imbalanced class distribution financial risk data inexplainable machine learningbased early distress warning model limit commercial application address limitation enhance business failure prediction performance treeensemble boosting manner moreover solve class imbalanced issue business failure datasets weighted objective function weighted crossentropy embedded boosted tree framework making weighted xgboost costsensitive business failure prediction model besides tackle second issue explore intrinsic interpretability proposed method visualizing feature importance incorporating partial dependence plot technique locally interpret inidual business failure event experimental result business failure datasets different predictive horizon collected china security market accounting research database csmard show proposed weighted xgboost good solution reduce error recognizing firm business failure furthermore visualized feature importance score partial dependence plot result demonstrate costsensitive treebased ensemble good tool guide investor making rational well provide interpretable business prediction result reference policymaking regulator ,1
ML_716,machine learning ml artificial intelligence ai become mainstream technology many accelerator proposed cope computation kernel however access external memory frequently due large size deep neural network model suffering von neumann bottleneck moreover privacy issue becoming critical ondevice training emerging solution however ondevice training challenging perform training limited power budget requires lot computation memory access inference energyefficient processinginmemory pim architecture supporting endtoend ondevice training named tpim macro design includes tsram cellbased pim block compute inmemory operation three computational datapaths endtoend training three computational path integrates arithmetic unit forward propagation backward propagation gradient calculation weight update respectively allowing weight data stored memory stationary tpim also support variable bit precision cover various ml scenario fully variable input bit precision bit bit bit bit weight bit precision forward propagation input bit precision bit weight bit precision backward propagation addition tpim implement sparsity handling scheme skip computation input data turn arithmetic unit weight data reduce unnecessary computation leakage power finally fabricate tpim chip mm die nm cmos logic process operates ���mhz supply voltage ���v dissipating ���mw power inference mw training result achieves ���topsw energy efficiency inference bit activation bit weight data ���topsw training bit activationerror bit weight data conclusion tpim first pim chip support endtoend training demonstrating time performance improvement latest p,1
ML_717,hospital receive triage large volume medical referral otorhinolaryngology annually challenge derive knowledge written unstructured text may unavailable electronic format acquiring knowledge insight referral important health management policymakers triaging general practitioner gp referral ear nose throat ent specialist manual process performed experienced clinician timeconsuming proposes utilising machine learning data mining automate process referral ensemble machine learning algorithm perform clinical text mining unstructured referral text order derive relationship among discovered medical term proposed implemented set comprehensive term set association rule describe entire referral datasets characteristic obtained association rule mining experiment neural networkbased text classification model classify referral high accuracy developed tested reported ,1
ML_718,stock market prediction prediction stock index single stock price time series data prediction algorithm machine learning deep learning used assist stock market supervision stock trading etc study influential factor stock market prediction deep learning model longshort term memory lstm three kind influential factor selected including historical shanghai ashare index historical u nasdaq index term frequency increase position decrease position weibo order see performance influential factor made two kind group one single factor group multiple factor group experiment carried data january december prediction result measured three evaluation metric mean absolute error mae root mean square error rmse mean absolute percentage error mape experiment result show three evaluation metric prediction result single factor group better prediction result multiple factor group term prediction stock index value daily rise fall show research stock market index trend prediction predictive factor better prediction result ,1
ML_719,lack training data model important issue construction machine learning model simulation data generation procedure built obtain healthcare data small amount sample simulation data belongs healthcare data item total specifically includes basic personal information item medical expense item common disease item daily living habit item health checkup value item addition basic personal information item data ided continuous data item medical expense health checkup value discrete data item common disease daily habit based continuous data large amount continuous data generated multivariate distribution ensuring distribution satisfies central limit theorem random forest regression model built simulate medical cost data discrete data support vector machine svm built optimized svm model obtained multivariate comparison considering loss function penalty term regularization validate model soundness model fit random forest regression model tested measure relationship prediction error mean expectation r^ accuracy assessment model simulation established ass prediction efficiency optimized svm model assessed essentially % summary simulation generation procedure provides technical support improve medical database ,1
ML_720,computer field cybersecurity focus attention detect malware one focus difficulty network security research effectively traditional existing malware detection scheme mainly ided two method category database matching machine learning method rise deep learning deep learning method applied field malware detection deeper semantic feature extracted via deep neural network task follows machine learning method onedimensional convolutional neural network detect malware propose machine method combining learning deep learning used detection machine learning us lgbm obtain accuracy rate % onedimensional cnn obtains accuracy rate % lgbm used screen importance feature onedimensional convolutional neural network help improve detection result accuracy rate % ,1
ML_721,portfolio management investment strategy redistribute given fund different asset aim maximize return minimize risk given period much research application machine learning technique portfolio management propose novel investment strategy us framework based depthwise convolution squeeze excitation module residual block gate recurrent unit called dsrg network test performance strategy eight common trading strategy obtain corresponding accumulative portfolio value sharpe ratio addition sharpe ratio used measure adjusted rate return strategy result show proposed strategy outperforms least % better strategy used otherwise comparison experiment still maintained rate return % experiment comparison strategy showed loss ,1
ML_722,oil gas pipeline failure due internal corrosion threaten human safety infrastructural economic loss environmental devastation propose innovative method predicting internal corrosive depth oil gas pipeline extreme learning machine elm based historical inline inspection ili data first undergoes mutual information principal component analysis mipca feature selection inservice pipe section qinghai china spanning kilometer recorded internal corrosion defect used case evaluate efficacy proposed model feature including distance elbow distance upstream girth weld initial defect depth pipeline pressure elevation identified used predictor result show compared widely used machine learning method back propagation bp neural network random forest rf proposed method improves accuracy calculation speed prediction model currently used method highly generalizable better prediction help better maintenance plan thereby minimizing risk cost pipeline failure ,1
ML_723,distributed machine learning applied many field federated learning one popular distributed machine learning method however large number federated learning client make learning process vulnerable malicious participant propose federated learning architecture combined blockchain technology achieves good result defending attack first introduce overall structure combined scheme explain design combination scheme detail especially candidate model generation finally perform simulation experiment mnist verify superiority scheme experimental result show scheme resist attacker effectively proportion attacker % accuracy global model still around % ,1
ML_724,outbreak covid people eager develop potential drug specific disease efficient technological mean alzheimers disease ad become one top ten cause death world typical neurodegenerative disease acetylcholinesterase ache inhibited improves transmission cholinergic neurotransmitter patient restores cognitive function acetylcholinesterase inhibitor acheis often considered researcher potential drug treatment ad machine learning algorithm data mining technique accelerate drug development reduce cost biological experiment great significance develop model accurately predict acheis however study applied efficient mature ensemble learning method problem predicting potential inhibitor ache constructed dataset publicly available biological experiment database first time established ensemble learning model based catboost xgboost predict potential acheis demonstrate advantage ensemble learning model building acheis predictor based imbalanced heterogeneous data comprehensive evaluation afterwards also combined bestperforming model blending model acheiel case study obtained topranked potential inhibitor shown potential inhibit ache result suggest method promising application field ad finally developed web online prediction platform based best model reference researcher ,1
ML_725,face recognition hot topic field artificial intelligence pattern recognition mainly conducive machine learning algorithm judge whether face sample belong certain category based discussion analysis pca svm technology expounds basic principle process face recognition put forward face recognition method based pca svm finally method used recognize lfw labeled face wild face data set parameter adjuster named gridsearchcv used adjust parameter improve precision recall face recognition experimental result show face recognition technology based pca svm reduces dimension face data also increase recognition accuracy feasible face recognition method ,1
ML_726,hierarchical multilabel text classification hmtc important challenging field natural language processing nlp example automatic classification complaint text customer communication operator typical hmtc complaint text assigned multiple category stored hierarchical structure category different level related existing hmtc method however either process classification task level simultaneously utilize multiple classifier level separately ignore dependency among different level hierarchical structure proposed matrix factorization mf recursiveattention ra approach called mfra handle hmtc task capturing association among label different level mfra raise reliability hmtc based realworld complaint data customer communication operator experiment demonstrate top f score proposed mfra method achieves maximum increase % compared commonly used machine learning algorithm hierarchical svm clus hmc maximum increase % compared deep learning algorithm gru textcnn bert scene respectively ,1
ML_727,humanmachine interfacehmi technology gradually become research hotspot continuous development computer technology internet thingsiot technology hand gesture recognitionhgr important part hmi technology widely concerned among many technical route hgr technology wearable hgr technology based amode ultrasound show great application potential due advantage lightweight device free sensor constraint etc however process processing amode ultrasonic signal amplitude signal position may vary due muscle fatigue strength etc gesture repeated time later design method overcome problem accomplish hgr offline state setting threshold normalization method energy feature ultrasonic signal according threshold three machine learning algorithm including support vector machine svm linear discriminant analysis lda naive bayes nb used verify feasibility method average recognition accuracy experiment reached % signal stability also verified improved addition design recognition strategy based nb algorithm model identify unknown gesture ie gesture trained model five known gesture five unknown gesture set experiment average recognition accuracy known gesture % unknown gesture % method used optimize experience hgr system ,1
ML_728,intrusion detection id cloud environment received paramount interest last year among latest approach machine learningbased id method allow u discover unknown attack however due lack malicious sample rapid evolution erse attack constructing cloud id system id robust wide range unknown attack remains challenging article propose novel solution enable robust cloud id deep neural network specifically develop two deep generative model synthesize malicious sample cloud system first model conditional denoising adversarial autoencoder cdaae used generate specific type malicious sample second model cdaeeknn hybrid cdaae knearest neighbor algorithm generate malicious borderline sample improve accuracy cloud id synthesized sample merged original sample form augmented datasets three machine learning algorithm trained augmented datasets effectiveness analyzed experiment conducted four popular id datasets show proposed technique significantly improve accuracy cloud id compared baseline technique stateoftheart approach moreover model also enhance accuracy machine learning algorithm detecting currently challenging distributed denial ddos attack including lowrate ddos attack application layer ddos attack ,1
ML_729,present directly modulated laser dml time wavelength ision multiplexed passive optical network twdmpons edfabased booster amplification soabased preamplification utilized improve optical power budget experimentally demonstrate cband optically amplified data transmission compare performance nonreturntozero onoff keying nrzook four eightlevel pulse amplitude modulation pampam g class dml optical amplification uplink downlink power budget db db respectively achieved pam gbit signal harddecision forward error correction hdfec limit x & ltsup & gt & ltsup & gt transmission km singlemode fiber link mitigate waveform distortion caused limited bandwidth nonlinear dynamic memory effect strong laser frequency chirp dml especially multilevel signal modulation artificial neural networkbased machine learning equalizer lowcomplexity volterra nonlinear equalizer applied operate signal baud rate bit error ratio performance conjunction enhanced power budget lowcomplexity nonlinear equalizer justify validity dml nextgeneration pons ,1
ML_730,lowcost particulate matter sensor transforming air quality monitoring greater mobility compared reference monitor calibration lowcost sensor requires training data codeployed reference monitor machine learning based calibration give better performance conventional technique requires large amount training data sensor calibrated codeployed reference monitor propose novel transfer learning method quick calibration sensor minimal codeployment reference monitor transfer learning utilizes large amount data sensor limited amount data target sensor experimentation find proposed modelagnosticmetalearning maml based transfer learning method significantly effective competitive baseline reducing calibration error % % relative raw observation best baseline respectively ,1
ML_731,developed smart e glove recognizes static hand gesture used ing communication smart glove employ five dielectric elastomer sensor capture finger motion implement machine learning classifier onboard electronics recognize gesture five basic classification algorithm trained assessed decision tree support vector machine svm logistic regression gaussian na��ve bayes multilayer perceptron basic classifier selected perform well multiclass classification problem trained supervised learning modelbased algorithm implemented microprocessor training dataset collected participant providing range different hand size training algorithm evaluated dry environment data collected ten participant test well cope information furthermore underwater experiment conducted ass impact underwater environment algorithm classification result show classifier performed well dry environment accuracy fscores range logistic regressor svm highest score accuracy fscore underwater result showed algorithm underwater however performance drop er  focus buoyancy control breathing er trim ,1
ML_732,proposes novel bearing fault detection framework realtime condition monitoring induction motor based difference visibility graph dvg theory regard vibration signal healthy well different rolling bearing defect acquired fanend driveend accelerometer data recorded three different bearing defect four loading condition acquired vibration time series converted topological network dvg transformed vibration data graph domain degree distribution dd selected feature discriminate different fault network analysis variance anova test false discovery rate fdr correction discriminative dd feature selected feature subsequently fed input deep learning model ie bidirectional long shortterm network bilstm classifier fault classification classification problem addressed proposed approach delivered high fault detection accuracy finally classification performance proposed framework compared wellknown machinelearning classifier delivered satisfactory result ,1
ML_733,federated learning fl emerging distributed privacypreserving machine learning framework however performance traditional fl method seriously impaired realworld data appear noniid recent clustered federated learning cfl method eliminate impact noniid data grouping client similar data distribution cluster unfortunately existing cfl method heavily rely presetting cluster number failing achieve adaptive client clustering also experimentally observe imbalanced data largely degrade correctness client clustering novel cfl method without manual intervention named autocfl eliminate effect noniid imbalanced data simultaneously deal imbalanced data local training adjustment strategy adaptively adjusts number local training epoch client improve clustering correctness adaptability weighted votingbased client clustering strategy automatically group client appropriate cluster extensive experiment conducted evaluate design autocfl three popular datasets various data setting experimental result demonstrate autocfl outperforms stateoftheart method eg average improving model accuracy % reducing communication cost adaptive manner ,1
ML_734,ability digitally recorded quantified neurological exam information important help healthcare system deliver better care inperson via telehealth compensate growing shortage neurologist current neurological digital biomarker pipeline however narrowed specific neurological exam component applied assessing specific condition propose accessible visionbased exam documentation solution called digitized neurological examination dne expand exam biomarker recording option clinical application smartphonetablet dne software healthcare provider clinical setting people home enabled video capture examination performing instructed neurological test including finger tapping finger finger forearm roll standup walk modular design dne software support integration additional test dne extract recorded examination dd humanbody pose quantifies kinematic spatiotemporal feature feature clinically relevant allow clinician document observe quantified movement change metric time web server interface recording viewing feature visualization available dne evaluated collected dataset subject containing normal simulatedimpaired movement overall accuracy dne demonstrated classifying recorded movement various machine learning model test show accuracy beyond % upperlimb test % standup walk test ,1
ML_735,hyperspectral anomaly detection important hyperspectral image application find pixel anomalous spectral signature compared neighbor background without prior information existed research related statisticbased distancebased technique summarizing background sample certain model finding outlier various distance metric focus based machine learning method witnessed remarkable progress recent year particular study generally roughly grouped traditional machine learning deep learningbased method several representative method including traditional machine deep learningbased method conducted four real hsis experiment finally conclusion regarding summarized prospect future development direction discussed ,1
ML_736,surface defect detection essential process ensure quality product surface defect classification sdc based deep learning dl shown great potential however welltrained sdc model usually requires large training data small intraclass difference defect normal sample also degrades performance sdc model overcome drawback research proposed cycleconsistent adversarial network attention mechanism attencgan firstly attencgan used synthesizing defect sample enlarge sample volume secondly attention mechanism adopted feature enhancement finding discriminative part sample enlarging difference among sample attencgan tested kolektorsdd dagm datasets accuracy % % sample experiment result show attencgan outperforms published sdc method based dl machine learning validates potential ,1
ML_737,htype photonic crystal nanocavity hold quite small volume cavity mode among dielectric cavity find ultrahigh quality factor q structure htype photonic crystal nanocavity allow stable operation laser even fabricationinduced disordering previous obtained iterative machine learning model searched structure slotted version value q obtained value order magnitude higher obtained manual optimization however improvement value saturated insufficient prediction accuracy model higher q regime instead applying iterative machine learning model implemented covariance matrix adaptation evolution strategy algorithm search structure stepbystep q calculation q value obtained nanocavities consuming lower calculation cost q structure significantly suppressed unwanted outofplane modal leakage improved robustness structural disordering ,1
ML_738,nowadays blockchainbased technology developed various industry improve data security iiot device become increasingly prevalent digital world especially support developing smart factory although blockchain powerful tool vulnerable cyber attack detecting anomaly blockchainbased iiot network smart factory crucial protecting network system unexpected attack federated learning fl build threat hunting framework called block hunter automatically hunt attack blockchainbased iiot network block hunter utilizes clusterbased architecture anomaly detection combined several machine learning model federated environment best knowledge block hunter first federated threat hunting model iiot network identifies anomalous behavior preserve privacy ,1
ML_739,development deep learning artificial intelligence becoming important technology automated computing mobile device innovation given modern mobile device ability conduct activity object detection recognition speech text examines existing research deep learning machine learning artificial intelligence ass level deep learning mobile device environment furthermore examined benefit blockchain smart contract mobile device environment finally obstacle associated integration artificial intelligence mobile device environment presented emphasizing importance addressing issue future order establish safe resilient framework ,1
ML_740,recent field object vehicle detection video interested became applicable method deep learning machine learning objective application display targeted object video field still facing low detection accuracy problem goal develop approach able classify vehicle video hog feature linear svm classifier machine learning method yolov look version algorithm deep learning method used two famous datasets vehicle detection video kitti gti datasets result address problem vehicle detection improved accuracy training ,1
ML_741,latent gaussian model boosting widely used technique statistic machine learning treeboosting show excellent prediction accuracy many data set potential drawback assumes conditional independence sample produce discontinuous prediction eg spatial data difficulty highcardinality categorical variable latent gaussian model gaussian process grouped random effect model flexible prior model explicitly model dependence among sample allow efficient learning predictor function making probabilistic prediction however existing latent gaussian model usually assume either zero linear prior mean function unrealistic assumption article introduces novel approach combine boosting latent gaussian model order remedy abovementioned drawback leverage advantage technique obtain increased prediction accuracy compared existing approach simulated realworld data experiment ,1
ML_742,artificial neural network ann capacity learn characteristic nonlinear system nonlinear mapping potential candidate highly nonlinear dynamical process control neural network controller design speed adjustment indirect field oriented induction machine drive considered original pi based controller first proposed simulated inputoutput nonlinear relationship learned offline feedforward linear network one hidden layer simulation neural network controlled system show promising result motor reach reference speed rapidly without overshoot step command tracked almost zero steady state error overshoot load disturbance rapidly rejected variation motor parameter fairly well dealt ,1
ML_743,introduce analyze vehicleallocation algorithm overhead hoist transport oht system semiconductor waferfabrication facility fabs oht widely used type automated materialhandling system fabs comprising hundred vehicle delivering lot processing machine timely transport unit delivery oht system critical efficient overall operation modern fab first describe limitation current oht vehicleallocation algorithm detail improved system implemented practical environment manage operation hundred oht vehicle proposed system based reinforcement learning particular us qlearningbased dynamic vehicleallocation algorithm examine traffic condition allocate oht vehicle delivery propose multiple algorithm based qlearning approach compare performance conventional allocation approach reveals appropriate algorithm industry demonstrate algorithm efficient sufficiently fast used practical largescale setting ,1
ML_744,methodology characterization lateral indentation silicongermanium sige nanosheets different nondestructive inline compatible metrology technique presented discussed gateallaround nanosheet device structure total three sacrificial sige sheet fabricated different etch process condition used induce indent depth variation scatterometry spectral interferometry xray fluorescence conjunction advanced interpretation machine learning algorithm used quantify sige indentation solution two approach average indent represented single parameter well sheetspecific indent presented scatterometry spectral interferometry well xray fluorescence measurement suitable technique quantify average indent single parameter furthermore machine learning algorithm enable fast solution path combining xray fluorescence difference data scatterometry spectrum therefore avoiding need full optical model solution similar machine learning model approach employed sheetspecific indent monitoring however reference data crosssection transmission electron microscopy image analysis required training found scatterometry spectral interferometry spectrum traditional optical model combination advanced algorithm achieve good match sheetspecific reference data ,1
ML_745,industrial internet thing iiot mainly dataoriented network intelligent processing massive data desiderated realize interconnection machine currently deep learningbased method widely applied intelligent construction iiot maximize selfmonitoring selfmanagement capability various machine however quantity quality data optimization parameter greatly limit property method breakthrough artificial intelligence deep reinforcement learning provides inspiration direction combine advantage deep learning reinforcement learning construct endtoend fault identification system therefore novel deep dual reinforcement learning model proposed consisted actor model critic model dual structure avoid overselfoptimization network action model continually learns knowledge identifying unknown sample ��greedy algorithm critic model dynamically adjusts policy guide action model right training direction effectiveness proposed method verified three bearing datasets result indicate proposed method enables agent independently realize pre fault quantitative identification establishment experience storage unit overcomes problem insufficient sample avoids blind trial error proposed mode ,1
ML_746,due need computing model process large quantity data efficiently high throughput many stateoftheart machine learning algorithm processinginmemory pim paradigm emerging potential replacement standard digital architecture workload tutorial progress pim technology recent year circuit architecture level analysis pim technology surpasses performance conventional architecture finally outline vision future pim technology ,1
ML_747,recently topic utilize prior knowledge obtained machine learning technique eda flow widely studied topic propose practical plugin named pro routability optimization routed wirelength estimation applied stateoftheart commercial eda tool academic eda flow negligible runtime overhead pro consists three part effective fully convolutional network fcn based predictor utilizes data placement result forecast global routing gr congestion parameter optimizer reasonably adjust gr cost parameter based prediction result generate better gr solution detailed routing convolutional neural network cnn based wirelength estimator accurate routed wirelength placement stage predicted gr congestion experiment show industrial benchmark suite advanced technology node pro achieve high accuracy gr congestion prediction significantly reduce design rule checking drc violation % average dac benchmark suite pro achieve low error rate % wirelength estimation greatly outperforms flute % % ,1
ML_748,flow cell array fcas concurrently provide efficient onchip liquid cooling electrochemical power generation technology especially promising threedimensional multiprocessor systemsonchip mpsocs realized deeply scaled technology challenging power thermal requirement indeed fcas effectively improve power delivery network pdn performance particularly switched capacitor sc converter employed decouple flow cell systemsonchip voltage allowing operate optimal point nonetheless design fcabased solution entail nonobvious consideration tradeoff stemming dual role governing thermal power delivery characteristic mpsocs showcasing explore multiple fca design configuration demonstrate technology decrease temperature heterogeneous mpsoc ���c total power consumption % compared highperformance coldplate based liquid cooling solution time fcas enable % voltage drop recovery across dy sc converter occupying small fraction chip area outcome provide opportunity boost mpsoc computing performance increasing operating frequency eraging result introduce novel temperature voltageaware model predictive control mpc strategy optimizes power efficiency runtime achieve applicationwide speedup % various machine learning ml data mining highperformance benchmark keeping mpsoc temperature ���c voltage d,1
ML_749,naval battlefield one position future conflict major power powerful naval battlefield target search capability last barrier carry maritime training operation time complex changeable environment important strategic position become difficult battlefield joint search rescue central part order reduce time target search maritime battlefield realtime path planning method maritime battlefield based deep reinforcement learning proposed method proposed advantage path planning multimachine collaborative meet requirement realtime performance first mathematical planning model target search naval battlefield constructed mapped reinforcement learning model based rainbow deep reinforcement learning algorithm state vector neural network structure algorithm framework target search path planning naval battlefield designed process finally feasibility effectiveness proposed method verified experiment sequential exchange strategy sequential insertion strategy * algorithm added improve optimal path obtained algorithm iteration improved algorithm applied target path planning problem time window experiment solomon data set optimal solution path improved algorithm compared proved improved algorithm better performance way cooperative behavior multiagents realized stability reinforcement learning improved simulation result show length path searched proposed algorithm inflection point path shortened % % respectively compared benchmark algorithm verifies superiority proposed algorithm ,1
ML_750,astounding acceleration artificial intelligence quantum computing advance naturally give rise line research unrolls potential advantage quantum computing classical machine learning task known quantum machine learning quantum machine intelligence typical objective either exploring potential quantum advantage classical learning task levering wellestablished classical ml algorithm tackle quantumrelated problem noisy intermediatescale quantum nisq device second research direction quantum neural network qnns accomplish bayesian learning observing wide range study qnns sole training method based frequentist training find bayesian learning benefit qnns two aspect first bayesiantrained model enjoy high level generalization due prior posterior distribution usage compared frequentist training justified paper theoretical model capacity second bayesian inference offer epistemic uncertainty estimation merit decisionmaking process worth mentioning frequentisttrained qnns generally lack desirable property bayesian training procedure derived model considered class qnns called bayesianqnns posse desirable property bayesian inference maintaining comparable predictive performance frequentist counterpart proposed bayesian quantum neural network justified empirical evidence numerical experiment ,1
ML_751,phishing social engineering cyberattack criminal deceive user obtain credential login form submits data malicious server compare machine learning deep learning technique method capable detecting phishing website url analysis current stateoftheart solution dealing phishing detection legitimate class made homepage without including login form contrary url login page class consider much representative real case scenario demonstrate existing technique obtain high falsepositive rate tested url legitimate login page additionally datasets different year show model decrease accuracy time training base model old datasets testing recent url also perform frequency analysis current phishing domain identify different technique carried phishers campaign prove statement created dataset named phishing index login url piluk composed k legitimate url including index login website k phishing url finally logistic regression model combined term frequency inverse document frequency tfidf feature extraction obtains % accuracy introduced login url dataset ,1
ML_752,ease advancement drone technology resulting widespread application unmanned aerial vehicle uavs erse field making booming technology among uavs several application livestock agriculture one promising uavs facilitate various operation efficient animal management field characterized multiple environmental technical economic strategic challenge however advanced technological technique like artificial intelligence ai internet thing iot machine learning ml deep learning dl advanced sensor etc assurance animal welfare operating uavs lead widespread adoption drone technology amongst livestock farmer discus livestock management research uavs monitor farm animal via detection counting tracking animal etc article attempt made elucidate different aspect broader issue around livestock management highlighting associated challenge opportunity prospect first subject matter necessary information analysis best knowledge therefore article promise provide interested researcher detailed information field guiding future research ,1
ML_753,every maritime accident cause severe damage human also maritime instrument like vessel author therefore propose machine learningbased maritime accident prediction system used prevent maritime accident happening predicting interpreting accident overcomes limitation existing work lack practicability sense expost analysis conducted suggest accident prevention strategy maritime accident analyzed holistically extensive literature review expert interview large number risk factor associated maritime accident identified related data collected utilized throughout variable selection data retrieval hotspot identification maritime accident prediction model construction process various machine learning algorithm exploited order construct organized system addition interpretation resulting accident prediction given interpretable machine learning algorithm provide explainable result user finally proposed system evaluated servqual model prof effectiveness realworld application ,1
ML_754,machine vision based vehicle reidentification reid play important role intelligent transportation system yet previous method mainly focus fixed surveillance camera instead unmanned aerial vehicle uav high flexibility uavbased vehicle reid problem special challenge including complicated shooting angle low discrimination topdown feature large variance vehicle scale etc overcome challenge propose novel structure uavbased vehicle reid without license plate firstly triplehead segmentation net proposed segmenting uavcaptured vehicle different height direction secondly posture calibration model designed uniform vehicle posture based segmentation result reducing influence different posture thirdly novel crossview & amp hardsensitive metric learning chsml method proposed train reid network crossview training constraint hard sensitive principle mechanism chsml take crossview sample id training unit learn potential visual relationship crossview build hard sensitive weight matrix make learning focus hard sample improves low reid accuracy brought crossview hard sample moreover facilitate research uavbased vehicle reid largescale uavbased vehicle reid dataset called veriuav released vehicle id experiment show proposed structure gain better performance compared representative method uavbased vehicle reid ,1
ML_755,economic lifeline southwest china sichuan province contributed chinese sustainable economic development prominent chengdu chengduchongqing area pivotal china regional development plate th fiveyear plan china implementation chengduchongqing double city economic circle emphasized different aspect policy directly stimulate regional economy thus driving economic development sichuan accordingly take gdp city sichuan province dependent variable except traditional financial method model adopts one machine learning method principal component analysis pca compare development level city horizontally vertically meanwhile machine learning method model sampling accuracy first two principal component could interpret % total variance therefore evaluates analyzes result rank city exploring possibility coordinated economic development sichuan province background construction twin chengduchongqing economic circle hopefully consequence research provides theoretical reference policy implementation ,1
ML_756,common disease population liver disease easy found easy develop liver cirrhosis liver cancer article proposes wlrxgb algorithm establish prediction model patient liver disease help doctor perform preliminary screening patient liver disease article us liver function record patient us wlrxgb algorithm establish model predict whether patient liver disease us accuracy rate recall rate f score evaluation model research found wlrxgb algorithm compared traditional machine learning algorithm model established catboost algorithm better predictive ability make accurate prediction patient liver disease accuracy rate recall rate fscore ,1
ML_757,research aim predict stock market information news title published influential news website term frequency inverse document frequency used encoding method compare predicting power several different machine learning algorithm twoclass averaged perceptron twoclass bayes point machine twoclass boosted decision tree twoclass decision forest twoclass decision jungle twoclass locally deep support vector machine twoclass logistic regression twoclass neural network approach chinese news title u news title covering dow jones industrial average range csi index price range investigated transforming stock price dummy variable twoclass neural network model found best predicting model chinese market twoclass decision jungle model best choice u market ,1
ML_758,credit risk important part commercial bank risk management risk management core issue bank financial management good bad credit risk management directly affect bank efficiency one effective mean avoid nonperforming loan various business development promotion bank nonperforming loan rate also growing affect rapid healthy development bank even lead expansion scale bank liability era big data importance proper utilization data gradually emerged brings challenge opportunity commercial bank ability make good big data become key risk management commercial bank data mining crossdisciplinary field brings together technique method database statistic machine learning field uncover potentially useful information knowledge large amount banking data provide manager effective information decision making turn prevent manage risk effectively based data mining technology investigates bank credit risk management method effectively solve credit risk control problem commercial bank optimize credit project process improve quality credit delivery provide reference credit risk management related personnel ,1
ML_759,breakthrough various statistical learning method machine learning playing increasingly important role production life although machine learning model perform well practice security issue machine learning model attracted widespread attention academia industry example machine learning model require lot manpower material financial resource training huge commercial value generally speaking machine learning model trade secret company patent us flush+reload technique extract support vector machine svm kernel function information cache side channel seriously threatens security machine learning model experiment attacked scikitlearn machine learning framework two attack required accurately infer kernel function used victim svm training program ,1
ML_760,true validity result evaluation quality teaching depends scientifically feasible reasonable reliable evaluation method order improve accuracy reliability interdisciplinary teaching evaluation conduct teaching evaluation based understanding interdisciplinary combined nuclear function constructed principle machine learning algorithm parametric optimization method established improve algorithm model constructed interdisciplinary teaching quality evaluation machine learning algorithm rvm relevance vector machine analyzed application interdisciplinary teaching evaluation system experimental result show machine learningbased interdisciplinary teaching evaluation rvm model high accuracy good reliability ,1
ML_761,deep learning technology applied field machine vision image colorization gradually become hot research direction traditional image colorization technology need humancomputer interaction application operation process technology complex difficult difficult achieve largescale application considering shortcoming traditional method propose image colorization algorithm designing improved generation adversarial network gan aiming problem blackandwhite photo colorization selfattention model sam used construct image generation image detail generated according clue feature position spectral normalization method introduced improve quality network generated image discriminator algorithm proposed effectively check consistency feature longrange detail image experimental result show algorithm effectively achieve batch colorization blackandwhite image ,1
ML_762,jiangsu zhejiang shanghai located yangtze river delta high degree openness outside world developed economy region vital economic strength country studying economic development region refer development region chinamachine learning integral part ai important driver ai scientific research application area bring series fundamental change traditional decisionmaking mechanism principal component analysis unsupervised machine learning algorithm mainly used dimensionality reduction data approach reveal feature regional economic quality evaluation convenient understandingthis article construct economic development quality evaluation system four aspect economic efficiency innovation development people life sustainable development principal component analysis method used compare economic development quality city jiangsu zhejiang shanghai time analyze result carried evaluation put forward countermeasure suggestion improving quality jiangsu zhejiang shanghai regional economy help highquality development jiangsus regional economy zhejiang shanghai ,1
ML_763,order accurately predict shortterm load combination forecasting model based extreme learning machine proposed first variational modal technology used decompose original load sequence appropriate number modal component obtained secondly according different performance characteristic modal time series extreme learning machine model used prediction improved bat algorithm used optimize selection parameter extreme learning machine finally output value model built subsequence reconstructed obtain final prediction result measured data effectiveness accuracy combined forecasting model proposed verified load forecasting ,1
ML_764,massive onsite data produced internet thing iot bring valuable information immense potential thus empowering wave emerging application however rapid increase onsite iot data stream become extremely challenging develop scalable computing platform provide comprehensive workflow processing iot data stream lower latency intelligence end kubernetesbased scalable fog computing platform kfiml integrating big data streaming processing machine learning mlbased application also provide comprehensive iot data processing workflow including data access transfer big data processing online ml longterm storage monitoring platform feasibly validated clustered testbed comprises master node iot broker server worker node local database server leveraging lightweight orchestration system namely kubernetes readily scale manage containerized software framework testbed big data processing layer utilizes advanced data flow framework apache flink support streaming processing statistical analysis low latency addition specified long shortterm memory lstm based ml pipeline employed online ml layer enable realtime predictive analysis iot data stream experiment realworld smart grid case demonstrate containerbased kfiml platform wellscaled kubernetes efficiently perform big data processing increased onsite iot data stream lower latency conduct mlbased application ,1
ML_765,federated learning fl disruptive machine learning paradigm enables collaborative training global model decentralized local datasets without sharing span wide scope application internetofthings iot biomedical engineering drug discovery support lowlatency highprivacy fl wireless network propose reconfigurable intelligent surface ri empowered overtheair fl system alleviate dilemma learning accuracy privacy achieved simultaneously exploiting channel propagation reconfigurability ri boosting receive signal power well waveform superposition property overtheair computation aircomp fast model aggregation considering practical scenario highdimensional local model update transmitted across multiple communication block characterize convergence behavior differentially private federated optimization algorithm formulate system optimization problem optimize learning accuracy satisfying privacy power constraint via joint design transmit power artificial noise phase shift ri twostep alternating minimization framework developed simulation result validate systematic theoretical algorithmic achievement demonstrate ri achieve better tradeoff privacy accuracy overtheair fl system ,1
ML_766,proposes computationally efficient methodology predict damage progression solder contact electronic component temperaturetime curve two machine learning algorithm multilayer perceptron long shortterm memory network trained compared respect prediction accuracy required amount training data training performed synthetic normally distributed data realistic automotive application finite element model simple bipolar chip resistor surface mount technology configuration used numerically compute synthetic data result machine learning algorithm show relevant accuracy prediction accumulated creep strain training data length hour % available training data model show constantly good fitting performance rsupsup multilayer perceptron rsupsup long shortterm memory network prediction error accumulated creep strain le % amount hour training data decrease le % data therefore approach promising lifetime prediction directly electronic device ,1
ML_767,present development novel modelling approach based deep learning dl predict orthotropic composite property copperpatterned conductive layer printed circuit board pcbs data needed ass bulk pcb property existing method laminar composite image datasets copper patterned artwork required approach gathered composite homogenised orthotropic elastic modulus respective conductive layout evaluated automated macroscript executed finite element analysis modulus value assigned label image copper layout dataset regression convolutional neural network developed optimised training dataset validated test datasetthe result show dl model predict orthotopic value elastic modulus highly nonstructured copper pattern accurately absolute error predicted v true fea evaluated property value le % composite propriety range % pattern validation dataset advantage proposed machine learning solution existing technique digitalised made available enduser easytouse computationally fast toolset modelling approach enable design engineer effectively explore pcb design alternative awareness thermomechanical property effect assembly performance component reliability ,1
ML_768,precise control complex system requires good numerical model elegant consideration inidual uniqueness datadriven online machine learning oml framework proposed achieve goal set uvled reliability testing data applied verify feasibility oml concept moreover design guideline deducedthe oml model built based neural network nn architecture genetic algorithm ga principal component analysis pca applied obtain optimal nn initial weighting parameter hundred iteration model defined based model ml careful investigation evolution nn parameter iteration feasibility oml engineering application validated moreover basic strategy oml established including continuous monitoring weighting change prediction error result show hour data required predict inidual led performance hour acceptable accuracy ,1
ML_769,coronavirus disease covid outbreak become global health threat influx covid patient prolonged length stay los emergency department ed united state objective develop reliable prediction model covid patient ed los identify clinical factor age comorbidities associated los hour target data collected urban demographically erse hospital detroit covid patient ed presentation march december trained four machine learning model namely logistic regression lr gradient boosting gb decision tree dt random forest rf across different data processing stage predict covid patient ed los le greater hour analysis inclusive covid patient known ed los significant clinical factor incorporated gb model outperformed baseline classifier lr treebased classifier dt rf accuracy % fscore predicting ed los testing data significant accuracy gain achieved splitting identified key independent factor combination patient demographic comorbidities ed operational data predicted ed stay patient prolonged covid prediction framework serve decisionsupport tool improve ed hospital resource planning inform patient better ed los estimation ,1
ML_770,machine learning ml algorithm used decision support d autonomous system commonly train labeled categorical sample closed set however pose problem deployed d autonomous system encounter anomalous pattern originate closed set distribution used training case ml algorithm trained closed set sample may erroneously identify anomalous pattern originated one category closed set sometimes high confidence consider problem unknown pattern recognition generative perspective additional synthetic training sample represent anomaly added training data synthetic sample generated optimally balance desire place anomaly boundary training set feature space adversely effecting core classification performance test set demonstrate efficacy distancebased probabilistic anomaly augmentation dpaa proposed erse set application character recognition intrusion detection compare combined classification identification performance recent set traditional novelty detection approach ,1
ML_771,sleep monitoring polysomnography psg hospital considered expensive preferable way contactless wearable sensor monitor sleep daily patient home internet thing iot platform utilized sleep monitoring contactless wearable sensor integrated system developed based eventdriven microservice architecture multiple service respond event provided system electrocardiogram ecg data used input sleep monitoring system combination weighted extreme learning machine welm algorithm particle swarm optimization pso used process ecg data followed fuzzy logic measure sleep quality display data dashboard based experimental result proposed architecture increased throughput % decreased response time % reduced memory consumption % per instance replication compared noneventdriven architecture accuracy sleep stage classification % % three four class respectively area roc curve auc reached three four class classification ,1
ML_772,industry prognostic health management phm used improve system reliability efficiency phm remaining useful life rul prediction play key role preventing machine failure reducing operation cost recently development deep learning technology long shortterm memory lstm convolutional neural network cnn adopted many rul prediction approach show impressive performance however existing deep learning based method directly utilize raw signal since noise widely exists raw signal quality approach feature representation degraded degenerate rul prediction accuracy address issue firstly propose series handcrafted feature flow hffs suppress raw signal noise thus improve encoded sequential information rul prediction additionally effectively integrate proposed hffs raw input signal novel bilstm based twostream network proposed novel twostream network three different fusion method designed investigate combine stream feature representation reasonable way verify proposed bilstm based twostream network extensive experiment carried cmapss dataset showing superior performance stateoftheart approach ,1
ML_773,data analysis increasingly performed data assembled uncontrolled source facing inconsistency knowledgerepresentation convention typical practice create clean data analysis matching entity merging variant overcome difference knowledge representation despite progress data management technique automate process still need laborintensive supervision analyst evaluate benefit advanced statistical tool address directly many analytic task across data source without entitymatching cleaning reframing analytical question machinelearning task enables replace exact matching entity continuous description ���vectorial embeddings��� expose similarity entry analysis le cleaning trustworthy ? answer question thorough benchmark question typical socioeconomic study across employee database compare approach based machine learning manual data cleaning entity matching reveals embeddings machine learning improves result validity smaller estimation error manual cleaning considerably le human labor machine learning often comanagement cleaning suggests directly analysis beneficial capture ambiguity hard represent curation ,1
ML_774,novel measurement framework absolute total anthocyanin content aac leaf proposed proximallysensed leaf spectroscopic measurement coupled machine learning technique leaf reflectance transflection spectral measurement investigated sounding entire spectral range visible shortwave infrared accounting whole shape leaf spectrum result show low prediction error higher average mgg aac retrieval even quarter available data used training improved performance higher fraction training data employment transflectance shown benefit retrieval process providing generally lower prediction error aac retrieval process machine learning technique automatically performs wavelength selection providing output subset relevant wavelength aac retrieval framework represents first step towards development lowcost measurement system easily operated field quick reliable anthocyanin content measurement ,1
ML_775,intermittent fault common problem various kind electronic device focused intermittent fault phenomenon degraded electrical connector vibration environment analyze intermittent fault degraded electrical connector microstate contact model constructed simulate resistance variation behavior vibration environment relationship intermittent fault behavior degradation state studied health indicator parameter extracted signal act symptom degradation test platform built collect intermittent fault signal electrical connector different degradation state vibration environment degradation curve health indicator used predict remaining useful life rul electrical connector method extreme learning machine elm adopted conduct prediction rul genetic algorithm ga used optimize weight bias parameter elm result reflect intermittent fault characteristic proper degradation index prediction rul degraded electrical connector ,1
ML_776,although positioning indoor outdoor environment investigated indepth inidually various mean little attention paid intersected area environment positioning accuracy boundary area remains concern indoor positioning several recent study applied machine learning algorithm based wifi signal however method may applicable solve boundary localization problem faced positioning boundary area around building propose deep learning model concatenates autoencoders lstm network perform multisensor multitask fingerprint positioning adopted sensor include wifi gps cellular fused gps magnetometer model first employ dense blockbased autoencoder extract representative latent code fingerprint latent code proven distinguishable since revertible original input sequence latent code injected lstm network performing three output task responsible location estimation suitable sensor selection indooroutdoor classification respectively extensive reallife experiment performed two campus result demonstrate model achieves high positioning accuracy average euclidean distance estimation error meter ,1
ML_777,hversatile video coding vvc latest international video coding standard encode ultrahighdefinition video effectively quadtree nested multitype tree qtmtt structure provides various size coding tree partitioning allows nested binary tree bt split ternary tree tt split qt level furthermore numerous advanced coding tool equipped hvvc encoder however encoding time increase tremendously previous research regarding fast coding algorithm hvvc seldom mention perceptual redundancy utilizes human vision model noticeable difference extract visually distinguishable pixel may affect visual perception observe distribution acquired horizontal vertical projection visually distinguishable pixel coding unit related corresponding mtt splitting mode therefore distribution representing perceptual information human vision used input feature machine learning fast mtt decision determined random forest model machine learning proposed quickly select partition intra coding experimental result demonstrate proposed method effectively accelerate intra coding process maintain good bitrate video quality based property visual perception proposed algorithm provides better performance previous ,1
ML_778,neuromorphic circuit usually analog computation vectormatrix multiplication vmm neural network nn promising machine learning accelerator much lower latency power consumption digital one analog computation expected efficient design space digital computation since signal digitized therefore suitable internetofthing iot application require ultralow power consumption low cost iot application sometimes also desirable eliminate digital circuit adder register shifter multiplexer analogtodigital converter vmm array reduce power consumption however optimization purely analog circuit difficult requires full spice circuit simulation softwarecircuitdevice cooptimization framework python wrapper automatic full circuit spice simulation analysis neuromorphic circuit framework allows user experiment nn design software affect performance hardware neuromorphic circuit take veriloga spice model calibration pdk various technology emerging memory reram without calibration unlike behavior model show simulation time reasonable even hundred thousand synapsis limited computation resource reram nm generic technology example effect feedback network opamp design software ml architecture input data accuracy inference accuracy studied ,1
ML_779,gait recognition wearable sensor effective approach identifying people recognizing distinctive walking pattern deep learningbased network recently emerged promising technique gait recognition yielding better performance template matching traditional machine learning method however recent study focused improving gait detection accuracy neglecting model complexity deep learning domain making unsuitable lowpower wearable device therefore inference model result latency due calculation overhead proposes efficient network suitable wearable device without sacrificing prediction performance modified residual block accumulated shallow convolutional neural network five weighted layer gait recognition proved efficacy architectural component extensive experiment publicly available imubased datasets whugait ouisir proposed model outperforms stateoftheart method regarding recognition accuracy percent efficient average term model parameter memory consumption ,1
ML_780,monitoring financial transaction critical antimoney laundering aml obligation financial institution recent year machine learningbased transaction monitoring system successfully complemented traditional rulebased system reduce high number false positive effort needed alert manually unfortunately machine learningbased solution also disadvantage unsupervised model detect novel fraudulent pattern usually characterized high number false alarm supervised model instead usually offer higher detection rate require large amount labeled data achieve performance amaretto active learning framework money laundering detection combine unsupervised supervised learning technique support transaction monitoring process improving detection performance reducing fraud management cost amaretto exploit novel selection strategy target subset transaction investigation making efficient feedback provided analyst perform experimental evaluation synthetic dataset provided industrial partner simulates profile client trading international capital marketswe show amaretto outperforms stateoftheart solution reducing money laundering risk improving detection performance particular compare stateoftheart unsupervised supervised technique commonly used aml domain one implemented workwe show isolation random forest amaretto perform best analysis auroc first % better average detection rate second % better average addition method characterized lower cost computed term daily number transaction examined number false positive negative finally compare amaretto stateoftheart active learning fraud detection system achieving better detection performance lower cost scenario analysis worth mentioning amaretto improves detection rate % reduces overall cost % realistic scenario analysis ,1
ML_781,proposes proofofconcept device continuously ass usage handheld power tool detect construction working task eg different drilling work potential misusages eg drop energy efficient architecture design designed device based bluetooth low energy ble nfc connectivity ble used exchange data gateway whereas nfc chosen energyefficient wakeup mechanism temperature humidity sensor embedded monitor storage condition accelerometer tool usage monitoring arm cortexmf core embedded ble module exploited process information edge tiny machine learning tinyml algorithm proposed process data directly board achieve low latency high energy efficiency tinyml algorithm developed embedded proposed device detect different usage class tool transportation noload metal wood drilling dataset containing minute threeaxis acceleration different activity acquired device attached construction rotary hammer drill used train validate algorithm network architecture search na performed optimize tradeoff accuracy complexity achieving accuracy % model size roughly kb experimental result showed ultralow power consumption sleep mode na peak power consumption running tinyml edge result balanced combination edge processing capability low power consumption enabling obtain smart internet thing iot device field long lifetime year operation year shelf mode standard mah coin battery enables long battery lifetime operation device degradation utility analysis closing gap edge processing fine granularity data evaluation ,1
ML_782,common phenomenon increasingly stimulates interest investor company entrepreneur involved crowd funding activity particularly kickstarter website identifying metric make campaign markedly successful seek gauge importance key predictive variable feature based statistical analysis identify modelbased machine learning method based performance assessment predict success campaign compare selected different machine learning algorithm achieve research objective maximize insight dataset used feature engineering performed machine learning model inclusive logistic regression lr support vector machine svms form linear discriminant analysis lda quadratic discriminant analysis qda random forest analysis bagging boosting performed compared via cross validation approach term resulting test error rate f score accuracy precision recall rate machine learning model employed predictive analysis test error rate classification metric score obtained across three crossvalidation approach identified bagging gradient boosting svms robust method predicting success kickstarter project major research objective achieved accessing performance key statistical learning method guide choice learning method model giving u measure quality ultimately chosen model however bayesian semiparametric approach future research consideration method facilitate usage infinite number parameter capture information regarding underlying distribution even complex data ,1
ML_783,bladder cancer bc common urinary malignancy however accurate diagnosis prediction recurrence therapy remain elusive aimed develop biosignature immunotherapybased response gene expression data publicly available bc datasets collected machine learning ml approach applied identify novel biosignature differentiate patient subgroup immune phenotyping bc imvigor dataset included three subtypes inflamed excluded desert immune immune phenotype analyzed gene expression traditional powerful classification method random forest deep neural network dnn support vector machine svm together boosting feature selection method specifically dnn yielded highest area curve auc precision recall pr curve receiver operating characteristic roc curve phenotype respectively resulting identification gene expression feature useful immune phenotype classification result suggest significant potential develop utilize machine learning algorithm analysis bc precaution conclusion finding novel gene expression assay accurately discriminate bc patient control upon validation independent cohort gene signature could developed predictive test support clinical evaluation patient care ,1
ML_784,one key difference traditional software engineering machine learning ml lack specification ml model traditionally specification provide cornerstone compositional reasoning ideandconquer strategy build large complex system component hard come machine learned component lack specification seems like fundamental problem first sight fact software engineer routinely deal iffy specification practice face weak specification wrong specification unanticipated interaction among specification ml may push u problem fundamentally rethinking ml model composition perspective featureinteraction problem highlight importance software design ,1
ML_785,enigma machine invented last world war served significant role german military history cryptography emergence radio transmission military communication faced revolution medium however manually encrypting message possibly leaking intelligence didnt meet military requirement encryption machine way efficient enciphering message manually high demand enigma machine initially protect commercial privacy nazi german developed additional mechanism adapt battlefield breaking enigma machine among top priority ally crucial rule cryptography meaningful examine explore enigma machine enigma encryption scheme one first encryption scheme involving electromechanics learning structure principle inspire future encryption scheme even though technology progressing tremendously afterwards rule processing cipher traffic remained great extent making enigma machine contributive investigation conducted explores security factor enigma machine possible advance enigma machine implementing algorithm component enigma machine research group developed simulator enigma machine via python inspection research group concludes security enigma machine top period without procedural error difficult break enigma machine ,1
ML_786,tobacco smoking leading cause lung cancer link million premature loss human capital around world pose everincreasing risk human two challenge tobacco smoking analysis lack latest data unrecorded influential factor resulting poor accessibility census data us machine learning data visualization method analyze relationship tobacco smoking lung cancer aiming make suggestion improving smoking phenomenon specifically enriching research dataset required onset research filling missing data organizing datasets targeted survey governmental institutional website preparation stage logistic regression knn two model detect cancer associated smoking character gene type confirm correction cancer tobacco smoking finally applies apache echarts microsoft tableau python matplotlib realize visualization bring three possible solution based smoking problem increasing tax tobacco prohibition cigarette advertisement institutional assistance quitting smoking experimental result show disastrous effect smoking data analysis even though decline global smoking rate past year smoking still unabated becoming second risk factor emanates numerous death based section visualization display two applicable effective policy proved official website world data restrain damage smoking ,1
ML_787,aiming problem traditional machine learning apply learned knowledge task poor classification effect dealing unbalanced botnet detection data proposed botnet detection method based generative adversarial networkgan efficient lifelong learning algorithmella firstly time window used extract feature ctu data set training set test set ided gan used expand data small number sample training set ella model trained expanded training set finally experiment carried test set experimental result show compared bella method average accuracy increased % average recall rate increased % compared traditional machine learning method ganella also achieve better detection result ,1
ML_788,order make student intuitively understand personal ability provide visual data support improving learning process firstly discus background significance student ability portrait system based big data secondly construction presentation process student ability portrait clarified feature value extraction model based id machine learning algorithm proposed feature feature attribute group student ability portrait established student ability portrait output visualization technology finally concluded student ability portrait help student monitor improve selfefficacy adjust learning behavior time improve learning efficiency learning effect ,1
ML_789,aim find relatively better method deal classification problem different data set exploring different machine learning method research direction analyze performance difference machine learning method data classification gaussian distribution image voice text excel find better classification method corresponding data set mainly used three machine learning method knearest neighbor algorithm knn supportvector machine svm neural network final test result show relatively simple discrete data excel knn best effect addition svm knn method image data inferior neural network remaining two data classification three machine learning method reasonable accuracy rate ,1
ML_790,flower recognition one distinguish specie flower since specie flower great variety hard distinguish specie manual feature recently development deep learning technique help u discovery much feature hidden image help u improve precious recognition thus motived advantage machine learning technique feature extraction depiction handcraft feature image detail build flower recognition model based feature extracted following three type feature extracted deep learning dualview feature multimodal feature ,1
ML_791,try explore possibility cyclegan field face aging effect cyclegan based aging model reason used cyclegan cyclegan require paired data training set paired data expensive difficult obtain paired data therefore unpaired data used training set greatly reduce cost facial aging plan psnr ssim measure truthfulness cyclegan generated image quantified aging effect cnnbased dex network ass age aging image process research found model unbalanced processing image different gender ethnic group tried make model balanced case classification training pretraining achieved good result finally developed gui convenient interface user cycle gan model face aging series quantitative analysis able conclude model good effect field facial aging superior aging model based deep learning also provide code project github httpsgithubcommeditatorefacetimetravelmachine ,1
ML_792,anomaly detection also known outlier detection one basic task data mining aim eliminate noise discovers potential knowledge received wide attention field data mining machine learning etc although many anomaly detection method proposed still problem well addressed including sample imbalance abnormal data occupies small portion entire dataset making modeling difficulty lack available labeled data deep learning model higher computational complexity proposed tadpctabular anomaly density peak clustering method focus tabular data studying anomaly detection method based density peak clustering algorithm introduce method pruning anomaly ensure detected abnormal value result conventional noise way reduce false positive compared widely used anomaly detection algorithm abodanglebased outlier detection loflocal outlier factor iforestisolation forest knnk nearest neighbor six different datasets proposed method tadpc effectively improves accuracy reduces false rate ,1
ML_793,complex structure unit composition transmission line routing operate stably balanced state however due natural human factor strong wind earthquake animal activity artificial misoperation circuit unit transmission line often affected external factor cause fault transmission line fault bring hidden danger tide intelligence necessary develop fault detection system transmission line based intelligent algorithm order clear line fault soon possible machine learning technology effectively establish fault detection system develop transmission line fault detection system based multilayer perceptron compared variety machine learning algorithm highlight advantage multilayer perceptron conduct experimental verification data set data threephase current voltage input experiment show multilayer perceptron algorithm higher accuracy random forest decision tree svm method multilayer perceptron improve % compared random forest % compared decision tree % compared svm ,1
ML_794,botnet serious network security threat cause server crash detect behavior botnet already become important part research network security dnsdomain name system request first step mainframe computer controlled botnet communicate c & ampccommand control server detection dns request domain name important way mainframe computer controlled botnet however detection method based fixed rule hard take effect botnet based dgadomain generation algorithm malicious domain name keep evolving derive many different generation method contrasted traditional method method based machine learning better way detect learning modeling dga present method based naive bayes model xgboost model svmsupport vector machine model mlpmultilayer perceptron model test real data set collected dga alexa secrepo experimental result show precision score recall score f score model ,1
ML_795,rapid development high technology artificial intelligence plenty novel software invention created thus essential consider make innovation practically improve convenience efficiency daily life therefore concerned implementing machine learning method address problem daily life thus novel form reinforcement learning algorithm applied shortest path problem abstracted real life problem focus finding optimal route tennote weighted graph one point destination agent trained four hundred time accumulate value q table result determined final q value success resolving problem algorithm implemented practically despite limitation help algorithm agent determine desired route extremely quickly improve efficiency ,1
ML_796,order improve expression detection ability english vocabulary feature multifeature fusion model english vocabulary semantic feature based machine learning proposed multifeature fusion recognition method english vocabulary semantic feature based machine learning proposed time domain feature analysis dynamic word meaning distribution model multidimensional feature english vocabulary semantic feature established disturbance identification multidimensional feature english vocabulary semantic feature carried combining joint estimation method semantics corpus parameter feature decomposition model multidimensional feature english vocabulary semantic feature constructed dynamic word meaning distribution modulation method fuzzy understanding method binary semantics adopted associated semantic ambiguity resolved machine self organizing learning method adopted english semantic text fusion target language retrieval carried statistical information analysis model multidimensional feature english vocabulary semantic feature established information clustering source language autocorrelation detection fusion feature recognition multidimensional parameter feature english vocabulary semantic feature realized test result show accuracy multidimensional feature recognition english vocabulary semantic feature method high semantic expression ability english vocabulary improved fusion english vocabulary semantic feature output signaltonoise ratio high ,1
ML_797,accurate staging lung adenocarcinoma important lung cancer operation prognosis however due large heterogeneity clinical staging difficult automatic prediction traditional method difficult extract heterogeneity discussed automatic prediction lung adenocarcinoma invasiveness multiple machine learning approach analyzed key factor performed retrospective ggn patient logistic regression support vector machine gaussian kernel random forest neural network classifier constructed identify lung adenocarcinoma invasiveness including minimally invasive adenocarcinoma invasive adenocarcinoma miaia performance four machine learning algorithm evaluated area roc curve auc sensitivity specificity extracting key factor proposed screening method based contribution factor neural network result demonstrated nn classifier could used noninvasive method automatically predicting lung adenocarcinoma invasiveness assist ggn management prior surgery predicted miaia patient could invasive method improve condition ,1
ML_798,human death prediction analysis help national department cope future trend suggests different country take appropriate measure reduce future death number challenging predict future death trend based existing data determine reason behind difference death composition different country us linear regression predict world death pattern us sdi kmeans analyze data find deep reason innovation analyze comprehensive death pattern include death factor machine learning model training compared contemporary work firstly search data kaggle filter data prediction part linear regression model based world death dataset trained implement mongodb+ html structure visualize prediction result analysis part sdi elbow method kmeans algorithm used underlying cause death country verify reliability prediction model r value interpretation error value evaluate model experimental result show death trend generated prediction model roughly correlate actual trend analysis demonstrates economical background geographical factor crucial influencing death pattern ,1
ML_799,botnet severe threat computer network detection botnet behavior important research area cyber security malware author leverage domain generation algorithm dga generate bulk pseudorandom domain name connect command control c & ampc server make detection prevention extremely difficult previous mostly defended dga domain preregistering sinkholeing publishing blacklist reverse engineering malware however approach easily bypassed malware author communication botnet c & ampc server first step generally sending domain name system dns request packet thus alternative approach based capturing analyzing dns traffic classifying domain previous tried cluster domain technique involved usage contextual information thus take long time period run algorithm mean technique used realtime detection compared traditional method recent method attempt predict whether domain dga generated based solely domain name string nevertheless method involved human engineered feature readily circumvented attacker proposed method extract linguistic feature well applies machine learning algorithm classify domain name verify performance proposed method designed implemented botnet detection system trained tested model real data result demonstrate proposed method able capture suspicious packet accurately classify domain evaluated system real traffic correctly classify dga domain % case furthermore detecting unknown dga domain system achieved % accuracy ,1
ML_800,based idea mixed learning design model mixed learning making full training institutionssoftware hardware environment human resource design development large number educational teaching resource construction network platform provides online learning support service ensure quality online learning facetoface learning saving time reduce cost learning improve efficiency learning mobilize student active mix combination training real feasible significance training activity systematic activity training set implementation effect plan affected many factor indepth detailed training programin order make teacher educational technology training better design educational technology training also need constant revision improvement time combined machine learning algorithm make comparative analysis satisfaction mixed learning ordinary learning verified mixed learning mode better effect ,1
